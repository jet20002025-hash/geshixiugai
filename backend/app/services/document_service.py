from __future__ import annotations

import base64
import io
import json
import os
import re
import shutil
import sys
import uuid
import xml.sax.saxutils
from datetime import datetime
from pathlib import Path
from typing import Dict, Tuple, Optional

from docx import Document
from docx.enum.text import WD_PARAGRAPH_ALIGNMENT
from docx.oxml import parse_xml
from docx.shared import RGBColor, Pt
from docx.oxml.ns import qn
from docx.oxml.shared import OxmlElement
from docx.text.paragraph import Paragraph
from fastapi import UploadFile

from .utils import docx_format_utils
from .storage_factory import get_storage
from .thesis_format_standard import (
    FONT_STANDARDS,
    STYLE_MAPPING_RULES,
    DEFAULT_STYLE,
    PAGE_SETTINGS,
    HEADER_SETTINGS,
    PAGE_NUMBER_FORMAT,
    REFERENCE_REQUIREMENTS,
)


class DocumentService:
    def __init__(self, document_dir: Path, template_dir: Path) -> None:
        self.document_dir = document_dir
        self.template_dir = template_dir
        self.document_dir.mkdir(parents=True, exist_ok=True)
        # è·å–å­˜å‚¨å®ä¾‹ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        self.storage = get_storage()
        self.use_storage = self.storage is not None
    
    def _log_to_file(self, message: str) -> None:
        """å°†æ—¥å¿—æ¶ˆæ¯åŒæ—¶è¾“å‡ºåˆ° stderr å’Œæ—¥å¿—æ–‡ä»¶ï¼ˆåŒé‡ä¿é™©ï¼‰"""
        print(message, file=sys.stderr, flush=True)
        try:
            with open("/var/log/geshixiugai/error.log", "a") as f:
                f.write(f"{message}\n")
        except Exception:
            pass

    async def process_document(
        self, 
        template_id: Optional[str] = None, 
        university_id: Optional[str] = None,
        upload: Optional[UploadFile] = None
    ) -> Tuple[str, Dict]:
        if not upload or not upload.filename or not upload.filename.lower().endswith(".docx"):
            raise ValueError("ä»…æ”¯æŒ docx æ–‡æ¡£")
        
        # éªŒè¯å‚æ•°ï¼štemplate_id å’Œ university_id å¿…é¡»äºŒé€‰ä¸€
        if not template_id and not university_id:
            raise ValueError("å¿…é¡»æä¾› template_id æˆ– university_id ä¹‹ä¸€")
        if template_id and university_id:
            raise ValueError("ä¸èƒ½åŒæ—¶æä¾› template_id å’Œ university_id")
        
        # åŠ è½½æ¨¡æ¿å…ƒæ•°æ®
        if university_id:
            template_metadata = self._load_university_template(university_id)
        else:
            template_metadata = self._load_template(template_id)
        document_id = uuid.uuid4().hex
        # ç”Ÿæˆå”¯ä¸€çš„ä¸‹è½½ tokenï¼Œç”¨äºéªŒè¯ç”¨æˆ·èº«ä»½
        download_token = uuid.uuid4().hex
        task_dir = self.document_dir / document_id
        task_dir.mkdir(parents=True, exist_ok=True)

        # ä¿å­˜åŸå§‹æ–‡ä»¶å
        original_filename = upload.filename
        
        original_path = task_dir / "original.docx"
        original_path.write_bytes(await upload.read())

        # åŠ è½½æ–‡æ¡£
        document = Document(original_path)
        
        # è¯Šæ–­1ï¼šæ£€æŸ¥åŸå§‹æ–‡æ¡£ä¸­è¯šä¿¡æ‰¿è¯ºå’Œæ‘˜è¦çš„åˆ†é¡µæƒ…å†µ
        self._log_to_file(f"[è¯Šæ–­] ========== å¼€å§‹è¯Šæ–­ï¼šåŸå§‹æ–‡æ¡£ ==========")
        original_diagnosis = self._diagnose_integrity_abstract_separation(document)
        self._log_to_file(f"[è¯Šæ–­] åŸå§‹æ–‡æ¡£è¯Šæ–­ç»“æœ: {original_diagnosis['issue'] if original_diagnosis['issue'] else 'æœ‰åˆ†é¡µç¬¦'}")
        self._log_to_file(f"[è¯Šæ–­] åˆ†é¡µç¬¦ä½ç½®: {len(original_diagnosis['page_break_locations'])} ä¸ª")
        
        # åº”ç”¨é¡µé¢è®¾ç½®ï¼ˆä¼˜å…ˆä½¿ç”¨æ ‡å‡†ï¼‰
        self._apply_page_settings(document)
        
        # æ£€æµ‹é¡µçœ‰ï¼ˆä¸ä¿®æ”¹ï¼Œåªæ£€æµ‹ï¼‰
        # ä¸å†è‡ªåŠ¨åº”ç”¨é¡µçœ‰ï¼Œåªæ£€æµ‹æ˜¯å¦å­˜åœ¨
        
        # åˆå¹¶æ¨¡æ¿è§„åˆ™å’Œæ ‡å‡†è§„åˆ™ï¼ˆæ ‡å‡†ä¼˜å…ˆï¼‰
        # å¦‚æœæ˜¯é¢„è®¾æ¨¡æ¿ï¼Œä½¿ç”¨ parametersï¼›å¦‚æœæ˜¯è‡ªå®šä¹‰æ¨¡æ¿ï¼Œä½¿ç”¨ styles
        if template_metadata.get("university_id"):
            # é¢„è®¾æ¨¡æ¿ï¼šä» parameters ä¸­æå–æ ¼å¼è§„åˆ™
            university_params = template_metadata.get("parameters", {})
            template_rules = self._convert_university_params_to_rules(university_params)
        else:
            # è‡ªå®šä¹‰æ¨¡æ¿ï¼šä½¿ç”¨ styles
            template_rules = template_metadata.get("styles", {})
        
        merged_rules = self._merge_rules_with_standard(template_rules)
        
        final_doc, stats = self._apply_rules(
            document=document,
            rules=merged_rules,
            default_style=template_metadata.get("default_style") or DEFAULT_STYLE,
        )
        
        # æ£€æµ‹å›¾ç‰‡å¹¶æ£€æŸ¥å›¾é¢˜
        figure_issues = self._check_figure_captions(final_doc)
        if figure_issues:
            stats["figure_issues"] = figure_issues
        
        # æ£€æµ‹å‚è€ƒæ–‡çŒ®å¼•ç”¨æ ‡æ³¨
        reference_issues = self._check_reference_citations(final_doc)
        if reference_issues:
            stats["reference_issues"] = reference_issues
        
        # ä¿®å¤å‰å…ˆè¯Šæ–­ä¸€æ¬¡ï¼Œè®°å½•åˆå§‹çŠ¶æ€
        self._log_to_file(f"[æ£€æµ‹] ========== ä¿®å¤å‰æ£€æµ‹ï¼šè¯šä¿¡æ‰¿è¯ºå’Œæ‘˜è¦åˆ†é¡µç»“æœ ==========")
        pre_fix_diagnosis = self._diagnose_integrity_abstract_separation(final_doc)
        if pre_fix_diagnosis["has_page_break_between"]:
            self._log_to_file(f"[æ£€æµ‹] âœ… ä¿®å¤å‰å·²æœ‰åˆ†é¡µç¬¦ï¼Œæ— éœ€ä¿®å¤")
        else:
            self._log_to_file(f"[æ£€æµ‹] âŒ ä¿®å¤å‰æ²¡æœ‰åˆ†é¡µç¬¦ï¼Œéœ€è¦ä¿®å¤")
        
        # ç¡®ä¿è¯šä¿¡æ‰¿è¯ºå’Œæ‘˜è¦åˆ†å¼€åœ¨ä¸åŒé¡µï¼ˆåœ¨ç©ºç™½è¡Œåˆ é™¤ä¹‹å‰ï¼‰
        self._log_to_file(f"[ä¿®å¤] ========== å¼€å§‹ä¿®å¤ï¼šç¡®ä¿è¯šä¿¡æ‰¿è¯ºå’Œæ‘˜è¦åˆ†å¼€åœ¨ä¸åŒé¡µ ==========")
        separation_fixed = self._ensure_integrity_abstract_separation(final_doc)
        if separation_fixed:
            self._log_to_file(f"[ä¿®å¤] âœ… å·²ç¡®ä¿è¯šä¿¡æ‰¿è¯ºå’Œæ‘˜è¦åˆ†å¼€åœ¨ä¸åŒé¡µ")
            stats["integrity_abstract_separation_fixed"] = True
        else:
            self._log_to_file(f"[ä¿®å¤] âš ï¸ æœªè¿›è¡Œä¿®å¤ï¼ˆå¯èƒ½å·²æœ‰åˆ†é¡µç¬¦æˆ–æœªæ‰¾åˆ°è¯šä¿¡æ‰¿è¯º/æ‘˜è¦ï¼‰")
        
        # ä¿®å¤åå†æ¬¡æ£€æµ‹ï¼Œç¡®è®¤åˆ†é¡µç»“æœ
        self._log_to_file(f"[æ£€æµ‹] ========== ä¿®å¤åæ£€æµ‹ï¼šè¯šä¿¡æ‰¿è¯ºå’Œæ‘˜è¦åˆ†é¡µç»“æœ ==========")
        post_fix_diagnosis = self._diagnose_integrity_abstract_separation(final_doc)
        if post_fix_diagnosis["has_page_break_between"]:
            self._log_to_file(f"[æ£€æµ‹] âœ… ä¿®å¤æˆåŠŸï¼šè¯šä¿¡æ‰¿è¯ºå’Œæ‘˜è¦å·²åˆ†å¼€åœ¨ä¸åŒé¡µ")
            self._log_to_file(f"[æ£€æµ‹] åˆ†é¡µç¬¦ä½ç½®: {len(post_fix_diagnosis['page_break_locations'])} ä¸ª")
            for loc in post_fix_diagnosis['page_break_locations']:
                self._log_to_file(f"[æ£€æµ‹]   - æ®µè½ {loc['index']}: {loc['type']}")
            stats["post_fix_separation_status"] = "å·²åˆ†å¼€"
        else:
            self._log_to_file(f"[æ£€æµ‹] âŒ ä¿®å¤å¤±è´¥ï¼šè¯šä¿¡æ‰¿è¯ºå’Œæ‘˜è¦ä»ç„¶æ²¡æœ‰åˆ†é¡µç¬¦")
            self._log_to_file(f"[æ£€æµ‹] é—®é¢˜: {post_fix_diagnosis.get('issue', 'æœªçŸ¥')}")
            stats["post_fix_separation_status"] = "æœªåˆ†å¼€"
        stats["post_fix_diagnosis"] = post_fix_diagnosis
        
        # ç¡®ä¿ä¸­æ–‡æ‘˜è¦å’Œè‹±æ–‡æ‘˜è¦åˆ†å¼€åœ¨ä¸åŒé¡µ
        self._log_to_file(f"[ä¿®å¤] ========== å¼€å§‹ä¿®å¤ï¼šç¡®ä¿ä¸­æ–‡æ‘˜è¦å’Œè‹±æ–‡æ‘˜è¦åˆ†å¼€åœ¨ä¸åŒé¡µ ==========")
        abstract_separation_fixed = self._ensure_abstract_separation(final_doc)
        if abstract_separation_fixed:
            self._log_to_file(f"[ä¿®å¤] âœ… å·²ç¡®ä¿ä¸­æ–‡æ‘˜è¦å’Œè‹±æ–‡æ‘˜è¦åˆ†å¼€åœ¨ä¸åŒé¡µ")
            stats["abstract_separation_fixed"] = True
        
        # æ£€æµ‹å¤§æ®µç©ºç™½
        blank_issues = self._check_excessive_blanks(final_doc)
        if blank_issues:
            stats["blank_issues"] = blank_issues
        
        # æ£€æµ‹å¹¶åˆ é™¤æ•´é¡µç©ºç™½é¡µï¼ˆä¸å…è®¸æ•´é¡µç©ºç™½ï¼‰
        blank_page_issues = self._check_and_remove_blank_pages(final_doc)
        if blank_page_issues:
            stats["blank_page_issues"] = blank_page_issues
        
        # æ£€æµ‹é¡µçœ‰
        header_issues = self._check_header(final_doc)
        if header_issues:
            stats["header_issues"] = header_issues

        final_path = task_dir / "final.docx"
        final_doc.save(final_path)

        # è¯Šæ–­2ï¼šæ£€æŸ¥æ ¼å¼ä¿®æ”¹åçš„æ–‡æ¡£ä¸­è¯šä¿¡æ‰¿è¯ºå’Œæ‘˜è¦çš„åˆ†é¡µæƒ…å†µ
        self._log_to_file(f"[è¯Šæ–­] ========== å¼€å§‹è¯Šæ–­ï¼šæ ¼å¼ä¿®æ”¹åçš„æ–‡æ¡£ ==========")
        final_diagnosis = self._diagnose_integrity_abstract_separation(final_doc)
        self._log_to_file(f"[è¯Šæ–­] æ ¼å¼ä¿®æ”¹åè¯Šæ–­ç»“æœ: {final_diagnosis['issue'] if final_diagnosis['issue'] else 'æœ‰åˆ†é¡µç¬¦'}")
        self._log_to_file(f"[è¯Šæ–­] åˆ†é¡µç¬¦ä½ç½®: {len(final_diagnosis['page_break_locations'])} ä¸ª")
        
        # å¯¹æ¯”è¯Šæ–­ç»“æœ
        if original_diagnosis["has_page_break_between"] and not final_diagnosis["has_page_break_between"]:
            self._log_to_file(f"[è¯Šæ–­] âš ï¸ è­¦å‘Šï¼šæ ¼å¼ä¿®æ”¹è¿‡ç¨‹ä¸­ä¸¢å¤±äº†åˆ†é¡µç¬¦ï¼")
            stats["diagnosis_warning"] = "æ ¼å¼ä¿®æ”¹è¿‡ç¨‹ä¸­ä¸¢å¤±äº†è¯šä¿¡æ‰¿è¯ºå’Œæ‘˜è¦ä¹‹é—´çš„åˆ†é¡µç¬¦"
        elif not original_diagnosis["has_page_break_between"]:
            self._log_to_file(f"[è¯Šæ–­] âš ï¸ è­¦å‘Šï¼šåŸå§‹æ–‡æ¡£ä¸­å°±æ²¡æœ‰åˆ†é¡µç¬¦ï¼")
            stats["diagnosis_warning"] = "åŸå§‹æ–‡æ¡£ä¸­è¯šä¿¡æ‰¿è¯ºå’Œæ‘˜è¦ä¹‹é—´æ²¡æœ‰åˆ†é¡µç¬¦"
        
        stats["original_diagnosis"] = original_diagnosis
        stats["final_diagnosis"] = final_diagnosis

        # éªŒè¯æ ¼å¼ä¿®æ”¹æ˜¯å¦æ­£ç¡®ï¼šå¯¹æ¯”åŸå§‹æ–‡æ¡£å’Œä¿®æ”¹åçš„æ–‡æ¡£
        print(f"[æ ¼å¼éªŒè¯] å¼€å§‹éªŒè¯æ ¼å¼ä¿®æ”¹æ˜¯å¦æ­£ç¡®...")
        format_verification = self._verify_format_changes(original_path, final_path, merged_rules)
        stats["format_verification"] = format_verification
        
        # è¾“å‡ºæ ¼å¼éªŒè¯ç»“æœ
        if format_verification.get("errors"):
            print(f"[æ ¼å¼éªŒè¯] âš ï¸ å‘ç° {len(format_verification['errors'])} ä¸ªæ ¼å¼é—®é¢˜ï¼š")
            for error in format_verification["errors"][:10]:  # åªæ˜¾ç¤ºå‰10ä¸ª
                print(f"[æ ¼å¼éªŒè¯]   - {error}")
        else:
            print(f"[æ ¼å¼éªŒè¯] âœ… æ ¼å¼éªŒè¯é€šè¿‡ï¼Œæ‰€æœ‰æ ¼å¼ä¿®æ”¹æ­£ç¡®")
        
        if format_verification.get("summary"):
            print(f"[æ ¼å¼éªŒè¯] æ ¼å¼ä¿®æ”¹æ‘˜è¦ï¼š")
            for key, value in format_verification["summary"].items():
                print(f"[æ ¼å¼éªŒè¯]   - {key}: {value}")

        preview_path = task_dir / "preview.docx"
        self._generate_watermarked_preview(final_path, preview_path)
        
        # è¯Šæ–­3ï¼šæ£€æŸ¥é¢„è§ˆæ–‡æ¡£ï¼ˆå¸¦æ°´å°çš„Wordæ–‡æ¡£ï¼‰ä¸­è¯šä¿¡æ‰¿è¯ºå’Œæ‘˜è¦çš„åˆ†é¡µæƒ…å†µ
        self._log_to_file(f"[è¯Šæ–­] ========== å¼€å§‹è¯Šæ–­ï¼šé¢„è§ˆæ–‡æ¡£ï¼ˆå¸¦æ°´å°ï¼‰ ==========")
        preview_doc = Document(preview_path)
        preview_diagnosis = self._diagnose_integrity_abstract_separation(preview_doc)
        self._log_to_file(f"[è¯Šæ–­] é¢„è§ˆæ–‡æ¡£è¯Šæ–­ç»“æœ: {preview_diagnosis['issue'] if preview_diagnosis['issue'] else 'æœ‰åˆ†é¡µç¬¦'}")
        self._log_to_file(f"[è¯Šæ–­] åˆ†é¡µç¬¦ä½ç½®: {len(preview_diagnosis['page_break_locations'])} ä¸ª")
        
        # å¯¹æ¯”è¯Šæ–­ç»“æœ
        if final_diagnosis["has_page_break_between"] and not preview_diagnosis["has_page_break_between"]:
            self._log_to_file(f"[è¯Šæ–­] âš ï¸ è­¦å‘Šï¼šç”Ÿæˆé¢„è§ˆæ–‡æ¡£è¿‡ç¨‹ä¸­ä¸¢å¤±äº†åˆ†é¡µç¬¦ï¼")
            stats["diagnosis_warning"] = "ç”Ÿæˆé¢„è§ˆæ–‡æ¡£è¿‡ç¨‹ä¸­ä¸¢å¤±äº†è¯šä¿¡æ‰¿è¯ºå’Œæ‘˜è¦ä¹‹é—´çš„åˆ†é¡µç¬¦"
        stats["preview_diagnosis"] = preview_diagnosis
        
        # ç”ŸæˆPDFé¢„è§ˆï¼ˆä¼˜å…ˆä½¿ç”¨LibreOfficeç›´æ¥è½¬æ¢ï¼Œä¿æŒæ ¼å¼å®Œå…¨ä¸€è‡´ï¼‰
        # é¢„è§ˆPDF = ä¿®æ”¹åçš„æ–‡æ¡£ + æ°´å°ï¼Œæ ¼å¼ä¸æœ€ç»ˆæ–‡æ¡£å®Œå…¨ä¸€è‡´ï¼Œä»…æ ¼å¼ä¸ºPDF
        pdf_path = preview_path.with_suffix('.pdf')
        print(f"[é¢„è§ˆ] å¼€å§‹ç”ŸæˆPDFé¢„è§ˆ: {pdf_path}")
        print(f"[é¢„è§ˆ] é¢„è§ˆç­–ç•¥ï¼šç›´æ¥ä»Wordè½¬PDFï¼ˆä½¿ç”¨LibreOfficeï¼‰ï¼Œä¿æŒæ ¼å¼å®Œå…¨ä¸€è‡´ï¼Œä»…æ·»åŠ æ°´å°")
        # åˆå§‹åŒ– html_pathï¼Œç¡®ä¿åœ¨æ‰€æœ‰æƒ…å†µä¸‹éƒ½æœ‰å®šä¹‰
        html_path = preview_path.with_suffix('.html')
        
        # ä¼˜å…ˆä½¿ç”¨LibreOfficeç›´æ¥ä»Wordè½¬PDFï¼ˆæ ¼å¼å®Œç¾ï¼ŒåªåŠ æ°´å°ï¼Œä¸æœ€ç»ˆæ–‡æ¡£å®Œå…¨ä¸€è‡´ï¼‰
        # å…ˆç”Ÿæˆä¸´æ—¶PDFï¼Œç„¶åæ·»åŠ æ°´å°
        temp_pdf_path = pdf_path.with_suffix('.temp.pdf')
        pdf_success = self._try_libreoffice_pdf_conversion(preview_path, temp_pdf_path)
        
        # æ£€æµ‹5ï¼šPDFç”Ÿæˆåï¼Œæ£€æŸ¥PDFä¸­è¯šä¿¡æ‰¿è¯ºå’Œæ‘˜è¦çš„åˆ†é¡µç»“æœ
        if pdf_success and temp_pdf_path.exists():
            try:
                from pypdf import PdfReader
                pdf_reader = PdfReader(str(temp_pdf_path))
                pdf_page_count = len(pdf_reader.pages)
                self._log_to_file(f"[æ£€æµ‹] ========== PDFç”Ÿæˆåæ£€æµ‹ï¼šè¯šä¿¡æ‰¿è¯ºå’Œæ‘˜è¦åˆ†é¡µç»“æœ ==========")
                self._log_to_file(f"[æ£€æµ‹] PDFæ€»é¡µæ•°: {pdf_page_count}")
                
                # æ£€æŸ¥æ¯ä¸€é¡µï¼Œæ‰¾åˆ°è¯šä¿¡æ‰¿è¯ºå’Œæ‘˜è¦æ‰€åœ¨çš„é¡µé¢
                integrity_page = None
                abstract_page = None
                
                # æ£€æŸ¥å‰10é¡µï¼ˆé€šå¸¸è¯šä¿¡æ‰¿è¯ºå’Œæ‘˜è¦åœ¨å‰å‡ é¡µï¼Œä½†å¯èƒ½å› ä¸ºæ ¼å¼é—®é¢˜å»¶åï¼‰
                check_pages = min(10, pdf_page_count)
                self._log_to_file(f"[æ£€æµ‹] æ£€æŸ¥å‰ {check_pages} é¡µä»¥æŸ¥æ‰¾è¯šä¿¡æ‰¿è¯ºå’Œæ‘˜è¦")
                
                for page_num in range(check_pages):
                    try:
                        page_text = pdf_reader.pages[page_num].extract_text()
                        # è°ƒè¯•ï¼šè¾“å‡ºæ¯é¡µçš„å‰100ä¸ªå­—ç¬¦ï¼ˆç”¨äºæ’æŸ¥ï¼‰
                        if page_num < 5:  # åªè¾“å‡ºå‰5é¡µçš„è°ƒè¯•ä¿¡æ¯
                            preview_text = page_text[:100].replace('\n', ' ').strip()
                            self._log_to_file(f"[æ£€æµ‹] ç¬¬ {page_num + 1} é¡µæ–‡æœ¬é¢„è§ˆ: {preview_text}...")
                        
                        # æ£€æŸ¥æ˜¯å¦åŒ…å«è¯šä¿¡æ‰¿è¯ºï¼ˆæ”¯æŒå¤šç§å˜ä½“ï¼‰
                        has_integrity = (
                            'è¯šä¿¡æ‰¿è¯º' in page_text or 
                            ('è¯š' in page_text and 'ä¿¡' in page_text and 'æ‰¿' in page_text and 'è¯º' in page_text) or
                            'è¯šä¿¡' in page_text and 'æ‰¿è¯º' in page_text
                        )
                        
                        # æ£€æŸ¥æ˜¯å¦åŒ…å«æ‘˜è¦ï¼ˆæ”¯æŒå¤šç§å˜ä½“ï¼‰
                        has_abstract = (
                            'æ‘˜è¦' in page_text or
                            'ABSTRACT' in page_text.upper() or
                            ('æ‘˜' in page_text and 'è¦' in page_text)
                        )
                        
                        if has_integrity and integrity_page is None:
                            integrity_page = page_num + 1
                            self._log_to_file(f"[æ£€æµ‹] âœ… ç¬¬ {page_num + 1} é¡µåŒ…å«è¯šä¿¡æ‰¿è¯º")
                        if has_abstract and abstract_page is None:
                            abstract_page = page_num + 1
                            self._log_to_file(f"[æ£€æµ‹] âœ… ç¬¬ {page_num + 1} é¡µåŒ…å«æ‘˜è¦")
                    except Exception as e:
                        self._log_to_file(f"[æ£€æµ‹] âŒ æ— æ³•æå–ç¬¬ {page_num + 1} é¡µæ–‡æœ¬: {e}")
                
                # åˆ¤æ–­ç»“æœå¹¶è¾“å‡º
                self._log_to_file(f"[æ£€æµ‹] ========== PDFåˆ†é¡µç»“æœ ==========")
                # å§‹ç»ˆè¾“å‡ºé¡µç ä¿¡æ¯ï¼ˆå¦‚æœæ‰¾åˆ°ï¼‰
                if integrity_page is not None:
                    self._log_to_file(f"[æ£€æµ‹] ğŸ“„ è¯šä¿¡æ‰¿è¯ºæ‰€åœ¨é¡µç : ç¬¬ {integrity_page} é¡µ")
                    stats["pdf_integrity_page"] = integrity_page
                if abstract_page is not None:
                    self._log_to_file(f"[æ£€æµ‹] ğŸ“„ æ‘˜è¦æ‰€åœ¨é¡µç : ç¬¬ {abstract_page} é¡µ")
                    stats["pdf_abstract_page"] = abstract_page
                
                # åˆ¤æ–­åˆ†é¡µæƒ…å†µ
                if integrity_page is not None and abstract_page is not None:
                    if integrity_page == abstract_page:
                        self._log_to_file(f"[æ£€æµ‹] âŒ PDFä¸­è¯šä¿¡æ‰¿è¯ºå’Œæ‘˜è¦åœ¨åŒä¸€é¡µï¼ˆç¬¬ {integrity_page} é¡µï¼‰")
                        self._log_to_file(f"[æ£€æµ‹] âš ï¸ è­¦å‘Šï¼šWordè½¬PDFè¿‡ç¨‹ä¸­åˆ†é¡µç¬¦å¯èƒ½å¤±æ•ˆ")
                        stats["pdf_separation_status"] = "åˆå¹¶åœ¨åŒä¸€é¡µ"
                        stats["pdf_separation_warning"] = f"PDFä¸­è¯šä¿¡æ‰¿è¯ºå’Œæ‘˜è¦åœ¨åŒä¸€é¡µï¼ˆç¬¬ {integrity_page} é¡µï¼‰ï¼ŒWordè½¬PDFè¿‡ç¨‹ä¸­åˆ†é¡µç¬¦å¯èƒ½å¤±æ•ˆ"
                    else:
                        self._log_to_file(f"[æ£€æµ‹] âœ… PDFä¸­è¯šä¿¡æ‰¿è¯ºå’Œæ‘˜è¦åˆ†å¼€åœ¨ä¸åŒé¡µ")
                        self._log_to_file(f"[æ£€æµ‹] ğŸ“Š é¡µç å¯¹æ¯”: è¯šä¿¡æ‰¿è¯º(ç¬¬ {integrity_page} é¡µ) vs æ‘˜è¦(ç¬¬ {abstract_page} é¡µ)")
                        stats["pdf_separation_status"] = "å·²åˆ†å¼€"
                        stats["pdf_separation_pages"] = {"integrity": integrity_page, "abstract": abstract_page}
                elif integrity_page is not None:
                    self._log_to_file(f"[æ£€æµ‹] âš ï¸ æ‰¾åˆ°è¯šä¿¡æ‰¿è¯ºï¼ˆç¬¬ {integrity_page} é¡µï¼‰ï¼Œä½†æœªæ‰¾åˆ°æ‘˜è¦")
                    stats["pdf_separation_status"] = "æœªæ‰¾åˆ°æ‘˜è¦"
                elif abstract_page is not None:
                    self._log_to_file(f"[æ£€æµ‹] âš ï¸ æ‰¾åˆ°æ‘˜è¦ï¼ˆç¬¬ {abstract_page} é¡µï¼‰ï¼Œä½†æœªæ‰¾åˆ°è¯šä¿¡æ‰¿è¯º")
                    stats["pdf_separation_status"] = "æœªæ‰¾åˆ°è¯šä¿¡æ‰¿è¯º"
                else:
                    self._log_to_file(f"[æ£€æµ‹] âš ï¸ æœªæ‰¾åˆ°è¯šä¿¡æ‰¿è¯ºå’Œæ‘˜è¦")
                    stats["pdf_separation_status"] = "æœªæ‰¾åˆ°"
                self._log_to_file(f"[æ£€æµ‹] ========================================")
                    
            except Exception as e:
                self._log_to_file(f"[æ£€æµ‹] âŒ æ— æ³•è¯»å–PDF: {e}")
                stats["pdf_separation_status"] = "æ£€æµ‹å¤±è´¥"
        
        # å¦‚æœLibreOfficeè½¬æ¢å¤±è´¥ï¼Œå›é€€åˆ°HTMLè½¬PDFï¼ˆä¸æ¨èï¼Œæ ¼å¼ä¼šæœ‰å˜åŒ–ï¼‰
        if not pdf_success:
            print(f"[é¢„è§ˆ] âš ï¸ LibreOfficeè½¬æ¢å¤±è´¥ï¼Œå›é€€åˆ°HTMLè½¬PDFï¼ˆæ ¼å¼å¯èƒ½æœ‰å˜åŒ–ï¼Œä¸æ¨èï¼‰")
            pdf_success = self._generate_pdf_preview(preview_path, temp_pdf_path, stats)
        
        if pdf_success and temp_pdf_path.exists():
            # ä¸ºé¢„è§ˆPDFæ·»åŠ æ°´å°ï¼ˆç¡®ä¿å…è´¹ç”¨æˆ·åªèƒ½çœ‹åˆ°å¸¦æ°´å°çš„PDFï¼‰
            print(f"[é¢„è§ˆ] ä¸ºé¢„è§ˆPDFæ·»åŠ æ°´å°...")
            watermark_success = self._add_pdf_watermarks(
                pdf_path=temp_pdf_path,
                output_path=pdf_path,
                watermark_text="www.geshixiugai.cn",
                watermarks_per_page=10
            )
            
            if watermark_success and pdf_path.exists():
                pdf_size = pdf_path.stat().st_size
                print(f"[é¢„è§ˆ] âœ… PDFé¢„è§ˆç”ŸæˆæˆåŠŸï¼ˆå·²æ·»åŠ æ°´å°ï¼‰: {pdf_path}, å¤§å°: {pdf_size / 1024:.2f} KB")
                # åˆ é™¤ä¸´æ—¶PDFæ–‡ä»¶
                if temp_pdf_path.exists():
                    temp_pdf_path.unlink()
            else:
                print(f"[é¢„è§ˆ] âš ï¸ æ°´å°æ·»åŠ å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹PDF")
                if temp_pdf_path.exists():
                    # å¦‚æœæ°´å°æ·»åŠ å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹PDFï¼ˆä½†åº”è¯¥ç¡®ä¿åŸå§‹PDFä¹Ÿæœ‰æ°´å°ï¼‰
                    temp_pdf_path.rename(pdf_path)
                pdf_success = True
        elif pdf_success:
            print(f"[é¢„è§ˆ] âš ï¸ PDFç”Ÿæˆè¿”å›æˆåŠŸä½†æ–‡ä»¶ä¸å­˜åœ¨: {temp_pdf_path}")
            pdf_success = False
        
        if not pdf_success:
            # å›é€€åˆ°HTMLé¢„è§ˆ
            print(f"[é¢„è§ˆ] PDFç”Ÿæˆå¤±è´¥ï¼Œå›é€€åˆ°HTMLé¢„è§ˆ")
            self._generate_html_preview(preview_path, html_path, stats)
            if html_path.exists():
                html_size = html_path.stat().st_size
                print(f"[é¢„è§ˆ] HTMLé¢„è§ˆç”ŸæˆæˆåŠŸ: {html_path}, å¤§å°: {html_size / 1024:.2f} KB")
            else:
                print(f"[é¢„è§ˆ] âš ï¸ HTMLé¢„è§ˆç”Ÿæˆå¤±è´¥ï¼Œæ–‡ä»¶ä¸å­˜åœ¨: {html_path}")

        report_data = {
            "document_id": document_id,
            "template_id": template_id,
            "summary": stats,
        }

        report_path = task_dir / "report.json"
        report_path.write_text(json.dumps(report_data, ensure_ascii=False, indent=2), encoding="utf-8")

        # å¦‚æœä½¿ç”¨äº‘å­˜å‚¨ï¼Œå°†æ–‡ä»¶ä¸Šä¼ åˆ°äº‘å­˜å‚¨
        if self.use_storage:
            files_to_save = {
                "original": original_path,
                "final": final_path,
                "preview": preview_path,
                "report": report_path,
            }
            # æ·»åŠ PDFæˆ–HTMLé¢„è§ˆæ–‡ä»¶
            # æ³¨æ„ï¼špdf_path å’Œ html_path å·²ç»åœ¨ä¸Šé¢å®šä¹‰è¿‡äº†
            if pdf_path.exists():
                pdf_size = pdf_path.stat().st_size
                print(f"[å­˜å‚¨] å‡†å¤‡ä¸Šä¼ PDFé¢„è§ˆæ–‡ä»¶: {pdf_path}, å¤§å°: {pdf_size / 1024:.2f} KB")
                files_to_save["pdf"] = pdf_path
            else:
                print(f"[å­˜å‚¨] PDFæ–‡ä»¶ä¸å­˜åœ¨ï¼Œæ£€æŸ¥HTMLæ–‡ä»¶")
                # html_path å·²ç»åœ¨ä¸Šé¢å®šä¹‰è¿‡äº†ï¼Œç›´æ¥ä½¿ç”¨
                if html_path.exists():
                    html_size = html_path.stat().st_size
                    print(f"[å­˜å‚¨] å‡†å¤‡ä¸Šä¼ HTMLé¢„è§ˆæ–‡ä»¶: {html_path}, å¤§å°: {html_size / 1024:.2f} KB")
                    files_to_save["html"] = html_path
                else:
                    print(f"[å­˜å‚¨] âš ï¸ è­¦å‘Š: PDFå’ŒHTMLé¢„è§ˆæ–‡ä»¶éƒ½ä¸å­˜åœ¨ï¼")
            
            self._save_to_storage(document_id, files_to_save)

        # ç¡®ä¿ template_id ä¸ä¸º Noneï¼ˆå¦‚æœä½¿ç”¨ university_idï¼Œåˆ™ä½¿ç”¨ university_id ä½œä¸ºæ ‡è¯†ï¼‰
        final_template_id = template_id if template_id else (f"university_{university_id}" if university_id else "unknown")
        
        metadata = {
            "document_id": document_id,
            "template_id": final_template_id,
            "status": "completed",
            "paid": False,
            "download_token": download_token,  # ä¸‹è½½éªŒè¯ token
            "original_filename": original_filename,  # ä¿å­˜åŸå§‹æ–‡ä»¶å
            "summary": stats,
            "report_path": str(report_path),
            "preview_path": str(preview_path),
            "preview_html_path": str(html_path),
            "final_path": str(final_path),
            "created_at": datetime.utcnow().isoformat(),
            "updated_at": datetime.utcnow().isoformat(),
        }

        metadata_path = task_dir / "metadata.json"
        metadata_path.write_text(json.dumps(metadata, ensure_ascii=False, indent=2), encoding="utf-8")
        
        # å¦‚æœä½¿ç”¨äº‘å­˜å‚¨ï¼Œä¹Ÿä¸Šä¼  metadata
        if self.use_storage:
            self._save_file_to_storage(f"documents/{document_id}/metadata.json", metadata_path.read_bytes())
        
        return document_id, stats

    def get_document_metadata(self, document_id: str) -> Dict:
        # ä¼˜å…ˆä»äº‘å­˜å‚¨è¯»å–
        if self.use_storage:
            metadata_key = f"documents/{document_id}/metadata.json"
            if self.storage.file_exists(metadata_key):
                content = self.storage.download_file(metadata_key)
                if content:
                    return json.loads(content.decode("utf-8"))
        
        # å›é€€åˆ°æœ¬åœ°æ–‡ä»¶ç³»ç»Ÿ
        metadata_path = self.document_dir / document_id / "metadata.json"
        if not metadata_path.exists():
            return {}
        return json.loads(metadata_path.read_text(encoding="utf-8"))

    def update_metadata(self, document_id: str, **kwargs) -> Dict:
        # å…ˆåŠ è½½ metadataï¼ˆä¼˜å…ˆä»å­˜å‚¨ï¼‰
        data = self.get_document_metadata(document_id)
        if not data:
            raise FileNotFoundError("metadata not found")
        
        # æ›´æ–°æ•°æ®
        data.update(kwargs)
        data["updated_at"] = datetime.utcnow().isoformat()
        
        # ä¿å­˜åˆ°æœ¬åœ°å’Œå­˜å‚¨
        task_dir = self.document_dir / document_id
        task_dir.mkdir(parents=True, exist_ok=True)
        metadata_path = task_dir / "metadata.json"
        metadata_path.write_text(json.dumps(data, ensure_ascii=False, indent=2), encoding="utf-8")
        
        # å¦‚æœä½¿ç”¨äº‘å­˜å‚¨ï¼Œä¹Ÿæ›´æ–°å­˜å‚¨ä¸­çš„ metadata
        if self.use_storage:
            metadata_key = f"documents/{document_id}/metadata.json"
            content = json.dumps(data, ensure_ascii=False, indent=2).encode("utf-8")
            self._save_file_to_storage(metadata_key, content)
        
        return data

    def _load_template(self, template_id: str) -> Dict:
        """åŠ è½½ç”¨æˆ·ä¸Šä¼ çš„è‡ªå®šä¹‰æ¨¡æ¿"""
        metadata_path = self.template_dir / template_id / "metadata.json"
        if not metadata_path.exists():
            raise FileNotFoundError("template not found")
        return json.loads(metadata_path.read_text(encoding="utf-8"))
    
    def _load_university_template(self, university_id: str) -> Dict:
        """åŠ è½½é¢„è®¾å¤§å­¦æ¨¡æ¿"""
        from .university_template_service import UniversityTemplateService
        
        service = UniversityTemplateService()
        template = service.get_university_template(university_id)
        if not template:
            raise FileNotFoundError(f"æœªæ‰¾åˆ°å¤§å­¦æ¨¡æ¿: {university_id}")
        
        # å°†é¢„è®¾æ¨¡æ¿è½¬æ¢ä¸ºä¸è‡ªå®šä¹‰æ¨¡æ¿ç›¸åŒçš„æ ¼å¼
        parameters = template.get("parameters", {})
        
        # æ„å»ºæ¨¡æ¿å…ƒæ•°æ®æ ¼å¼
        metadata = {
            "template_id": f"university_{university_id}",
            "name": template.get("display_name", template.get("name")),
            "university_id": university_id,
            "styles": {},  # é¢„è®¾æ¨¡æ¿ä¸ä½¿ç”¨ stylesï¼Œè€Œæ˜¯ä½¿ç”¨ parameters
            "parameters": parameters,  # é¢„è®¾æ¨¡æ¿çš„å‚æ•°
            "default_style": "body_text",
        }
        
        return metadata

    def _paragraph_has_image_or_equation(self, paragraph) -> bool:
        """åˆ¤æ–­æ®µè½æ˜¯å¦åŒ…å«å›¾ç‰‡æˆ–å…¬å¼"""
        # æ£€æŸ¥æ˜¯å¦åŒ…å«å›¾ç‰‡
        has_image = False
        try:
            # æ–¹æ³•1: æ£€æŸ¥æ®µè½ä¸­çš„runsæ˜¯å¦åŒ…å«å›¾ç‰‡
            for run in paragraph.runs:
                if not hasattr(run, 'element'):
                    continue
                run_xml = str(run.element.xml)
                # æ’é™¤VMLå½¢çŠ¶çš„æ°´å°
                if 'v:shape' in run_xml.lower() and 'textpath' in run_xml.lower():
                    continue
                # æ£€æŸ¥æ˜¯å¦åŒ…å«çœŸæ­£çš„å›¾ç‰‡å…ƒç´ 
                if ('pic:pic' in run_xml or 'a:blip' in run_xml) and ('r:embed' in run_xml or 'r:link' in run_xml or 'a:blip' in run_xml):
                    has_image = True
                    break
        except:
            pass
        
        # æ–¹æ³•2: æ£€æŸ¥æ®µè½å…ƒç´ ä¸­æ˜¯å¦åŒ…å«å›¾ç‰‡
        if not has_image:
            try:
                para_xml = str(paragraph._element.xml)
                if 'v:shape' in para_xml.lower() and 'textpath' in para_xml.lower():
                    pass  # è¿™æ˜¯æ°´å°ï¼Œè·³è¿‡
                elif ('pic:pic' in para_xml or 'a:blip' in para_xml) and ('r:embed' in para_xml or 'r:link' in para_xml or 'a:blip' in para_xml):
                    has_image = True
            except:
                pass
        
        # æ–¹æ³•3: ä½¿ç”¨xpathæŸ¥æ‰¾drawingå…ƒç´ 
        if not has_image:
            try:
                from docx.oxml.ns import qn
                # ä½¿ç”¨findallé…åˆqnï¼Œè€Œä¸æ˜¯xpath with namespaces
                drawings = paragraph._element.findall('.//' + qn('w:drawing'))
                if drawings:
                    for drawing in drawings:
                        drawing_xml = str(drawing.xml)
                        if 'v:shape' in drawing_xml.lower() and 'textpath' in drawing_xml.lower():
                            continue
                        if ('pic:pic' in drawing_xml or 'a:blip' in drawing_xml) and ('r:embed' in drawing_xml or 'r:link' in drawing_xml or 'a:blip' in drawing_xml):
                            has_image = True
                            break
            except:
                pass
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«å…¬å¼ï¼ˆOffice Math æˆ– MathTypeï¼‰
        has_equation = False
        try:
            para_xml = str(paragraph._element.xml)
            # æ£€æŸ¥Office Math (oMath)
            if 'm:oMath' in para_xml or 'm:oMathPara' in para_xml:
                has_equation = True
            # æ£€æŸ¥MathTypeå…¬å¼ï¼ˆé€šå¸¸åŒ…å«objectæ ‡ç­¾ï¼‰
            elif 'object' in para_xml.lower() and ('mathtype' in para_xml.lower() or 'equation' in para_xml.lower()):
                has_equation = True
            # æ£€æŸ¥æ®µè½ä¸­çš„runsæ˜¯å¦åŒ…å«å…¬å¼
            if not has_equation:
                for run in paragraph.runs:
                    if not hasattr(run, 'element'):
                        continue
                    run_xml = str(run.element.xml)
                    if 'm:oMath' in run_xml or 'm:oMathPara' in run_xml:
                        has_equation = True
                        break
        except:
            pass
        
        return has_image or has_equation
    
    def _paragraph_has_flowchart(self, paragraph) -> bool:
        """åˆ¤æ–­æ®µè½æ˜¯å¦åŒ…å«æµç¨‹å›¾ï¼ˆç”±å¤šä¸ªå½¢çŠ¶ç»„æˆçš„æµç¨‹å›¾ï¼‰"""
        try:
            para_xml = str(paragraph._element.xml)
            
            # æ–¹æ³•1: æ£€æµ‹ Word Processing Shapes (wps:wsp) - ç°ä»£ Word æ–‡æ¡£ä¸­çš„å½¢çŠ¶
            # æµç¨‹å›¾é€šå¸¸åŒ…å«å¤šä¸ªå½¢çŠ¶ï¼Œå¦‚æœæ®µè½ä¸­æœ‰å¤šä¸ª wps:wsp å…ƒç´ ï¼Œå¯èƒ½æ˜¯æµç¨‹å›¾
            if 'wps:wsp' in para_xml:
                # è®¡ç®—å½¢çŠ¶æ•°é‡
                shape_count = para_xml.count('wps:wsp')
                # å¦‚æœåŒ…å«å¤šä¸ªå½¢çŠ¶ï¼ˆè‡³å°‘2ä¸ªï¼‰ï¼Œå¯èƒ½æ˜¯æµç¨‹å›¾
                if shape_count >= 2:
                    return True
            
            # æ–¹æ³•2: æ£€æµ‹ VML Shapes (v:shape) - æ—§ç‰ˆ Word æ–‡æ¡£ä¸­çš„å½¢çŠ¶
            # æ’é™¤æ°´å°ï¼ˆåŒ…å« textpath çš„ v:shape é€šå¸¸æ˜¯æ°´å°ï¼‰
            vml_shapes = []
            if 'v:shape' in para_xml.lower():
                # æ£€æŸ¥æ˜¯å¦æœ‰å¤šä¸ªéæ°´å°çš„å½¢çŠ¶
                # ç®€å•åˆ¤æ–­ï¼šå¦‚æœåŒ…å« v:shape ä½†ä¸åŒ…å« textpathï¼Œå¯èƒ½æ˜¯æµç¨‹å›¾çš„ä¸€éƒ¨åˆ†
                vml_count = para_xml.lower().count('v:shape')
                textpath_count = para_xml.lower().count('textpath')
                # å¦‚æœæœ‰å½¢çŠ¶ä¸”ä¸æ˜¯æ°´å°ï¼Œå¯èƒ½æ˜¯æµç¨‹å›¾
                if vml_count > textpath_count and vml_count >= 2:
                    return True
            
            # æ–¹æ³•3: æ£€æµ‹ SmartArt æµç¨‹å›¾
            # SmartArt åœ¨ XML ä¸­é€šå¸¸åŒ…å« 'smartart' æˆ–ç‰¹å®šçš„å‘½åç©ºé—´
            if 'smartart' in para_xml.lower() or 'dgm:' in para_xml:
                return True
            
            # æ–¹æ³•4: æ£€æµ‹ drawing å…ƒç´ ä¸­çš„å¤šä¸ªå½¢çŠ¶
            # ä½¿ç”¨ findall æŸ¥æ‰¾ drawing å…ƒç´ ï¼Œæ£€æŸ¥æ˜¯å¦åŒ…å«å¤šä¸ªå½¢çŠ¶
            try:
                from docx.oxml.ns import qn
                drawings = paragraph._element.findall('.//' + qn('w:drawing'))
                if drawings:
                    # æ£€æŸ¥æ¯ä¸ª drawing å…ƒç´ ä¸­æ˜¯å¦åŒ…å«å¤šä¸ªå½¢çŠ¶
                    for drawing in drawings:
                        drawing_xml = str(drawing.xml)
                        # è®¡ç®—å½¢çŠ¶æ•°é‡
                        wps_count = drawing_xml.count('wps:wsp')
                        vml_count = drawing_xml.lower().count('v:shape') - drawing_xml.lower().count('textpath')
                        # å¦‚æœåŒ…å«å¤šä¸ªå½¢çŠ¶ï¼Œå¯èƒ½æ˜¯æµç¨‹å›¾
                        if wps_count >= 2 or (vml_count >= 2 and vml_count > 0):
                            return True
            except:
                pass
            
            # æ–¹æ³•5: æ£€æµ‹æ®µè½ä¸­çš„ runs æ˜¯å¦åŒ…å«å½¢çŠ¶
            try:
                shape_count = 0
                for run in paragraph.runs:
                    if not hasattr(run, 'element'):
                        continue
                    run_xml = str(run.element.xml)
                    # æ’é™¤æ°´å°
                    if 'v:shape' in run_xml.lower() and 'textpath' in run_xml.lower():
                        continue
                    # æ£€æŸ¥æ˜¯å¦åŒ…å«å½¢çŠ¶
                    if 'wps:wsp' in run_xml or ('v:shape' in run_xml.lower() and 'textpath' not in run_xml.lower()):
                        shape_count += 1
                # å¦‚æœåŒ…å«å¤šä¸ªå½¢çŠ¶ï¼Œå¯èƒ½æ˜¯æµç¨‹å›¾
                if shape_count >= 2:
                    return True
            except:
                pass
            
        except:
            pass
        
        return False

    def _apply_page_settings(self, document: Document) -> None:
        """åº”ç”¨é¡µé¢è®¾ç½®ï¼ˆé¡µè¾¹è·ç­‰ï¼‰ï¼Œä½†ä¸ä¿®æ”¹ä»»ä½•é¡µè¾¹è·ï¼Œä¿æŒæ–‡æ¡£åŸå§‹é¡µè¾¹è·"""
        # ä¸ä¿®æ”¹ä»»ä½• section çš„é¡µè¾¹è·ï¼Œä¿æŒæ–‡æ¡£åŸå§‹é¡µè¾¹è·
        # å°é¢é¡µå’Œåç»­é¡µé¢çš„é¡µè¾¹è·éƒ½ä¸ä¿®æ”¹
        pass
    
    def _check_header(self, document: Document) -> list:
        """æ£€æµ‹é¡µçœ‰æ˜¯å¦å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™æç¤ºæ·»åŠ """
        issues = []
        
        # æ£€æŸ¥æ‰€æœ‰èŠ‚çš„é¡µçœ‰
        has_header = False
        for section in document.sections:
            header = section.header
            # æ£€æŸ¥é¡µçœ‰æ˜¯å¦æœ‰å†…å®¹
            for para in header.paragraphs:
                if para.text and para.text.strip():
                    has_header = True
                    break
            if has_header:
                break
        
        # å¦‚æœæ²¡æœ‰ä»»ä½•é¡µçœ‰ï¼Œæ·»åŠ æç¤º
        if not has_header:
            issues.append({
                "type": "missing_header",
                "severity": "warning",
                "message": "æ–‡æ¡£ç¼ºå°‘é¡µçœ‰",
                "suggestion": f"è¯·åœ¨æ–‡æ¡£ä¸­æ·»åŠ é¡µçœ‰ï¼Œå»ºè®®å†…å®¹ï¼š{HEADER_SETTINGS['text']}"
            })
        
        return issues
    
    def _convert_university_params_to_rules(self, university_params: Dict) -> Dict[str, Dict]:
        """
        å°†é¢„è®¾å¤§å­¦æ¨¡æ¿çš„å‚æ•°è½¬æ¢ä¸ºæ ¼å¼è§„åˆ™
        
        Args:
            university_params: å¤§å­¦æ¨¡æ¿å‚æ•°å­—å…¸ï¼ŒåŒ…å« body_text, page_settings ç­‰
            
        Returns:
            æ ¼å¼è§„åˆ™å­—å…¸ï¼Œæ ¼å¼ä¸ FONT_STANDARDS ç›¸åŒ
        """
        rules = {}
        
        # å¤åˆ¶æ ‡å‡†è§„åˆ™ä½œä¸ºåŸºç¡€
        for style_name, style_config in FONT_STANDARDS.items():
            rules[style_name] = style_config.copy()
        
        # åº”ç”¨é¢„è®¾æ¨¡æ¿çš„å‚æ•°è¦†ç›–
        # ä¸»è¦è¦†ç›– body_text çš„è¡Œè·ç­‰å‚æ•°
        if "body_text" in university_params:
            body_params = university_params["body_text"]
            if "body_text" in rules:
                # è¦†ç›– body_text çš„å‚æ•°
                for key, value in body_params.items():
                    rules["body_text"][key] = value
        
        # å¦‚æœé¢„è®¾æ¨¡æ¿æœ‰å…¶ä»–æ ·å¼å‚æ•°ï¼Œä¹Ÿå¯ä»¥è¦†ç›–
        for style_name, style_params in university_params.items():
            if style_name != "body_text" and style_name != "page_settings":
                if style_name in rules:
                    for key, value in style_params.items():
                        rules[style_name][key] = value
        
        return rules
    
    def _merge_rules_with_standard(self, template_rules: Dict[str, Dict]) -> Dict[str, Dict]:
        """
        åˆå¹¶æ¨¡æ¿è§„åˆ™å’Œæ ‡å‡†è§„åˆ™
        ä¼˜å…ˆçº§ï¼šæ ‡å‡†è§„åˆ™ > æ¨¡æ¿è§„åˆ™
        å¦‚æœæ¨¡æ¿è§„åˆ™ä¸­æœ‰æ ‡å‡†è§„åˆ™æ²¡æœ‰çš„æ ·å¼ï¼Œä¿ç•™æ¨¡æ¿è§„åˆ™
        """
        merged = {}
        
        # é¦–å…ˆæ·»åŠ æ ‡å‡†è§„åˆ™
        for style_name, style_config in FONT_STANDARDS.items():
            merged[style_name] = style_config.copy()
        
        # ç„¶åæ·»åŠ æ¨¡æ¿è§„åˆ™ï¼ˆå¦‚æœæ¨¡æ¿è§„åˆ™ä¸­çš„æ ·å¼åä¸åœ¨æ ‡å‡†ä¸­ï¼Œåˆ™æ·»åŠ ï¼‰
        for style_name, style_config in template_rules.items():
            # å¦‚æœæ¨¡æ¿æ ·å¼åä¸åœ¨æ ‡å‡†ä¸­ï¼Œä¿ç•™æ¨¡æ¿æ ·å¼
            if style_name not in merged:
                merged[style_name] = style_config.copy()
            else:
                # å¦‚æœæ¨¡æ¿æ ·å¼åœ¨æ ‡å‡†ä¸­ï¼Œä½†æ ‡å‡†ä¸­æ²¡æœ‰æŸäº›å­—æ®µï¼Œåˆ™è¡¥å……æ¨¡æ¿çš„å­—æ®µ
                standard_style = merged[style_name]
                for key, value in style_config.items():
                    if key not in standard_style or standard_style[key] is None:
                        standard_style[key] = value
        
        return merged
    
    def _detect_paragraph_style(self, paragraph: Paragraph) -> str:
        """
        æ ¹æ®æ®µè½å†…å®¹è‡ªåŠ¨æ£€æµ‹åº”è¯¥åº”ç”¨çš„æ ·å¼
        è¿”å›æ ·å¼åç§°ï¼ˆå¯¹åº”FONT_STANDARDSä¸­çš„keyï¼‰
        """
        text = paragraph.text.strip() if paragraph.text else ""
        if not text:
            return DEFAULT_STYLE
        
        # ä¼˜å…ˆæ£€æµ‹ç‰¹æ®Šæ ‡é¢˜ï¼šæ‘˜è¦ã€ABSTRACTã€ç›®å½•ã€ç»ªè®ºã€æ¦‚è¿°
        # è¿™äº›æ ‡é¢˜éœ€è¦è®¾ç½®ä¸ºé»‘ä½“ã€ä¸‰å·å­—ã€åŠ ç²—ã€å±…ä¸­
        if text == "æ‘˜è¦" or text.startswith("æ‘˜è¦"):
            return "abstract_title"
        if text == "ABSTRACT" or text.startswith("ABSTRACT"):
            return "abstract_title_en"
        if text == "ç›®å½•" or text.startswith("ç›®å½•") or text == "Contents" or text.startswith("Contents"):
            return "toc_title"
        if text == "ç»ªè®º" or text == "æ¦‚è¿°" or text.startswith("1 ç»ªè®º") or text.startswith("1 æ¦‚è¿°"):
            # å¦‚æœæ˜¯ç‹¬ç«‹çš„"ç»ªè®º"æˆ–"æ¦‚è¿°"ï¼Œä¸”æ®µè½è¾ƒçŸ­ï¼Œåˆ™è®¤ä¸ºæ˜¯æ ‡é¢˜
            if len(text) < 50:
                return "title_level_1"
        
        # æ ¹æ®æ ·å¼æ˜ å°„è§„åˆ™æ£€æµ‹
        for rule in STYLE_MAPPING_RULES:
            if re.match(rule["pattern"], text, re.IGNORECASE):
                return rule["style"]
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯æ ‡é¢˜
        style_name = paragraph.style.name if paragraph.style else None
        if style_name:
            style_lower = style_name.lower()
            if "æ ‡é¢˜" in style_name or "heading" in style_lower:
                # æ ¹æ®æ ‡é¢˜çº§åˆ«åˆ¤æ–­
                if "1" in style_name or "ä¸€" in style_name or "heading 1" in style_lower:
                    return "title_level_1"
                elif "2" in style_name or "äºŒ" in style_name or "heading 2" in style_lower:
                    return "title_level_2"
                elif "3" in style_name or "ä¸‰" in style_name or "heading 3" in style_lower:
                    return "title_level_3"
        
        # æ£€æŸ¥æ®µè½å†…å®¹ç‰¹å¾
        if text.startswith("å›¾") and len(text) < 100:
            return "figure_caption"
        if text.startswith("è¡¨") and len(text) < 100:
            return "table_caption"
        
        # ç« èŠ‚æ ‡é¢˜æ£€æµ‹ï¼šå¿…é¡»æ˜¯ç‹¬ç«‹çš„ã€è¾ƒçŸ­çš„æ®µè½
        # é¿å…å°†æ­£æ–‡ä¸­çš„"ç¬¬äºŒç« çš„æ–¹æ¡ˆ"ç­‰è¯¯è¯†åˆ«ä¸ºæ ‡é¢˜
        # æ ‡é¢˜ä¸€èˆ¬ä¸ä¼šè¶…è¿‡ä¸€è¡Œï¼Œå­—æ•°ä¸ä¼šè¶…è¿‡30ä¸ª
        chapter_match = re.match(r"^(ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å\d]+ç« |ç¬¬\d+ç« |Chapter\s+\d+)([ï¼Œ,ã€‚.ï¼š:ï¼›;]?)$", text)
        if chapter_match:
            # å¦‚æœåŒ¹é…åˆ°ç« èŠ‚æ ‡é¢˜ï¼Œä¸”æ®µè½è¾ƒçŸ­ï¼ˆæ ‡é¢˜é€šå¸¸æ˜¯ç‹¬ç«‹çš„çŸ­æ®µè½ï¼Œä¸è¶…è¿‡30ä¸ªå­—ç¬¦ï¼‰
            # æˆ–è€…åé¢åªæœ‰æ ‡ç‚¹ç¬¦å·ï¼Œåˆ™è®¤ä¸ºæ˜¯æ ‡é¢˜
            # æ¢è¡Œä»¥åå°±æ˜¯æ–°çš„å†…å®¹äº†ï¼Œæ ‡é¢˜ä¸€èˆ¬ä¸ä¼šè¶…è¿‡ä¸€è¡Œ
            remaining_text = text[len(chapter_match.group(0)):].strip()
            if len(text) <= 30 and (len(remaining_text) == 0 or remaining_text in ["ï¼Œ", "ã€‚", "ï¼š", "ï¼›", ",", ".", ":", ";"]):
                return "title_level_1"
        
        # äºŒçº§æ ‡é¢˜æ£€æµ‹ï¼šæ ¼å¼ä¸º æ•°å­—.æ•°å­— æˆ– æ•°å­—.æ•°å­— åè·Ÿæ–‡å­—å†…å®¹
        # ä¾‹å¦‚ï¼š2.1ã€3.1ã€4.1 æˆ– 2.1 ç³»ç»Ÿè®¾è®¡ã€3.1 éœ€æ±‚åˆ†æ ç­‰
        # æ ‡é¢˜ä¸€èˆ¬ä¸ä¼šè¶…è¿‡ä¸€è¡Œï¼Œå­—æ•°ä¸ä¼šè¶…è¿‡50ä¸ª
        section_match = re.match(r"^(\d+\.\d+)(\s*[ï¼Œ,ã€‚.ï¼š:ï¼›;]?\s*)(.*)$", text)
        if section_match:
            # åŒ¹é…åˆ° æ•°å­—.æ•°å­— æ ¼å¼
            # å¦‚æœåé¢æœ‰æ–‡å­—å†…å®¹ï¼ˆå¦‚"2.1 ç³»ç»Ÿè®¾è®¡"ï¼‰ï¼Œä¹Ÿæ˜¯æ ‡é¢˜
            # å¦‚æœåé¢åªæœ‰æ ‡ç‚¹ç¬¦å·æˆ–ä¸ºç©ºï¼Œä¹Ÿæ˜¯æ ‡é¢˜
            remaining_text = section_match.group(3).strip() if section_match.group(3) else ""
            # æ ‡é¢˜é€šå¸¸ä¸ä¼šè¶…è¿‡50ä¸ªå­—ç¬¦ï¼Œä¸”æ®µè½è¾ƒçŸ­
            if len(text) <= 50:
                return "title_level_2"
        
        # ä¹Ÿæ”¯æŒ"ç¬¬XèŠ‚"æ ¼å¼çš„äºŒçº§æ ‡é¢˜
        section_chinese_match = re.match(r"^(ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å\d]+èŠ‚)([ï¼Œ,ã€‚.ï¼š:ï¼›;]?)$", text)
        if section_chinese_match:
            remaining_text = text[len(section_chinese_match.group(0)):].strip()
            if len(text) <= 30 and (len(remaining_text) == 0 or remaining_text in ["ï¼Œ", "ã€‚", "ï¼š", "ï¼›", ",", ".", ":", ";"]):
                return "title_level_2"
        
        # ä¸‰çº§æ ‡é¢˜æ£€æµ‹ï¼šå¿…é¡»æ˜¯ç‹¬ç«‹çš„ã€è¾ƒçŸ­çš„æ®µè½
        # æ ‡é¢˜æ ¼å¼ï¼šæ•°å­—.æ•°å­—.æ•°å­— æˆ– æ•°å­—.æ•°å­—.æ•°å­— åè·Ÿæ ‡ç‚¹ç¬¦å·ï¼Œä¸”åé¢æ²¡æœ‰å…¶ä»–æ–‡å­—å†…å®¹
        # æ ‡é¢˜ä¸€èˆ¬ä¸ä¼šè¶…è¿‡ä¸€è¡Œï¼Œå­—æ•°ä¸ä¼šè¶…è¿‡30ä¸ª
        subsection_match = re.match(r"^(\d+\.\d+\.\d+)([ï¼Œ,ã€‚.ï¼š:ï¼›;]?)$", text)
        if subsection_match:
            remaining_text = text[len(subsection_match.group(0)):].strip()
            # åªæœ‰å½“å‰©ä½™æ–‡æœ¬ä¸ºç©ºæˆ–åªæœ‰æ ‡ç‚¹ç¬¦å·æ—¶ï¼Œä¸”æ€»é•¿åº¦ä¸è¶…è¿‡30ä¸ªå­—ç¬¦ï¼Œæ‰è®¤ä¸ºæ˜¯æ ‡é¢˜
            # å¦‚æœåé¢è¿˜æœ‰æ–‡å­—å†…å®¹ï¼ˆå¦‚"3.2.4 12864 æ¶²æ™¶æ˜¾ç¤ºå±"ï¼‰ï¼Œåˆ™ä¸æ˜¯æ ‡é¢˜ï¼Œæ˜¯æ­£æ–‡
            # æ¢è¡Œä»¥åå°±æ˜¯æ–°çš„å†…å®¹äº†ï¼Œæ ‡é¢˜ä¸€èˆ¬ä¸ä¼šè¶…è¿‡ä¸€è¡Œ
            if len(text) <= 30 and (len(remaining_text) == 0 or remaining_text in ["ï¼Œ", "ã€‚", "ï¼š", "ï¼›", ",", ".", ":", ";"]):
                return "title_level_3"
        
        # é»˜è®¤è¿”å›æ­£æ–‡æ ·å¼
        return DEFAULT_STYLE

    def _find_cover_end_index(self, document: Document) -> int:
        """æ‰¾åˆ°å°é¢ç»“æŸçš„æ®µè½ç´¢å¼•ï¼Œè·³è¿‡å°é¢éƒ¨åˆ†"""
        # å°é¢çš„ç»“æŸæ ‡å¿—ï¼šé€šå¸¸æ˜¯"æ‘˜è¦"ã€"ç›®å½•"ã€"å¼•è¨€"ã€"ç¬¬ä¸€ç« "ç­‰
        cover_end_keywords = [
            "æ‘˜è¦", "ABSTRACT", "ç›®å½•", "Contents", 
            "å¼•è¨€", "ç»ªè®º", "å‰è¨€", "ç¬¬ä¸€ç« ", "ç¬¬1ç« ", "Chapter 1",
            "1 å¼•è¨€", "1 ç»ªè®º", "1 æ¦‚è¿°"
        ]
        
        # ä»å‰å¾€åæŸ¥æ‰¾ï¼Œæ‰¾åˆ°ç¬¬ä¸€ä¸ªå°é¢ç»“æŸæ ‡å¿—
        for idx, paragraph in enumerate(document.paragraphs):
            para_text = paragraph.text.strip() if paragraph.text else ""
            if not para_text:
                continue
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯å°é¢ç»“æŸæ ‡å¿—
            for keyword in cover_end_keywords:
                if para_text.startswith(keyword) or keyword in para_text:
                    # ç¡®ä¿ä¸æ˜¯å°é¢ä¸­çš„æ–‡å­—ï¼ˆå°é¢é€šå¸¸è¾ƒçŸ­ï¼‰
                    if len(para_text) < 200:  # å°é¢ä¸­çš„æ–‡å­—é€šå¸¸è¾ƒçŸ­
                        return idx
        
        # å¦‚æœæ‰¾ä¸åˆ°ï¼Œè·³è¿‡å‰20ä¸ªæ®µè½ï¼ˆé€šå¸¸æ˜¯å°é¢ï¼‰
        return min(20, len(document.paragraphs) - 1)
    
    def _find_section_ranges(self, document: Document) -> Dict[str, Tuple[int, int]]:
        """
        è¯†åˆ«æ–‡æ¡£å„ä¸ªéƒ¨åˆ†çš„æ®µè½èŒƒå›´
        è¿”å›: {
            "cover": (0, cover_end),  # å°é¢ï¼ˆç¬¬ä¸€é¡µï¼‰
            "integrity": (start, end),  # è¯šä¿¡æ‰¿è¯ºï¼ˆç¬¬äºŒé¡µï¼‰
            "abstract_zh": (start, end),  # ä¸­æ–‡æ‘˜è¦ï¼ˆç¬¬ä¸‰é¡µï¼‰
            "abstract_en": (start, end),  # è‹±æ–‡æ‘˜è¦
            "toc": (start, end),  # ç›®å½•
            "body": (start, end),  # æ­£æ–‡
        }
        """
        ranges = {}
        cover_end = self._find_cover_end_index(document)
        ranges["cover"] = (0, cover_end)
        
        integrity_start = None
        integrity_end = None
        abstract_zh_start = None
        abstract_zh_end = None
        abstract_en_start = None
        abstract_en_end = None
        toc_start = None
        toc_end = None
        body_start = None
        
        # æŸ¥æ‰¾è¯šä¿¡æ‰¿è¯ºï¼ˆé€šå¸¸åœ¨å°é¢ä¹‹åï¼Œæ‘˜è¦ä¹‹å‰ï¼Œç¬¬äºŒé¡µï¼‰
        # æ”¯æŒ"è¯šä¿¡æ‰¿è¯º"ä¸­é—´æœ‰ç©ºæ ¼çš„æƒ…å†µï¼Œå¦‚"è¯šä¿¡ æ‰¿è¯º"ã€"è¯š ä¿¡ æ‰¿ è¯º"ç­‰
        # æ³¨æ„ï¼šè¯šä¿¡æ‰¿è¯ºå¯èƒ½åœ¨å°é¢èŒƒå›´å†…ï¼Œæ‰€ä»¥ä»æ®µè½0å¼€å§‹æŸ¥æ‰¾
        integrity_pattern = re.compile(r'è¯š\s*ä¿¡\s*æ‰¿\s*è¯º', re.IGNORECASE)
        integrity_keywords = ["å­¦æœ¯è¯šä¿¡", "åŸåˆ›æ€§å£°æ˜", "åŸåˆ›å£°æ˜"]
        
        self._log_to_file(f"[ä¿®å¤] å¼€å§‹æŸ¥æ‰¾è¯šä¿¡æ‰¿è¯ºï¼Œä»æ®µè½ 0 å¼€å§‹ï¼ˆcover_end={cover_end}ï¼‰")
        # å…ˆåœ¨å‰50ä¸ªæ®µè½ä¸­æŸ¥æ‰¾ï¼ˆé€šå¸¸è¯šä¿¡æ‰¿è¯ºåœ¨å‰å‡ é¡µï¼‰
        search_range = min(50, len(document.paragraphs))
        
        # æ”¹è¿›çš„æŸ¥æ‰¾é€»è¾‘ï¼šå››ä¸ªå­—å¯ä»¥åˆ†æ•£åœ¨ä¸åŒæ®µè½ï¼Œä¸­é—´å¯ä»¥æœ‰ä»»æ„ç©ºæ ¼
        # å…ˆæ‰¾"è¯š"ï¼Œå†æ‰¾"ä¿¡"ï¼Œå†æ‰¾"æ‰¿"ï¼Œå†æ‰¾"è¯º"ï¼ŒæŒ‰é¡ºåºå‡ºç°å³å¯
        cheng_idx = None  # è¯š
        xin_idx = None    # ä¿¡
        cheng2_idx = None # æ‰¿
        nuo_idx = None    # è¯º
        
        for idx in range(0, search_range):
            para_text = document.paragraphs[idx].text.strip() if document.paragraphs[idx].text else ""
            if not para_text:
                continue
            
            # è°ƒè¯•ï¼šè¾“å‡ºå‰20ä¸ªæ®µè½çš„æ–‡æœ¬ï¼ˆç”¨äºæ’æŸ¥ï¼‰
            if idx < 20 and integrity_start is None:
                self._log_to_file(f"[ä¿®å¤] æ®µè½ {idx} æ–‡æœ¬é¢„è§ˆ: {para_text[:80]}")
            
            # ç¬¬ä¸€æ­¥ï¼šæ‰¾"è¯š"
            if cheng_idx is None and 'è¯š' in para_text:
                cheng_idx = idx
                self._log_to_file(f"[ä¿®å¤] æ­¥éª¤1: æ‰¾åˆ°'è¯š'ï¼Œæ®µè½ç´¢å¼•: {idx}, æ–‡æœ¬: {para_text[:80]}")
                # å¦‚æœå››ä¸ªå­—éƒ½åœ¨åŒä¸€ä¸ªæ®µè½ï¼Œä¸€æ¬¡æ€§æ£€æŸ¥
                if 'ä¿¡' in para_text and 'æ‰¿' in para_text and 'è¯º' in para_text:
                    xin_idx = idx
                    cheng2_idx = idx
                    nuo_idx = idx
                    integrity_start = idx
                    self._log_to_file(f"[ä¿®å¤] âœ… åœ¨åŒä¸€æ®µè½æ‰¾åˆ°å®Œæ•´çš„'è¯šä¿¡æ‰¿è¯º'ï¼Œæ®µè½ç´¢å¼•: {idx}")
                    break
                # å¦åˆ™ç»§ç»­æŸ¥æ‰¾å…¶ä»–å­—
                continue
            
            # ç¬¬äºŒæ­¥ï¼šæ‰¾åˆ°"è¯š"åï¼Œæ‰¾"ä¿¡"ï¼ˆå¯ä»¥åœ¨åŒä¸€æ®µè½æˆ–ä¹‹åï¼‰
            if cheng_idx is not None and xin_idx is None and idx >= cheng_idx and 'ä¿¡' in para_text:
                xin_idx = idx
                self._log_to_file(f"[ä¿®å¤] æ­¥éª¤2: æ‰¾åˆ°'ä¿¡'ï¼Œæ®µè½ç´¢å¼•: {idx}, æ–‡æœ¬: {para_text[:80]}")
                # å¦‚æœ"æ‰¿"å’Œ"è¯º"ä¹Ÿåœ¨åŒä¸€æ®µè½ï¼Œä¸€æ¬¡æ€§æ£€æŸ¥
                if 'æ‰¿' in para_text and 'è¯º' in para_text:
                    cheng2_idx = idx
                    nuo_idx = idx
                    integrity_start = cheng_idx
                    self._log_to_file(f"[ä¿®å¤] âœ… æ‰¾åˆ°å®Œæ•´çš„'è¯šä¿¡æ‰¿è¯º'ï¼Œèµ·å§‹æ®µè½ç´¢å¼•: {integrity_start}")
                    break
                continue
            
            # ç¬¬ä¸‰æ­¥ï¼šæ‰¾åˆ°"ä¿¡"åï¼Œæ‰¾"æ‰¿"ï¼ˆå¯ä»¥åœ¨åŒä¸€æ®µè½æˆ–ä¹‹åï¼‰
            if xin_idx is not None and cheng2_idx is None and idx >= xin_idx and 'æ‰¿' in para_text:
                cheng2_idx = idx
                self._log_to_file(f"[ä¿®å¤] æ­¥éª¤3: æ‰¾åˆ°'æ‰¿'ï¼Œæ®µè½ç´¢å¼•: {idx}, æ–‡æœ¬: {para_text[:80]}")
                # å¦‚æœ"è¯º"ä¹Ÿåœ¨åŒä¸€æ®µè½ï¼Œä¸€æ¬¡æ€§æ£€æŸ¥
                if 'è¯º' in para_text:
                    nuo_idx = idx
                    integrity_start = cheng_idx
                    self._log_to_file(f"[ä¿®å¤] âœ… æ‰¾åˆ°å®Œæ•´çš„'è¯šä¿¡æ‰¿è¯º'ï¼Œèµ·å§‹æ®µè½ç´¢å¼•: {integrity_start}")
                    break
                continue
            
            # ç¬¬å››æ­¥ï¼šæ‰¾åˆ°"æ‰¿"åï¼Œæ‰¾"è¯º"ï¼ˆå¯ä»¥åœ¨åŒä¸€æ®µè½æˆ–ä¹‹åï¼‰
            if cheng2_idx is not None and nuo_idx is None and idx >= cheng2_idx and 'è¯º' in para_text:
                nuo_idx = idx
                self._log_to_file(f"[ä¿®å¤] æ­¥éª¤4: æ‰¾åˆ°'è¯º'ï¼Œæ®µè½ç´¢å¼•: {idx}, æ–‡æœ¬: {para_text[:80]}")
                # æ‰¾åˆ°æ‰€æœ‰å››ä¸ªå­—ï¼Œè®¾ç½®è¯šä¿¡æ‰¿è¯ºçš„èµ·å§‹ä½ç½®ä¸º"è¯š"æ‰€åœ¨çš„æ®µè½
                integrity_start = cheng_idx
                self._log_to_file(f"[ä¿®å¤] âœ… æ‰¾åˆ°å®Œæ•´çš„'è¯šä¿¡æ‰¿è¯º'ï¼Œèµ·å§‹æ®µè½ç´¢å¼•: {integrity_start}")
                break
            
            # ä¹Ÿæ£€æŸ¥å…¶ä»–è¯šä¿¡æ‰¿è¯ºç›¸å…³å…³é”®è¯ï¼ˆä½œä¸ºå¤‡é€‰æ–¹æ¡ˆï¼‰
            if integrity_start is None:
                found_keyword = False
                for keyword in integrity_keywords:
                    if keyword in para_text:
                        integrity_start = idx
                        self._log_to_file(f"[ä¿®å¤] âœ… æ‰¾åˆ°è¯šä¿¡æ‰¿è¯ºï¼ˆå…³é”®è¯åŒ¹é…ï¼š{keyword}ï¼‰ï¼Œæ®µè½ç´¢å¼•: {idx}, æ–‡æœ¬: {para_text[:80]}")
                        found_keyword = True
                        break
                if found_keyword:
                    break
        
        # å¦‚æœé€šè¿‡å››ä¸ªå­—åˆ†åˆ«æŸ¥æ‰¾çš„æ–¹å¼æ‰¾åˆ°äº†ï¼Œä½†è¿˜æ²¡æœ‰è®¾ç½® integrity_start
        if cheng_idx is not None and xin_idx is not None and cheng2_idx is not None and nuo_idx is not None and integrity_start is None:
            integrity_start = cheng_idx
            self._log_to_file(f"[ä¿®å¤] âœ… é€šè¿‡åˆ†æ­¥æŸ¥æ‰¾æ‰¾åˆ°å®Œæ•´çš„'è¯šä¿¡æ‰¿è¯º'ï¼Œèµ·å§‹æ®µè½ç´¢å¼•: {integrity_start}")
        
        # è¯šä¿¡æ‰¿è¯ºçš„ç»“æŸæ ‡å¿—ï¼šé‡åˆ°"æ‘˜è¦"æˆ–"ABSTRACT"æ—¶ç»“æŸ
        # æ³¨æ„ï¼šè¯šä¿¡æ‰¿è¯ºåº”è¯¥åœ¨ç‹¬ç«‹çš„ä¸€é¡µï¼Œæ‰€ä»¥é‡åˆ°"æ‘˜è¦"å°±åº”è¯¥ç»“æŸ
        if integrity_start is not None:
            # ä»è¯šä¿¡æ‰¿è¯ºå¼€å§‹ä½ç½®ä¹‹åæŸ¥æ‰¾æ‘˜è¦
            abstract_pattern = re.compile(r'^æ‘˜\s*è¦', re.IGNORECASE)
            for idx in range(integrity_start + 1, min(integrity_start + 30, len(document.paragraphs))):
                para_text = document.paragraphs[idx].text.strip() if document.paragraphs[idx].text else ""
                if not para_text:
                    continue
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯æ‘˜è¦å¼€å§‹ï¼ˆæ”¯æŒ"æ‘˜è¦"ä¸­é—´æœ‰ç©ºæ ¼ï¼Œæˆ–"ABSTRACT"å¤§å°å†™ä¸æ•æ„Ÿï¼‰
                abstract_en_pattern = re.compile(r'^abstract', re.IGNORECASE)
                if abstract_pattern.match(para_text) or abstract_en_pattern.match(para_text):
                    # æ£€æŸ¥æ‘˜è¦å‰æ˜¯å¦æœ‰åˆ†é¡µç¬¦ï¼Œå¦‚æœæœ‰ï¼Œè¯´æ˜è¯šä¿¡æ‰¿è¯ºå’Œæ‘˜è¦å·²ç»åˆ†å¼€
                    # å¦‚æœæ²¡æœ‰åˆ†é¡µç¬¦ï¼Œä½†æ‘˜è¦æ ‡é¢˜å‰æœ‰åˆ†é¡µç¬¦ï¼Œä¹Ÿè®¤ä¸ºå·²ç»åˆ†å¼€
                    if idx > 0:
                        prev_para = document.paragraphs[idx - 1]
                        if prev_para.paragraph_format.page_break_before:
                            integrity_end = idx
                            break
                        # æ£€æŸ¥å‰ä¸€ä¸ªæ®µè½æ˜¯å¦æœ‰åˆ†é¡µç¬¦
                        for run in prev_para.runs:
                            if hasattr(run, 'element'):
                                run_xml = str(run.element.xml)
                                if 'w:br' in run_xml and 'type="page"' in run_xml:
                                    integrity_end = idx
                                    break
                        if integrity_end is not None:
                            break
                    # å¦‚æœæ‘˜è¦æ ‡é¢˜æœ¬èº«æœ‰åˆ†é¡µç¬¦ï¼Œä¹Ÿè®¤ä¸ºå·²ç»åˆ†å¼€
                    abstract_para = document.paragraphs[idx]
                    if abstract_para.paragraph_format.page_break_before:
                        integrity_end = idx
                        break
                    # æ£€æŸ¥æ‘˜è¦æ ‡é¢˜çš„runsä¸­æ˜¯å¦æœ‰åˆ†é¡µç¬¦
                    for run in abstract_para.runs:
                        if hasattr(run, 'element'):
                            run_xml = str(run.element.xml)
                            if 'w:br' in run_xml and 'type="page"' in run_xml:
                                integrity_end = idx
                                break
                    if integrity_end is not None:
                        break
                    # å¦‚æœæ²¡æœ‰åˆ†é¡µç¬¦ï¼Œä½†å·²ç»æ‰¾åˆ°æ‘˜è¦æ ‡é¢˜ï¼Œä¹Ÿç»“æŸè¯šä¿¡æ‰¿è¯ºï¼ˆé¿å…åˆå¹¶ï¼‰
                    integrity_end = idx
                    break
        
        # å¦‚æœæ‰¾åˆ°äº†è¯šä¿¡æ‰¿è¯ºï¼Œä½†æ²¡æ‰¾åˆ°ç»“æŸæ ‡å¿—ï¼Œå‡è®¾åˆ°æ‘˜è¦ä¹‹å‰
        if integrity_start is not None and integrity_end is None:
            abstract_pattern = re.compile(r'^æ‘˜\s*è¦', re.IGNORECASE)
            for idx in range(integrity_start + 1, len(document.paragraphs)):
                para_text = document.paragraphs[idx].text.strip() if document.paragraphs[idx].text else ""
                abstract_en_pattern = re.compile(r'^abstract', re.IGNORECASE)
                if abstract_pattern.match(para_text) or abstract_en_pattern.match(para_text):
                    integrity_end = idx
                    break
        
        # ç¡®å®šæŸ¥æ‰¾åç»­éƒ¨åˆ†çš„èµ·å§‹ä½ç½®
        search_start = integrity_end if integrity_end is not None else cover_end
        
        # æŸ¥æ‰¾ä¸­æ–‡æ‘˜è¦ï¼ˆæ”¯æŒ"æ‘˜è¦"ä¸­é—´æœ‰ç©ºæ ¼ï¼‰
        abstract_pattern = re.compile(r'^æ‘˜\s*è¦', re.IGNORECASE)
        self._log_to_file(f"[ä¿®å¤] å¼€å§‹æŸ¥æ‰¾ä¸­æ–‡æ‘˜è¦ï¼Œä»æ®µè½ {search_start} å¼€å§‹")
        for idx in range(search_start, len(document.paragraphs)):
            para_text = document.paragraphs[idx].text.strip() if document.paragraphs[idx].text else ""
            if abstract_pattern.match(para_text) and abstract_zh_start is None:
                abstract_zh_start = idx
                self._log_to_file(f"[ä¿®å¤] âœ… æ‰¾åˆ°ä¸­æ–‡æ‘˜è¦ï¼Œæ®µè½ç´¢å¼•: {idx}, æ–‡æœ¬: {para_text[:50]}")
            elif abstract_zh_start is not None:
                # æ£€æŸ¥æ˜¯å¦æ˜¯å…³é”®è¯ã€ABSTRACTï¼ˆå¤§å°å†™ä¸æ•æ„Ÿï¼‰æˆ–ç›®å½•
                abstract_en_pattern = re.compile(r'^abstract', re.IGNORECASE)
                if para_text.startswith("å…³é”®è¯") or abstract_en_pattern.match(para_text) or para_text.startswith("ç›®å½•"):
                    abstract_zh_end = idx
                    break
        
        # å¦‚æœæ²¡æ‰¾åˆ°ç»“æŸæ ‡å¿—ï¼Œå‡è®¾æ‘˜è¦åˆ°"ABSTRACT"ï¼ˆå¤§å°å†™ä¸æ•æ„Ÿï¼‰æˆ–"ç›®å½•"ä¹‹å‰
        if abstract_zh_start is not None and abstract_zh_end is None:
            abstract_en_pattern = re.compile(r'^abstract', re.IGNORECASE)
            for idx in range(abstract_zh_start + 1, len(document.paragraphs)):
                para_text = document.paragraphs[idx].text.strip() if document.paragraphs[idx].text else ""
                if abstract_en_pattern.match(para_text) or para_text.startswith("ç›®å½•"):
                    abstract_zh_end = idx
                    break
        
        # æŸ¥æ‰¾è‹±æ–‡æ‘˜è¦ï¼ˆæ”¯æŒå¤§å°å†™ä¸æ•æ„Ÿï¼Œå¦‚ "Abstract", "ABSTRACT", "abstract"ï¼‰
        self._log_to_file(f"[ä¿®å¤] å¼€å§‹æŸ¥æ‰¾è‹±æ–‡æ‘˜è¦ï¼Œä»æ®µè½ {search_start} å¼€å§‹")
        abstract_en_pattern = re.compile(r'^abstract', re.IGNORECASE)
        for idx in range(search_start, len(document.paragraphs)):
            para_text = document.paragraphs[idx].text.strip() if document.paragraphs[idx].text else ""
            # æ£€æŸ¥æ˜¯å¦æ˜¯è‹±æ–‡æ‘˜è¦æ ‡é¢˜ï¼ˆå¤§å°å†™ä¸æ•æ„Ÿï¼‰
            if abstract_en_pattern.match(para_text) and abstract_en_start is None:
                abstract_en_start = idx
                self._log_to_file(f"[ä¿®å¤] âœ… æ‰¾åˆ°è‹±æ–‡æ‘˜è¦ï¼Œæ®µè½ç´¢å¼•: {idx}, æ–‡æœ¬: {para_text[:50]}")
            elif abstract_en_start is not None:
                # æ£€æŸ¥æ˜¯å¦æ˜¯è‹±æ–‡æ‘˜è¦ç»“æŸæ ‡å¿—ï¼šKeywords/Key words/ç›®å½•/Contents/ç¬¬ä¸€ç« ç­‰
                # æ”¯æŒ "Keywords"ã€"Key words"ã€"Key words:" ç­‰å¤šç§æ ¼å¼
                is_end_marker = (
                    para_text.startswith("Keywords") or 
                    para_text.startswith("Key words") or 
                    para_text.startswith("Key Words") or
                    para_text.startswith("ç›®å½•") or 
                    para_text.startswith("Contents") or 
                    para_text.startswith("ç¬¬ä¸€ç« ") or 
                    para_text.startswith("ç¬¬1ç« ")
                )
                if is_end_marker:
                    # æ‰¾åˆ°ç»“æŸæ ‡å¿—ï¼Œä½†éœ€è¦æ‰¾åˆ°"Key words"æˆ–"Keywords"ä¹‹åçš„å†…å®¹ç»“æŸä½ç½®
                    # ç»§ç»­æŸ¥æ‰¾ï¼Œç›´åˆ°æ‰¾åˆ°ç›®å½•æˆ–æ­£æ–‡å¼€å§‹
                    abstract_en_end = idx
                    self._log_to_file(f"[ä¿®å¤] æ‰¾åˆ°è‹±æ–‡æ‘˜è¦ç»“æŸæ ‡å¿—ï¼Œæ®µè½ç´¢å¼•: {idx}, æ–‡æœ¬: {para_text[:50]}")
                    # ç»§ç»­æŸ¥æ‰¾ï¼Œæ‰¾åˆ°"Key words"æˆ–"Keywords"ä¹‹åçš„å†…å®¹ç»“æŸä½ç½®
                    # å¦‚æœåé¢æ˜¯ç›®å½•æˆ–æ­£æ–‡ï¼Œåˆ™è‹±æ–‡æ‘˜è¦ç»“æŸ
                    for next_idx in range(idx + 1, min(idx + 10, len(document.paragraphs))):
                        next_para_text = document.paragraphs[next_idx].text.strip() if document.paragraphs[next_idx].text else ""
                        if next_para_text.startswith("ç›®å½•") or next_para_text.startswith("Contents") or next_para_text.startswith("ç¬¬ä¸€ç« ") or next_para_text.startswith("ç¬¬1ç« "):
                            abstract_en_end = next_idx
                            self._log_to_file(f"[ä¿®å¤] è‹±æ–‡æ‘˜è¦ç»“æŸä½ç½®: {next_idx}, æ–‡æœ¬: {next_para_text[:50]}")
                            break
                    break
        
        # æŸ¥æ‰¾ç›®å½•
        for idx in range(search_start, len(document.paragraphs)):
            para_text = document.paragraphs[idx].text.strip() if document.paragraphs[idx].text else ""
            if (para_text.startswith("ç›®å½•") or para_text.startswith("Contents")) and toc_start is None:
                toc_start = idx
            elif toc_start is not None and (para_text.startswith("ç¬¬ä¸€ç« ") or para_text.startswith("ç¬¬1ç« ") or para_text.startswith("Chapter 1") or para_text.startswith("1 å¼•è¨€") or para_text.startswith("1 ç»ªè®º")):
                toc_end = idx
                break
        
        # æŸ¥æ‰¾æ­£æ–‡å¼€å§‹ï¼ˆä»"ç»ªè®º"æˆ–"æ¦‚è¿°"å¼€å§‹ï¼‰
        for idx in range(search_start, len(document.paragraphs)):
            para_text = document.paragraphs[idx].text.strip() if document.paragraphs[idx].text else ""
            if (para_text.startswith("ç¬¬ä¸€ç« ") or para_text.startswith("ç¬¬1ç« ") or para_text.startswith("Chapter 1") or 
                para_text.startswith("1 å¼•è¨€") or para_text.startswith("1 ç»ªè®º") or para_text.startswith("1 æ¦‚è¿°") or
                para_text == "ç»ªè®º" or para_text == "æ¦‚è¿°" or para_text.startswith("ç»ªè®º") or para_text.startswith("æ¦‚è¿°")):
                body_start = idx
                break
        
        if integrity_start is not None:
            ranges["integrity"] = (integrity_start, integrity_end if integrity_end else (abstract_zh_start if abstract_zh_start else len(document.paragraphs)))
            self._log_to_file(f"[ä¿®å¤] è®¾ç½® integrity èŒƒå›´: {ranges['integrity']}")
        else:
            self._log_to_file(f"[ä¿®å¤] âš ï¸ æœªæ‰¾åˆ°è¯šä¿¡æ‰¿è¯ºï¼ˆintegrity_start is Noneï¼‰")
        if abstract_zh_start is not None:
            ranges["abstract_zh"] = (abstract_zh_start, abstract_zh_end if abstract_zh_end else (abstract_en_start if abstract_en_start else (toc_start if toc_start else len(document.paragraphs))))
            self._log_to_file(f"[ä¿®å¤] è®¾ç½® abstract_zh èŒƒå›´: {ranges['abstract_zh']}")
        else:
            self._log_to_file(f"[ä¿®å¤] âš ï¸ æœªæ‰¾åˆ°ä¸­æ–‡æ‘˜è¦ï¼ˆabstract_zh_start is Noneï¼‰")
        if abstract_en_start is not None:
            # å¦‚æœæ‰¾åˆ°äº†è‹±æ–‡æ‘˜è¦ä½†æ²¡æ‰¾åˆ°ç»“æŸä½ç½®ï¼Œå°è¯•æŸ¥æ‰¾"Key words"æˆ–"Keywords"ä¹‹åçš„å†…å®¹
            if abstract_en_end is None:
                # ä»è‹±æ–‡æ‘˜è¦å¼€å§‹ä½ç½®ä¹‹åæŸ¥æ‰¾"Key words"æˆ–"Keywords"
                for idx in range(abstract_en_start + 1, len(document.paragraphs)):
                    para_text = document.paragraphs[idx].text.strip() if document.paragraphs[idx].text else ""
                    if (para_text.startswith("Keywords") or para_text.startswith("Key words") or 
                        para_text.startswith("Key Words") or para_text.startswith("ç›®å½•") or 
                        para_text.startswith("Contents") or para_text.startswith("ç¬¬ä¸€ç« ") or 
                        para_text.startswith("ç¬¬1ç« ")):
                        # æ‰¾åˆ°ç»“æŸæ ‡å¿—ï¼Œç»§ç»­æŸ¥æ‰¾åé¢çš„å†…å®¹ç»“æŸä½ç½®
                        abstract_en_end = idx
                        # ç»§ç»­æŸ¥æ‰¾ï¼Œç›´åˆ°æ‰¾åˆ°ç›®å½•æˆ–æ­£æ–‡
                        for next_idx in range(idx + 1, min(idx + 20, len(document.paragraphs))):
                            next_para_text = document.paragraphs[next_idx].text.strip() if document.paragraphs[next_idx].text else ""
                            if next_para_text.startswith("ç›®å½•") or next_para_text.startswith("Contents") or next_para_text.startswith("ç¬¬ä¸€ç« ") or next_para_text.startswith("ç¬¬1ç« "):
                                abstract_en_end = next_idx
                                break
                        break
            ranges["abstract_en"] = (abstract_en_start, abstract_en_end if abstract_en_end else (toc_start if toc_start else (body_start if body_start else len(document.paragraphs))))
            self._log_to_file(f"[ä¿®å¤] è®¾ç½® abstract_en èŒƒå›´: {ranges['abstract_en']}")
        if toc_start is not None:
            ranges["toc"] = (toc_start, toc_end if toc_end else (body_start if body_start else len(document.paragraphs)))
        if body_start is not None:
            ranges["body"] = (body_start, len(document.paragraphs))
        
        return ranges

    def _apply_rules(
        self,
        document: Document,
        rules: Dict[str, Dict],
        default_style: str | None,
    ) -> Tuple[Document, Dict]:
        total_paragraphs = len(document.paragraphs)
        adjusted_paragraphs = 0
        used_styles: set[str] = set()
        changes_log = []  # è®°å½•è¯¦ç»†ä¿®æ”¹æ—¥å¿—

        default_rule = rules.get(default_style) if default_style else None
        
        # æ‰¾åˆ°å°é¢ç»“æŸä½ç½®ï¼Œè·³è¿‡å°é¢éƒ¨åˆ†
        cover_end_idx = self._find_cover_end_index(document)
        
        # è¯†åˆ«å„ä¸ªéƒ¨åˆ†çš„æ®µè½èŒƒå›´
        section_ranges = self._find_section_ranges(document)

        for idx, paragraph in enumerate(document.paragraphs):
            # è·³è¿‡å°é¢éƒ¨åˆ†ï¼Œä¸ä¿®æ”¹å°é¢å†…å®¹
            if idx < cover_end_idx:
                continue
            
            # åˆ¤æ–­å½“å‰æ®µè½å±äºå“ªä¸ªéƒ¨åˆ†
            current_section = None
            if "integrity" in section_ranges:
                start, end = section_ranges["integrity"]
                if start <= idx < end:
                    current_section = "integrity"
            if current_section is None and "abstract_zh" in section_ranges:
                start, end = section_ranges["abstract_zh"]
                if start <= idx < end:
                    current_section = "abstract_zh"
            if current_section is None and "abstract_en" in section_ranges:
                start, end = section_ranges["abstract_en"]
                if start <= idx < end:
                    current_section = "abstract_en"
            if current_section is None and "toc" in section_ranges:
                start, end = section_ranges["toc"]
                if start <= idx < end:
                    current_section = "toc"
            if current_section is None and "body" in section_ranges:
                start, end = section_ranges["body"]
                if start <= idx < end:
                    current_section = "body"
            
            # è·³è¿‡è¯šä¿¡æ‰¿è¯ºéƒ¨åˆ†ï¼Œä¸ä¿®æ”¹ä»»ä½•å†…å®¹ï¼ˆåªæ£€æŸ¥æœ‰æ— å³å¯ï¼‰
            if current_section == "integrity":
                continue
            
            style_name = paragraph.style.name if paragraph.style else None
            rule = None
            applied_rule_name = None
            paragraph_text = paragraph.text.strip() if paragraph.text else ""
            
            # æ ¹æ®å½“å‰éƒ¨åˆ†åº”ç”¨ç‰¹å®šæ ¼å¼è§„åˆ™
            # å¤„ç†ä¸­æ–‡æ‘˜è¦éƒ¨åˆ†
            if current_section == "abstract_zh":
                # æ‘˜è¦æ ‡é¢˜ï¼ˆæ”¯æŒ"æ‘˜"å’Œ"è¦"ä¸­é—´æœ‰ç©ºæ ¼ï¼Œå¦‚"æ‘˜ è¦"ã€"æ‘˜  è¦"ç­‰ï¼‰
                abstract_pattern = re.compile(r'^æ‘˜\s*è¦', re.IGNORECASE)
                if abstract_pattern.match(paragraph_text):
                    if "abstract_title" in rules:
                        rule = rules["abstract_title"].copy()
                        applied_rule_name = "abstract_title"
                    else:
                        rule = FONT_STANDARDS.get("abstract_title", {}).copy()
                        applied_rule_name = "abstract_title"
                    # å¼ºåˆ¶ç¡®ä¿æ‘˜è¦æ ‡é¢˜ï¼šé»‘ä½“ä¸‰å·ï¼ˆ16ptï¼‰ã€åŠ ç²—ã€å±…ä¸­
                    rule["font_name"] = "é»‘ä½“"
                    rule["font_size"] = 16  # ä¸‰å·å­—
                    rule["bold"] = True
                    rule["alignment"] = "center"
                # å…³é”®è¯æ ‡ç­¾
                elif paragraph_text.startswith("å…³é”®è¯"):
                    if "keywords_label" in rules:
                        rule = rules["keywords_label"].copy()
                        applied_rule_name = "keywords_label"
                    else:
                        rule = FONT_STANDARDS.get("keywords_label", {}).copy()
                        applied_rule_name = "keywords_label"
                # æ‘˜è¦æ­£æ–‡å†…å®¹
                else:
                    if "abstract_content" in rules:
                        rule = rules["abstract_content"].copy()
                        applied_rule_name = "abstract_content"
                    else:
                        rule = FONT_STANDARDS.get("abstract_content", {}).copy()
                        applied_rule_name = "abstract_content"
                    # ç¡®ä¿æ‘˜è¦æ­£æ–‡ï¼šå®‹ä½“å°å››ï¼ˆ12ptï¼‰ï¼Œè¡Œè·20ç£…
                    rule["font_name"] = "å®‹ä½“"
                    rule["font_size"] = 12
                    rule["line_spacing"] = 20
            
            # å¤„ç†è‹±æ–‡æ‘˜è¦éƒ¨åˆ†
            elif current_section == "abstract_en":
                # è‹±æ–‡æ‘˜è¦æ ‡é¢˜ï¼ˆæ”¯æŒå¤§å°å†™ä¸æ•æ„Ÿï¼Œå¦‚"Abstract"ã€"ABSTRACT"ã€"abstract"ï¼‰
                abstract_en_pattern = re.compile(r'^abstract', re.IGNORECASE)
                if abstract_en_pattern.match(paragraph_text):
                    if "abstract_title_en" in rules:
                        rule = rules["abstract_title_en"].copy()
                        applied_rule_name = "abstract_title_en"
                    else:
                        rule = FONT_STANDARDS.get("abstract_title_en", {}).copy()
                        applied_rule_name = "abstract_title_en"
                    # å¼ºåˆ¶ç¡®ä¿ABSTRACTæ ‡é¢˜ï¼šé»‘ä½“ä¸‰å·ï¼ˆ16ptï¼‰ã€åŠ ç²—ã€å±…ä¸­
                    rule["font_name"] = "é»‘ä½“"
                    rule["font_size"] = 16  # ä¸‰å·å­—
                    rule["bold"] = True
                    rule["alignment"] = "center"
                # å…³é”®è¯æ ‡ç­¾
                elif paragraph_text.startswith("Keywords") or paragraph_text.startswith("Key words"):
                    if "keywords_label_en" in rules:
                        rule = rules["keywords_label_en"].copy()
                        applied_rule_name = "keywords_label_en"
                    else:
                        rule = FONT_STANDARDS.get("keywords_label_en", {}).copy()
                        applied_rule_name = "keywords_label_en"
                # è‹±æ–‡æ‘˜è¦æ­£æ–‡å†…å®¹
                else:
                    if "abstract_content_en" in rules:
                        rule = rules["abstract_content_en"].copy()
                        applied_rule_name = "abstract_content_en"
                    else:
                        rule = FONT_STANDARDS.get("abstract_content_en", {}).copy()
                        applied_rule_name = "abstract_content_en"
                    # ç¡®ä¿è‹±æ–‡æ‘˜è¦æ­£æ–‡ï¼šTimes New Romanå°å››ï¼ˆ12ptï¼‰
                    rule["font_name"] = "Times New Roman"
                    rule["font_size"] = 12
            
            # å¤„ç†ç›®å½•éƒ¨åˆ†
            elif current_section == "toc":
                # ç›®å½•æ ‡é¢˜ï¼ˆæ”¯æŒä¸­é—´æœ€å¤š5ä¸ªç©ºæ ¼çš„å˜ä½“ï¼Œå¦‚"ç›® å½•"ã€"ç›®  å½•"ã€"ç›®    å½•"ç­‰ï¼‰
                # æ£€æŸ¥æ˜¯å¦åŒ…å«"ç›®"å’Œ"å½•"ï¼ˆå…è®¸ä¸­é—´æœ€å¤š5ä¸ªç©ºæ ¼ï¼‰
                is_toc_title_para = False
                if "ç›®" in paragraph_text and "å½•" in paragraph_text:
                    # å»é™¤ç©ºæ ¼å’Œæ ‡ç‚¹åæ£€æŸ¥æ˜¯å¦ç­‰äº"ç›®å½•"
                    cleaned_toc_text = re.sub(r'[\s\u3000ï¼š:ï¼Œ,ã€‚.ï¼›;ï¼!ï¼Ÿ?ã€]', '', paragraph_text)
                    if cleaned_toc_text == "ç›®å½•":
                        # æ£€æŸ¥"ç›®"å’Œ"å½•"ä¹‹é—´çš„å­—ç¬¦æ˜¯å¦åªæœ‰ç©ºæ ¼ï¼ˆæœ€å¤š5ä¸ªï¼‰
                        mu_pos = paragraph_text.find("ç›®")
                        lu_pos = paragraph_text.find("å½•")
                        if mu_pos >= 0 and lu_pos > mu_pos:
                            between_text = paragraph_text[mu_pos + 1:lu_pos]
                            # å¦‚æœä¸­é—´åªæœ‰ç©ºæ ¼ï¼ˆæœ€å¤š5ä¸ªï¼‰ï¼Œæˆ–è€…æ˜¯ç©ºå­—ç¬¦ä¸²ï¼Œè®¤ä¸ºæ˜¯ç›®å½•æ ‡é¢˜
                            if len(between_text) <= 5 and all(c in ' \t\u3000' for c in between_text):
                                is_toc_title_para = True
                            elif len(between_text) == 0:
                                is_toc_title_para = True
                elif paragraph_text.startswith("Contents") or paragraph_text.startswith("contents"):
                    cleaned_toc_text = re.sub(r'[\s\u3000ï¼š:ï¼Œ,ã€‚.ï¼›;ï¼!ï¼Ÿ?ã€]', '', paragraph_text).upper()
                    if cleaned_toc_text == "CONTENTS":
                        is_toc_title_para = True
                
                if is_toc_title_para:
                    if "toc_title" in rules:
                        rule = rules["toc_title"].copy()
                        applied_rule_name = "toc_title"
                    else:
                        rule = FONT_STANDARDS.get("toc_title", {}).copy()
                        applied_rule_name = "toc_title"
                    # å¼ºåˆ¶ç¡®ä¿ç›®å½•æ ‡é¢˜ï¼šé»‘ä½“ä¸‰å·ï¼ˆ16ptï¼‰ã€åŠ ç²—ã€å±…ä¸­
                    rule["font_name"] = "é»‘ä½“"
                    rule["font_size"] = 16  # ä¸‰å·å­—
                    rule["bold"] = True
                    rule["alignment"] = "center"
                # ç›®å½•å†…å®¹
                else:
                    if "toc_content" in rules:
                        rule = rules["toc_content"].copy()
                        applied_rule_name = "toc_content"
                    else:
                        rule = FONT_STANDARDS.get("toc_content", {}).copy()
                        applied_rule_name = "toc_content"
                    # ç¡®ä¿ç›®å½•å†…å®¹ï¼šå®‹ä½“å°å››ï¼ˆ12ptï¼‰ï¼Œè¡Œè·20ç£…
                    rule["font_name"] = "å®‹ä½“"
                    rule["font_size"] = 12
                    rule["line_spacing"] = 20
            
            # å¤„ç†æ­£æ–‡éƒ¨åˆ†ï¼ˆä½¿ç”¨åŸæœ‰é€»è¾‘ï¼‰
            else:
                # ä¼˜å…ˆä½¿ç”¨æ ‡å‡†æ ¼å¼æ£€æµ‹
                detected_style = self._detect_paragraph_style(paragraph)
                if detected_style in rules:
                    rule = rules[detected_style].copy()
                    applied_rule_name = detected_style
                # å¦‚æœæ ‡å‡†æ ¼å¼ä¸­æ²¡æœ‰ï¼Œå°è¯•ä½¿ç”¨æ¨¡æ¿ä¸­çš„æ ·å¼å
                elif style_name and style_name in rules:
                    rule = rules[style_name].copy()
                    applied_rule_name = style_name
                # å¦‚æœéƒ½æ²¡æœ‰ï¼Œä½¿ç”¨é»˜è®¤è§„åˆ™
                elif default_rule:
                    rule = default_rule.copy()
                    applied_rule_name = default_style or "é»˜è®¤æ ·å¼"
                
                # å¦‚æœä»ç„¶æ²¡æœ‰è§„åˆ™ï¼Œä½¿ç”¨æ ‡å‡†é»˜è®¤æ ·å¼
                if not rule:
                    if DEFAULT_STYLE in rules:
                        rule = rules[DEFAULT_STYLE].copy()
                        applied_rule_name = DEFAULT_STYLE
                    elif default_rule:
                        rule = default_rule.copy()
                        applied_rule_name = default_style or "é»˜è®¤æ ·å¼"
            
            # å¼ºåˆ¶ç»Ÿä¸€æ­£æ–‡æ®µè½æ ¼å¼ï¼šæ¯•ä¸šè®ºæ–‡æ­£æ–‡å›ºå®šä¸ºå°å››ï¼ˆ12ptï¼‰å®‹ä½“ï¼Œå›ºå®šè¡Œè·20ç£…
            if rule:
                paragraph_text = paragraph.text.strip() if paragraph.text else ""
                # åˆ¤æ–­æ˜¯å¦æ˜¯æ ‡é¢˜ï¼ˆä½¿ç”¨æ›´ä¸¥æ ¼çš„åˆ¤æ–­ï¼Œé¿å…æŠŠæ­£æ–‡è¯¯åˆ¤ä¸ºæ ‡é¢˜ï¼‰
                is_heading = False
                if applied_rule_name:
                    # å¦‚æœåº”ç”¨çš„è§„åˆ™æ˜¯æ ‡é¢˜æ ·å¼ï¼Œåˆ™è®¤ä¸ºæ˜¯æ ‡é¢˜
                    if applied_rule_name in ["title_level_1", "title_level_2", "title_level_3", "abstract_title", "toc_title", "reference_title", "acknowledgment_title", "abstract_title_en"]:
                        is_heading = True
                        if idx < 10:  # åªè®°å½•å‰10ä¸ªæ®µè½çš„è¯¦ç»†ä¿¡æ¯
                            print(f"[æ ¼å¼åº”ç”¨] æ®µè½ {idx} è¢«è¯†åˆ«ä¸ºæ ‡é¢˜ï¼ˆè§„åˆ™: {applied_rule_name}ï¼‰")
                    # æˆ–è€…æ£€æŸ¥æ ·å¼åç§°ï¼ˆä½†æ›´ä¸¥æ ¼ï¼‰
                    elif style_name and ("æ ‡é¢˜" in style_name.lower() or "heading" in style_name.lower()):
                        # åªæœ‰å½“æ®µè½å¾ˆçŸ­ï¼ˆ<=30å­—ç¬¦ï¼‰ä¸”å±…ä¸­å¯¹é½æ—¶ï¼Œæ‰è®¤ä¸ºæ˜¯æ ‡é¢˜
                        if len(paragraph_text) <= 30 and paragraph.alignment == WD_PARAGRAPH_ALIGNMENT.CENTER:
                            is_heading = True
                            if idx < 10:
                                print(f"[æ ¼å¼åº”ç”¨] æ®µè½ {idx} è¢«è¯†åˆ«ä¸ºæ ‡é¢˜ï¼ˆæ ·å¼: {style_name}ï¼Œå†…å®¹: {paragraph_text[:20]}ï¼‰")
                    # æˆ–è€…æ£€æŸ¥æ®µè½å†…å®¹ç‰¹å¾ï¼ˆå±…ä¸­å¯¹é½çš„çŸ­æ–‡æœ¬ï¼Œæˆ–"ç»ªè®º"ã€"æ¦‚è¿°"ç­‰ï¼‰
                    elif paragraph.alignment == WD_PARAGRAPH_ALIGNMENT.CENTER and len(paragraph_text) < 30:
                        # æ›´ä¸¥æ ¼ï¼šåªæœ‰éå¸¸çŸ­çš„æ–‡æœ¬ï¼ˆ<=20å­—ç¬¦ï¼‰ä¸”å±…ä¸­å¯¹é½æ‰è®¤ä¸ºæ˜¯æ ‡é¢˜
                        if len(paragraph_text) <= 20:
                            is_heading = True
                            if idx < 10:
                                print(f"[æ ¼å¼åº”ç”¨] æ®µè½ {idx} è¢«è¯†åˆ«ä¸ºæ ‡é¢˜ï¼ˆå±…ä¸­çŸ­æ–‡æœ¬: {paragraph_text[:20]}ï¼‰")
                    # æˆ–è€…æ£€æŸ¥æ˜¯å¦æ˜¯"ç»ªè®º"ã€"æ¦‚è¿°"ç­‰æ ‡é¢˜
                    elif paragraph_text == "ç»ªè®º" or paragraph_text == "æ¦‚è¿°" or paragraph_text.startswith("1 ç»ªè®º") or paragraph_text.startswith("1 æ¦‚è¿°"):
                        if len(paragraph_text) <= 20:  # æ›´ä¸¥æ ¼ï¼šåªæœ‰å¾ˆçŸ­çš„æ–‡æœ¬æ‰è®¤ä¸ºæ˜¯æ ‡é¢˜
                            is_heading = True
                            if idx < 10:
                                print(f"[æ ¼å¼åº”ç”¨] æ®µè½ {idx} è¢«è¯†åˆ«ä¸ºæ ‡é¢˜ï¼ˆç»ªè®º/æ¦‚è¿°: {paragraph_text}ï¼‰")
                    # æˆ–è€…æ£€æŸ¥æ˜¯å¦ä»¥æ•°å­—å¼€å¤´ä¸”è¾ƒçŸ­ï¼ˆæ ‡é¢˜ä¸€èˆ¬ä¸ä¼šè¶…è¿‡ä¸€è¡Œï¼Œå­—æ•°ä¸ä¼šè¶…è¿‡50ä¸ªï¼‰
                    elif paragraph_text and paragraph_text[0].isdigit() and len(paragraph_text) <= 50:
                        # äºŒçº§æ ‡é¢˜æ ¼å¼ï¼šæ•°å­—.æ•°å­— æˆ– æ•°å­—.æ•°å­— åè·Ÿæ–‡å­—ï¼ˆå¦‚"2.1 ç³»ç»Ÿè®¾è®¡"ï¼‰
                        if re.match(r'^(\d+\.\d+)(\s*[ï¼Œ,ã€‚.ï¼š:ï¼›;]?\s*)(.*)$', paragraph_text):
                            is_heading = True
                            if idx < 10:
                                print(f"[æ ¼å¼åº”ç”¨] æ®µè½ {idx} è¢«è¯†åˆ«ä¸ºäºŒçº§æ ‡é¢˜ï¼ˆæ•°å­—ç¼–å·: {paragraph_text}ï¼‰")
                        # ä¸‰çº§æ ‡é¢˜æ ¼å¼ï¼šæ•°å­—.æ•°å­—.æ•°å­—
                        elif re.match(r'^(\d+\.\d+\.\d+)([ï¼Œ,ã€‚.ï¼š:ï¼›;]?)$', paragraph_text):
                            is_heading = True
                            if idx < 10:
                                print(f"[æ ¼å¼åº”ç”¨] æ®µè½ {idx} è¢«è¯†åˆ«ä¸ºæ ‡é¢˜ï¼ˆæ•°å­—ç¼–å·: {paragraph_text}ï¼‰")
                # å¦‚æœæ²¡æœ‰åº”ç”¨è§„åˆ™åç§°ï¼Œä½¿ç”¨å¤‡ç”¨åˆ¤æ–­é€»è¾‘ï¼ˆæ›´ä¸¥æ ¼ï¼‰
                if not is_heading:
                    is_heading = (
                        (style_name and ("æ ‡é¢˜" in style_name.lower() or "heading" in style_name.lower()) and len(paragraph_text) <= 20 and paragraph.alignment == WD_PARAGRAPH_ALIGNMENT.CENTER) or
                        (paragraph.alignment == WD_PARAGRAPH_ALIGNMENT.CENTER and len(paragraph_text) <= 15) or  # æ›´ä¸¥æ ¼ï¼š<=15å­—ç¬¦
                        # æ›´ä¸¥æ ¼çš„åˆ¤æ–­ï¼šåªæœ‰çº¯æ•°å­—ç¼–å·æ ¼å¼æ‰è®¤ä¸ºæ˜¯æ ‡é¢˜ï¼ˆæ ‡é¢˜ä¸€èˆ¬ä¸ä¼šè¶…è¿‡ä¸€è¡Œï¼Œå­—æ•°ä¸ä¼šè¶…è¿‡15ä¸ªï¼‰
                        (paragraph_text and paragraph_text[0].isdigit() and len(paragraph_text) <= 15 and 
                         re.match(r'^(\d+\.\d+\.\d+|\d+\.\d+|\d+)([ï¼Œ,ã€‚.ï¼š:ï¼›;]?)$', paragraph_text)) or
                        ((paragraph_text == "ç»ªè®º" or paragraph_text == "æ¦‚è¿°" or paragraph_text.startswith("1 ç»ªè®º") or paragraph_text.startswith("1 æ¦‚è¿°")) and len(paragraph_text) <= 20)
                    )
                
                # åˆ¤æ–­æ˜¯å¦åŒ…å«å›¾ç‰‡ã€å…¬å¼æˆ–æµç¨‹å›¾
                has_image_or_equation = self._paragraph_has_image_or_equation(paragraph)
                has_flowchart = self._paragraph_has_flowchart(paragraph)
                
                # åˆ¤æ–­æ˜¯å¦æ˜¯å›¾é¢˜ï¼ˆå›¾ç‰‡è¯´æ˜ï¼‰
                is_figure_caption = False
                if paragraph_text and len(paragraph_text) < 100:
                    # æ£€æŸ¥æ˜¯å¦ä»¥"å›¾"å¼€å¤´ï¼Œä¸”åŒ…å«æ•°å­—ï¼ˆå¦‚"å›¾1-1"ã€"å›¾2.1"ç­‰ï¼‰
                    if (paragraph_text.startswith("å›¾") and 
                        (re.search(r'å›¾\s*\d+[\.\-]\d+', paragraph_text) or re.search(r'å›¾\s*\d+', paragraph_text))):
                        is_figure_caption = True
                    # æ£€æŸ¥æ˜¯å¦æ˜¯æµç¨‹å›¾æ ‡é¢˜ï¼ˆæµç¨‹å›¾X-Xã€æµç¨‹å›¾X.Xç­‰ï¼‰
                    elif (paragraph_text.startswith("æµç¨‹å›¾") and 
                          (re.search(r'æµç¨‹å›¾\s*\d+[\.\-]\d+', paragraph_text) or re.search(r'æµç¨‹å›¾\s*\d+', paragraph_text))):
                        is_figure_caption = True
                
                # å¯¹äºæ ‡é¢˜ï¼Œç§»é™¤è¡Œè·è®¾ç½®ï¼Œä¿æŒæ ‡é¢˜çš„åŸå§‹è¡Œè·
                if is_heading:
                    rule.pop("line_spacing", None)
                
                # å¯¹äºåŒ…å«å›¾ç‰‡ã€å…¬å¼æˆ–æµç¨‹å›¾çš„æ®µè½ï¼Œç§»é™¤è¡Œè·è®¾ç½®ï¼Œé¿å…è¢«å‹ç¼©çœ‹ä¸è§ï¼Œå¹¶å¼ºåˆ¶å±…ä¸­
                if has_image_or_equation or has_flowchart:
                    # ç§»é™¤è¡Œè·è®¾ç½®ï¼Œä¿æŒå›¾ç‰‡/æµç¨‹å›¾æ®µè½çš„åŸå§‹è¡Œè·
                    rule.pop("line_spacing", None)
                    # ä¹Ÿç§»é™¤é¦–è¡Œç¼©è¿›ï¼Œå›¾ç‰‡/æµç¨‹å›¾æ®µè½é€šå¸¸ä¸éœ€è¦ç¼©è¿›
                    rule.pop("first_line_indent", None)
                    # å¼ºåˆ¶è®¾ç½®å›¾ç‰‡æ®µè½å±…ä¸­å¯¹é½
                    rule["alignment"] = "center"
                
                # å¯¹äºå›¾é¢˜ï¼ˆå›¾ç‰‡è¯´æ˜ï¼‰ï¼Œå¼ºåˆ¶å±…ä¸­å¹¶åº”ç”¨å›¾é¢˜æ ¼å¼
                if is_figure_caption:
                    # ä½¿ç”¨å›¾é¢˜æ ¼å¼æ ‡å‡†
                    if "figure_caption" in rules:
                        rule = rules["figure_caption"].copy()
                        applied_rule_name = "figure_caption"
                    else:
                        rule = FONT_STANDARDS.get("figure_caption", {}).copy()
                        applied_rule_name = "figure_caption"
                    # å¼ºåˆ¶ç¡®ä¿å›¾é¢˜å±…ä¸­å¯¹é½
                    rule["alignment"] = "center"
                
                # å¯¹äºæ­£æ–‡æ®µè½ï¼ˆéæ ‡é¢˜ã€éå›¾ç‰‡ã€éå…¬å¼ã€éæµç¨‹å›¾ï¼‰ï¼Œä¿ç•™åŸæœ‰å­—ä½“ï¼Œä¸å¼ºåˆ¶ç»Ÿä¸€
                if not is_heading and not has_image_or_equation and not has_flowchart:
                    # æ£€æŸ¥æ®µè½ä¸­æ‰€æœ‰ runs çš„å­—ä½“ï¼Œå¦‚æœæ®µè½å†…å­—ä½“ä¸ä¸€è‡´ï¼Œä¿ç•™å„è‡ªçš„å­—ä½“
                    run_fonts = []
                    for run in paragraph.runs:
                        if run.text.strip():  # åªæ£€æŸ¥æœ‰æ–‡æœ¬çš„ run
                            # ä» run ä¸­æå–å­—ä½“
                            run_font = None
                            if run.font and run.font.name:
                                run_font = run.font.name
                            else:
                                # å°è¯•ä» XML ä¸­æå–
                                try:
                                    r_pr = run._element.get_or_add_rPr()
                                    r_fonts = r_pr.rFonts
                                    if r_fonts is not None:
                                        run_font = r_fonts.get(qn("w:eastAsia")) or r_fonts.get(qn("w:ascii"))
                                except:
                                    pass
                            if run_font:
                                run_fonts.append(run_font)
                    
                    # å¦‚æœæ®µè½ä¸­æœ‰å¤šç§å­—ä½“ï¼Œä¸è®¾ç½® rule["font_name"]ï¼Œä¿ç•™åŸæœ‰å­—ä½“
                    unique_fonts = set(run_fonts)
                    if len(unique_fonts) > 1:
                        # æ®µè½ä¸­æœ‰å¤šç§å­—ä½“ï¼Œä¿ç•™å„è‡ªçš„å­—ä½“ï¼Œåªç»Ÿä¸€å­—å·å’Œè¡Œè·
                        print(f"[æ ¼å¼åº”ç”¨] æ®µè½ {idx} æ£€æµ‹åˆ°å¤šç§å­—ä½“: {unique_fonts}ï¼Œä¿ç•™å„è‡ªå­—ä½“")
                        # ç§»é™¤å­—ä½“è®¾ç½®ï¼Œå¹¶æ ‡è®°ä¸ºä¿ç•™å­—ä½“
                        rule.pop("font_name", None)
                        rule["_preserve_fonts"] = True  # æ ‡è®°ä¸ºä¿ç•™å­—ä½“
                        # åªè®¾ç½®å­—å·å’Œè¡Œè·ï¼ˆå¦‚æœè§„åˆ™ä¸­æœ‰ï¼‰
                        if DEFAULT_STYLE in FONT_STANDARDS:
                            standard_body = FONT_STANDARDS[DEFAULT_STYLE]
                            if "font_size" not in rule:
                                rule["font_size"] = standard_body.get("font_size", 12)
                            if "line_spacing" not in rule:
                                rule["line_spacing"] = standard_body.get("line_spacing", 20)
                            if "bold" not in rule:
                                rule["bold"] = standard_body.get("bold", False)
                            if "first_line_indent" not in rule:
                                rule["first_line_indent"] = standard_body.get("first_line_indent", 24)
                    elif len(unique_fonts) == 1:
                        # æ®µè½ä¸­åªæœ‰ä¸€ç§å­—ä½“ï¼Œæ£€æŸ¥æ˜¯å¦éœ€è¦ä¿ç•™
                        extracted_font = list(unique_fonts)[0]
                        font_lower = extracted_font.lower()
                        # å¦‚æœæ˜¯æ”¯æŒçš„å­—ä½“ï¼ˆæ¥·ä½“ã€å®‹ä½“ã€Times New Romanã€é»‘ä½“ï¼‰ï¼Œä¿ç•™
                        if ("æ¥·" in extracted_font or "kaiti" in font_lower or "kai" in font_lower or
                            "å®‹" in extracted_font or "simsun" in font_lower or "song" in font_lower or
                            "times" in font_lower or "new roman" in font_lower or "tnr" in font_lower or
                            "é»‘" in extracted_font or "simhei" in font_lower or "hei" in font_lower):
                            # ä¿ç•™åŸæœ‰å­—ä½“
                            rule["font_name"] = extracted_font
                            print(f"[æ ¼å¼åº”ç”¨] æ®µè½ {idx} ä¿ç•™å­—ä½“ï¼š{extracted_font}")
                            # åªè®¾ç½®å­—å·å’Œè¡Œè·ï¼ˆå¦‚æœè§„åˆ™ä¸­æœ‰ï¼‰
                            if DEFAULT_STYLE in FONT_STANDARDS:
                                standard_body = FONT_STANDARDS[DEFAULT_STYLE]
                                if "font_size" not in rule:
                                    rule["font_size"] = standard_body.get("font_size", 12)
                                if "line_spacing" not in rule:
                                    rule["line_spacing"] = standard_body.get("line_spacing", 20)
                                if "bold" not in rule:
                                    rule["bold"] = standard_body.get("bold", False)
                                if "first_line_indent" not in rule:
                                    rule["first_line_indent"] = standard_body.get("first_line_indent", 24)
                        else:
                            # ä¸æ”¯æŒçš„å­—ä½“ï¼Œä½¿ç”¨é»˜è®¤å®‹ä½“
                            if DEFAULT_STYLE in FONT_STANDARDS:
                                standard_body = FONT_STANDARDS[DEFAULT_STYLE]
                                rule["font_name"] = standard_body.get("font_name", "å®‹ä½“")
                                rule["font_size"] = standard_body.get("font_size", 12)
                                rule["line_spacing"] = standard_body.get("line_spacing", 20)
                                rule["bold"] = standard_body.get("bold", False)
                                rule["first_line_indent"] = standard_body.get("first_line_indent", 24)
                            print(f"[æ ¼å¼åº”ç”¨] æ®µè½ {idx} ä½¿ç”¨é»˜è®¤å­—ä½“ï¼šå®‹ä½“ã€12ptã€è¡Œè·20ç£…")
                    else:
                        # æ²¡æœ‰æå–åˆ°å­—ä½“ï¼Œä½¿ç”¨é»˜è®¤å®‹ä½“
                        if DEFAULT_STYLE in FONT_STANDARDS:
                            standard_body = FONT_STANDARDS[DEFAULT_STYLE]
                            rule["font_name"] = standard_body.get("font_name", "å®‹ä½“")
                            rule["font_size"] = standard_body.get("font_size", 12)
                            rule["bold"] = standard_body.get("bold", False)
                            rule["line_spacing"] = standard_body.get("line_spacing", 20)
                            rule["first_line_indent"] = standard_body.get("first_line_indent", 24)
                        print(f"[æ ¼å¼åº”ç”¨] æ®µè½ {idx} ä½¿ç”¨é»˜è®¤å­—ä½“ï¼šå®‹ä½“ã€12ptã€è¡Œè·20ç£…")
                # å¯¹äºæ ‡é¢˜ï¼Œæ ¹æ®çº§åˆ«è®¾ç½®å­—ä½“
                elif is_heading:
                    # æ ¹æ®æ ‡é¢˜çº§åˆ«è®¾ç½®å­—ä½“
                    if applied_rule_name in ["title_level_1", "title_level_2", "title_level_3"]:
                        if applied_rule_name in FONT_STANDARDS:
                            title_style = FONT_STANDARDS[applied_rule_name]
                            # ä¸€çº§æ ‡é¢˜ï¼šé»‘ä½“ï¼›äºŒçº§æ ‡é¢˜ï¼šå®‹ä½“ï¼›ä¸‰çº§æ ‡é¢˜ï¼šé»‘ä½“
                            rule["font_name"] = title_style.get("font_name", "é»‘ä½“" if applied_rule_name != "title_level_2" else "å®‹ä½“")
                            rule["font_size"] = title_style.get("font_size", 16 if applied_rule_name == "title_level_1" else 12)
                            rule["bold"] = title_style.get("bold", True)
                            print(f"[æ ¼å¼åº”ç”¨] æ®µè½ {idx} åº”ç”¨æ ‡é¢˜æ ¼å¼ï¼š{applied_rule_name}ï¼Œå­—ä½“ï¼š{rule['font_name']}ï¼Œå­—å·ï¼š{rule['font_size']}pt")
                    else:
                        # å…¶ä»–æ ‡é¢˜ï¼ˆå¦‚æ‘˜è¦ã€ç›®å½•ç­‰ï¼‰ä½¿ç”¨é»‘ä½“
                        if rule.get("font_name") is None or "é»‘" not in str(rule.get("font_name", "")):
                            rule["font_name"] = "é»‘ä½“"
                            print(f"[æ ¼å¼åº”ç”¨] æ®µè½ {idx} å¼ºåˆ¶è®¾ç½®ä¸ºæ ‡é¢˜æ ¼å¼ï¼šé»‘ä½“")

            if rule:
                # è®°å½•ä¿®æ”¹å‰çš„æ ¼å¼
                before_format = docx_format_utils.extract_paragraph_format(paragraph)
                paragraph_text = paragraph.text[:50] + "..." if len(paragraph.text) > 50 else paragraph.text
                
                # å†æ¬¡ç¡®è®¤ï¼šå¦‚æœæ®µè½åŒ…å«æµç¨‹å›¾ï¼Œç¡®ä¿è¡Œè·ä¸è¢«ä¿®æ”¹
                # æµç¨‹å›¾è§†ä¸ºå›¾ç‰‡ï¼Œä¸ä¿®æ”¹è¡Œè·
                if has_flowchart:
                    # ç¡®ä¿è§„åˆ™ä¸­ä¸åŒ…å«è¡Œè·è®¾ç½®
                    rule.pop("line_spacing", None)
                    rule.pop("first_line_indent", None)
                
                # åº”ç”¨è§„åˆ™
                docx_format_utils.apply_paragraph_rule(paragraph, rule)
                
                # æœ€ç»ˆæ£€æŸ¥ï¼šç¡®ä¿"æ‘˜è¦"ã€"ABSTRACT"å’Œ"ç›®å½•"æ ‡é¢˜å§‹ç»ˆå±…ä¸­ï¼ˆé˜²æ­¢è¢«å…¶ä»–é€»è¾‘è¦†ç›–ï¼‰
                para_text_check = paragraph.text.strip() if paragraph.text else ""
                if para_text_check:
                    # å»é™¤æ‰€æœ‰ç©ºæ ¼ã€æ ‡ç‚¹ç¬¦å·å’Œç©ºç™½å­—ç¬¦ï¼Œåªä¿ç•™å­—æ¯å’Œæ±‰å­—
                    cleaned_text_check = re.sub(r'[\s\u3000ï¼š:ï¼Œ,ã€‚.ï¼›;ï¼!ï¼Ÿ?ã€]', '', para_text_check)
                    cleaned_text_check_upper = cleaned_text_check.upper()
                    
                    is_abstract_title_check = False
                    is_toc_title_check = False
                    # æ£€æŸ¥å»é™¤ç©ºæ ¼å’Œæ ‡ç‚¹åæ˜¯å¦ç­‰äº"æ‘˜è¦"ã€"ABSTRACT"æˆ–"ç›®å½•"
                    if cleaned_text_check == "æ‘˜è¦" or cleaned_text_check_upper == "ABSTRACT":
                        is_abstract_title_check = True
                    elif cleaned_text_check == "ç›®å½•" or cleaned_text_check_upper == "CONTENTS":
                        is_toc_title_check = True
                    # å¦‚æœå»é™¤ç©ºæ ¼åçš„æ–‡æœ¬è¾ƒçŸ­ï¼Œä¹Ÿæ£€æŸ¥æ˜¯å¦åŒ…å«è¿™äº›å…³é”®è¯
                    elif len(cleaned_text_check) <= 15:  # åŸºäºå»é™¤ç©ºæ ¼åçš„é•¿åº¦
                        # æ£€æŸ¥æ˜¯å¦åŒ…å«"æ‘˜"å’Œ"è¦"ï¼ˆå…è®¸ä¸­é—´æœ‰ç©ºæ ¼æˆ–å…¶ä»–å­—ç¬¦ï¼‰
                        if "æ‘˜" in para_text_check and "è¦" in para_text_check:
                            if cleaned_text_check == "æ‘˜è¦":
                                is_abstract_title_check = True
                        # æ£€æŸ¥æ˜¯å¦åŒ…å«"ç›®"å’Œ"å½•"ï¼ˆå…è®¸ä¸­é—´æœ€å¤š5ä¸ªç©ºæ ¼ï¼‰
                        elif "ç›®" in para_text_check and "å½•" in para_text_check:
                            # æ£€æŸ¥"ç›®"å’Œ"å½•"ä¹‹é—´çš„å­—ç¬¦æ˜¯å¦åªæœ‰ç©ºæ ¼ï¼ˆæœ€å¤š5ä¸ªï¼‰
                            mu_pos = para_text_check.find("ç›®")
                            lu_pos = para_text_check.find("å½•")
                            if mu_pos >= 0 and lu_pos > mu_pos:
                                between_text = para_text_check[mu_pos + 1:lu_pos]
                                # å¦‚æœä¸­é—´åªæœ‰ç©ºæ ¼ï¼ˆæœ€å¤š5ä¸ªï¼‰ï¼Œæˆ–è€…æ˜¯ç©ºå­—ç¬¦ä¸²ï¼Œè®¤ä¸ºæ˜¯ç›®å½•æ ‡é¢˜
                                if len(between_text) <= 5 and all(c in ' \t\u3000' for c in between_text):
                                    if cleaned_text_check == "ç›®å½•":
                                        is_toc_title_check = True
                                elif len(between_text) == 0:
                                    if cleaned_text_check == "ç›®å½•":
                                        is_toc_title_check = True
                        # æ£€æŸ¥æ˜¯å¦åŒ…å«"ABSTRACT"ï¼ˆä¸åŒºåˆ†å¤§å°å†™ï¼‰
                        elif "ABSTRACT" in cleaned_text_check_upper or "abstract" in para_text_check.lower():
                            if cleaned_text_check_upper == "ABSTRACT":
                                is_abstract_title_check = True
                        # æ£€æŸ¥æ˜¯å¦åŒ…å«"Contents"ï¼ˆä¸åŒºåˆ†å¤§å°å†™ï¼‰
                        elif "CONTENTS" in cleaned_text_check_upper or "contents" in para_text_check.lower():
                            if cleaned_text_check_upper == "CONTENTS":
                                is_toc_title_check = True
                    
                    if is_abstract_title_check or is_toc_title_check:
                        # ç¡®ä¿æ ‡é¢˜æ ¼å¼ï¼šé»‘ä½“ä¸‰å·ï¼ˆ16ptï¼‰ã€åŠ ç²—ã€å±…ä¸­
                        paragraph.alignment = WD_PARAGRAPH_ALIGNMENT.CENTER
                        # è®¾ç½®å­—ä½“å’Œå­—å·
                        for run in paragraph.runs:
                            run.font.name = "é»‘ä½“"
                            run.font.size = Pt(16)  # ä¸‰å·å­—
                            run.font.bold = True
                        # å¦‚æœæ®µè½æ²¡æœ‰runsï¼Œåˆ›å»ºä¸€ä¸ªrunå¹¶è®¾ç½®æ ¼å¼
                        if not paragraph.runs:
                            run = paragraph.add_run()
                            run.font.name = "é»‘ä½“"
                            run.font.size = Pt(16)
                            run.font.bold = True
                
                # è®°å½•ä¿®æ”¹åçš„æ ¼å¼
                after_format = docx_format_utils.extract_paragraph_format(paragraph)
                
                # æ‰¾å‡ºå®é™…ä¿®æ”¹çš„å­—æ®µ
                changed_fields = []
                for key in before_format:
                    before_val = before_format.get(key)
                    after_val = after_format.get(key)
                    if before_val != after_val:
                        changed_fields.append({
                            "field": key,
                            "before": before_val,
                            "after": after_val
                        })
                
                if changed_fields:
                    adjusted_paragraphs += 1
                    changes_log.append({
                        "paragraph_index": idx,
                        "paragraph_preview": paragraph_text.strip() or "(ç©ºæ®µè½)",
                        "style_name": style_name,
                        "applied_rule": applied_rule_name,
                        "changes": changed_fields
                    })
                    if style_name:
                        used_styles.add(style_name)

        # ç»Ÿè®¡ä¿®æ”¹ç±»å‹
        change_summary = {}
        for change in changes_log:
            for field_change in change["changes"]:
                field_name = field_change["field"]
                if field_name not in change_summary:
                    change_summary[field_name] = 0
                change_summary[field_name] += 1

        stats = {
            "paragraphs_total": total_paragraphs,
            "paragraphs_adjusted": adjusted_paragraphs,
            "styles_applied": sorted(list(used_styles)),
            "changes_summary": change_summary,
            "changes_detail": changes_log[:50],  # åªä¿ç•™å‰50æ¡è¯¦ç»†è®°å½•ï¼Œé¿å…æŠ¥å‘Šè¿‡å¤§
        }

        return document, stats

    def _find_body_start_index(self, document: Document) -> int:
        """æ‰¾åˆ°æ­£æ–‡å¼€å§‹çš„æ®µè½ç´¢å¼•ï¼Œè·³è¿‡å°é¢ã€ç›®å½•ç­‰å‰ç½®éƒ¨åˆ†"""
        # æ­£æ–‡å¼€å§‹çš„æ ‡å¿—å…³é”®è¯ï¼ˆæŒ‰ä¼˜å…ˆçº§æ’åºï¼‰
        # é«˜ä¼˜å…ˆçº§ï¼šæ˜ç¡®çš„ç« èŠ‚æ ‡é¢˜
        chapter_keywords = [
            "ç¬¬ä¸€ç« ", "ç¬¬äºŒç« ", "ç¬¬ä¸‰ç« ", "ç¬¬å››ç« ", "ç¬¬äº”ç« ", "ç¬¬å…­ç« ", "ç¬¬ä¸ƒç« ", "ç¬¬å…«ç« ", "ç¬¬ä¹ç« ", "ç¬¬åç« ",
            "ç¬¬1ç« ", "ç¬¬2ç« ", "ç¬¬3ç« ", "ç¬¬4ç« ", "ç¬¬5ç« ", "ç¬¬6ç« ", "ç¬¬7ç« ", "ç¬¬8ç« ", "ç¬¬9ç« ", "ç¬¬10ç« ",
        ]
        
        # ä¸­ä¼˜å…ˆçº§ï¼šç« èŠ‚å…³é”®è¯
        section_keywords = [
            "å¼•è¨€", "ç»ªè®º", "å‰è¨€", "æ¦‚è¿°", "æ­£æ–‡", "æ­£æ–‡éƒ¨åˆ†",
        ]
        
        # ä½ä¼˜å…ˆçº§ï¼šå¸¦ç¼–å·çš„ç« èŠ‚ï¼ˆéœ€è¦æ›´ä¸¥æ ¼çš„åŒ¹é…ï¼‰
        numbered_sections = [
            "1 å¼•è¨€", "1 ç»ªè®º", "1 æ¦‚è¿°", "1 å‰è¨€",
            "1.1", "1.2", "2.1", "2.2",  # å°èŠ‚ç¼–å·
        ]
        
        # æ–¹æ³•1: æŸ¥æ‰¾æ˜ç¡®çš„ç« èŠ‚æ ‡é¢˜ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼‰
        for idx, paragraph in enumerate(document.paragraphs):
            paragraph_text = paragraph.text.strip() if paragraph.text else ""
            if not paragraph_text:
                continue
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯æ˜ç¡®çš„ç« èŠ‚æ ‡é¢˜
            for keyword in chapter_keywords:
                if keyword in paragraph_text:
                    # ç¡®ä¿ä¸æ˜¯ç›®å½•ä¸­çš„å¼•ç”¨ï¼ˆç›®å½•é€šå¸¸è¾ƒçŸ­ä¸”åŒ…å«"ç›®å½•"å­—æ ·ï¼‰
                    if "ç›®å½•" not in paragraph_text:
                        # ç« èŠ‚æ ‡é¢˜é€šå¸¸è¾ƒçŸ­ï¼Œæˆ–è€…æ®µè½å¼€å¤´å°±æ˜¯ç« èŠ‚æ ‡é¢˜
                        if len(paragraph_text) < 100 or paragraph_text.startswith(keyword):
                            return idx
        
        # æ–¹æ³•2: æŸ¥æ‰¾ç« èŠ‚å…³é”®è¯ï¼ˆä¸­ä¼˜å…ˆçº§ï¼‰
        for idx, paragraph in enumerate(document.paragraphs):
            paragraph_text = paragraph.text.strip() if paragraph.text else ""
            if not paragraph_text:
                continue
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯ç« èŠ‚å…³é”®è¯ï¼Œä¸”æ®µè½å¼€å¤´åŒ…å«å…³é”®è¯ï¼ˆé¿å…åŒ¹é…åˆ°æ­£æ–‡ä¸­çš„å¼•ç”¨ï¼‰
            for keyword in section_keywords:
                if paragraph_text.startswith(keyword) or (keyword in paragraph_text and len(paragraph_text) > 50):
                    # ç¡®ä¿ä¸æ˜¯ç›®å½•ä¸­çš„å¼•ç”¨
                    if "ç›®å½•" not in paragraph_text and len(paragraph_text) > 20:
                        return idx
        
        # æ–¹æ³•3: æŸ¥æ‰¾å¸¦ç¼–å·çš„ç« èŠ‚ï¼ˆéœ€è¦æ›´ä¸¥æ ¼çš„åŒ¹é…ï¼‰
        for idx, paragraph in enumerate(document.paragraphs):
            paragraph_text = paragraph.text.strip() if paragraph.text else ""
            if not paragraph_text:
                continue
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯å¸¦ç¼–å·çš„ç« èŠ‚ï¼ˆæ®µè½å¼€å¤´å¿…é¡»æ˜¯ç¼–å·ï¼‰
            for keyword in numbered_sections:
                if paragraph_text.startswith(keyword):
                    # ç¡®ä¿ä¸æ˜¯ç›®å½•ä¸­çš„å¼•ç”¨
                    if "ç›®å½•" not in paragraph_text and len(paragraph_text) > 20:
                        return idx
        
        # æ–¹æ³•4: å¦‚æœæ‰¾ä¸åˆ°å…³é”®è¯ï¼Œè·³è¿‡å‰Nä¸ªæ®µè½ï¼ˆé€šå¸¸æ˜¯å°é¢å’Œç›®å½•ï¼‰
        # è·³è¿‡å‰20ä¸ªæ®µè½ï¼Œæˆ–è€…æ–‡æ¡£æ€»æ®µè½æ•°çš„10%ï¼ˆå–è¾ƒå¤§å€¼ï¼‰
        skip_count = max(20, len(document.paragraphs) // 10)
        return min(skip_count, len(document.paragraphs) - 1)

    def _check_figure_captions(self, document: Document) -> list:
        """æ£€æµ‹æ–‡æ¡£ä¸­çš„å›¾ç‰‡ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰å›¾é¢˜ï¼Œè¿”å›ç¼ºå¤±å›¾é¢˜çš„å›¾ç‰‡åˆ—è¡¨
        æ³¨æ„ï¼šåªä»æ­£æ–‡å¼€å§‹æ£€æµ‹ï¼Œè·³è¿‡å°é¢ã€ç›®å½•ç­‰å‰ç½®éƒ¨åˆ†
        æ³¨æ„ï¼šä¸åœ¨æ–‡æ¡£ä¸­æ’å…¥æ ‡è®°ï¼Œåªè®°å½•é—®é¢˜åˆ°issuesä¸­ï¼Œä¿æŒæ–‡æ¡£å¹²å‡€"""
        issues = []
        missing_caption_indices = []  # è®°å½•ç¼ºå°‘å›¾é¢˜çš„å›¾ç‰‡æ®µè½ç´¢å¼•
        
        # æ‰¾åˆ°æ­£æ–‡å¼€å§‹çš„æ®µè½ç´¢å¼•
        body_start_idx = self._find_body_start_index(document)
        
        # åªä»æ­£æ–‡å¼€å§‹æ£€æµ‹å›¾ç‰‡
        for idx, paragraph in enumerate(document.paragraphs):
            # è·³è¿‡æ­£æ–‡ä¹‹å‰çš„æ®µè½
            if idx < body_start_idx:
                continue
            # æ£€æŸ¥æ®µè½ä¸­æ˜¯å¦åŒ…å«å›¾ç‰‡
            has_image = False
            paragraph_text = paragraph.text.strip() if paragraph.text else ""
            
            # è·³è¿‡æ˜æ˜¾ä¸æ˜¯å›¾ç‰‡çš„æ®µè½ï¼ˆæ¯”å¦‚çº¯æ–‡æœ¬æ®µè½ã€æ ‡é¢˜ç­‰ï¼‰
            # å¦‚æœæ®µè½æœ‰å¤§é‡æ–‡å­—ä¸”æ²¡æœ‰drawingç›¸å…³æ ‡ç­¾ï¼Œä¸å¤ªå¯èƒ½æ˜¯å›¾ç‰‡æ®µè½
            # ä½†ä¸è¦å®Œå…¨è·³è¿‡ï¼Œå› ä¸ºå›¾ç‰‡æ®µè½å¯èƒ½åŒ…å«ä¸€äº›æ–‡å­—è¯´æ˜
            # å…ˆæ£€æŸ¥æ˜¯å¦æœ‰drawingç›¸å…³æ ‡ç­¾ï¼Œå¦‚æœæ²¡æœ‰ä¸”æ–‡å­—å¾ˆå¤šï¼Œæ‰è·³è¿‡
            if len(paragraph_text) > 200:
                para_xml_preview = str(paragraph._element.xml)[:500] if hasattr(paragraph, '_element') else ""
                if 'drawing' not in para_xml_preview.lower() and 'pic:pic' not in para_xml_preview and 'a:blip' not in para_xml_preview:
                    continue
            
            # æ–¹æ³•1: æ£€æŸ¥æ®µè½ä¸­çš„runsæ˜¯å¦åŒ…å«çœŸæ­£çš„å›¾ç‰‡ï¼ˆå¿…é¡»åŒ…å«pic:picæˆ–a:blipï¼‰
            try:
                for run in paragraph.runs:
                    if not hasattr(run, 'element'):
                        continue
                    run_xml = str(run.element.xml)
                    # æ’é™¤æ˜æ˜¾æ˜¯VMLå½¢çŠ¶çš„æ°´å°ï¼ˆé€šè¿‡æ£€æŸ¥æ˜¯å¦æœ‰textpathç­‰ç‰¹å¾ï¼‰
                    if 'v:shape' in run_xml.lower() and 'textpath' in run_xml.lower():
                        continue  # è¿™æ˜¯æ°´å°ï¼Œè·³è¿‡
                    # å¿…é¡»åŒ…å«pic:picæˆ–a:blipï¼Œè¿™äº›æ‰æ˜¯çœŸæ­£çš„å›¾ç‰‡å…ƒç´ 
                    # åŒæ—¶éœ€è¦éªŒè¯æœ‰å›¾ç‰‡å¼•ç”¨ï¼ˆr:embedæˆ–r:linkï¼‰
                    if ('pic:pic' in run_xml or 'a:blip' in run_xml) and ('r:embed' in run_xml or 'r:link' in run_xml or 'a:blip' in run_xml):
                        has_image = True
                        break
            except:
                pass
            
            # æ–¹æ³•2: æ£€æŸ¥æ®µè½å…ƒç´ ä¸­æ˜¯å¦åŒ…å«çœŸæ­£çš„å›¾ç‰‡
            if not has_image:
                try:
                    para_xml = str(paragraph._element.xml)
                    # æ’é™¤VMLå½¢çŠ¶çš„æ°´å°
                    if 'v:shape' in para_xml.lower() and 'textpath' in para_xml.lower():
                        pass  # è¿™æ˜¯æ°´å°ï¼Œè·³è¿‡
                    # å¿…é¡»åŒ…å«pic:picæˆ–a:blipï¼Œä¸”éœ€è¦éªŒè¯æœ‰å›¾ç‰‡å¼•ç”¨
                    elif ('pic:pic' in para_xml or 'a:blip' in para_xml) and ('r:embed' in para_xml or 'r:link' in para_xml or 'a:blip' in para_xml):
                        has_image = True
                except:
                    pass
            
            # æ–¹æ³•3: ä½¿ç”¨findallæŸ¥æ‰¾drawingå…ƒç´ ï¼Œå¹¶éªŒè¯åŒ…å«çœŸæ­£çš„å›¾ç‰‡
            if not has_image:
                try:
                    from docx.oxml.ns import qn
                    # æŸ¥æ‰¾drawingå…ƒç´ ï¼ˆä½¿ç”¨findallé…åˆqnï¼Œè€Œä¸æ˜¯xpath with namespacesï¼‰
                    drawings = paragraph._element.findall('.//' + qn('w:drawing'))
                    if drawings:
                        # æ£€æŸ¥drawingä¸­æ˜¯å¦åŒ…å«çœŸæ­£çš„å›¾ç‰‡ï¼ˆpic:picæˆ–a:blipï¼‰
                        for drawing in drawings:
                            drawing_xml = str(drawing.xml)
                            # æ’é™¤VMLå½¢çŠ¶çš„æ°´å°
                            if 'v:shape' in drawing_xml.lower() and 'textpath' in drawing_xml.lower():
                                continue
                            # å¿…é¡»åŒ…å«pic:picæˆ–a:blipï¼Œä¸”éœ€è¦éªŒè¯æœ‰å›¾ç‰‡å¼•ç”¨
                            if ('pic:pic' in drawing_xml or 'a:blip' in drawing_xml) and ('r:embed' in drawing_xml or 'r:link' in drawing_xml or 'a:blip' in drawing_xml):
                                has_image = True
                                break
                except:
                    pass
            
            # å¦‚æœæ‰¾åˆ°å›¾ç‰‡ï¼Œè¿˜éœ€è¦éªŒè¯æ®µè½ç¡®å®åŒ…å«å›¾ç‰‡ï¼ˆä¸èƒ½åªæ˜¯æ–‡å­—è¯´æ˜ï¼‰
            # å¦‚æœæ®µè½åªæœ‰æ–‡å­—ä¸”æ²¡æœ‰å›¾ç‰‡å…ƒç´ ï¼Œè·³è¿‡
            if has_image:
                # å†æ¬¡éªŒè¯ï¼šå¦‚æœæ®µè½åªæœ‰æ–‡å­—è¯´æ˜ï¼ˆå¦‚"å¦‚ä¸‹å›¾æ‰€ç¤º"ï¼‰ï¼Œä½†æ²¡æœ‰å®é™…å›¾ç‰‡ï¼Œåˆ™è·³è¿‡
                # æ£€æŸ¥æ®µè½ä¸­æ˜¯å¦æœ‰å®é™…çš„å›¾ç‰‡å…ƒç´ ï¼Œè€Œä¸ä»…ä»…æ˜¯æ–‡å­—
                has_actual_image_element = False
                try:
                    para_xml_full = str(paragraph._element.xml)
                    # å¿…é¡»åŒ…å«pic:picå…ƒç´ ï¼ˆè¿™æ˜¯çœŸæ­£çš„å›¾ç‰‡å…ƒç´ ï¼‰
                    if 'pic:pic' in para_xml_full:
                        # è¿›ä¸€æ­¥éªŒè¯ï¼špic:picä¸­åº”è¯¥åŒ…å«blipï¼ˆå›¾ç‰‡æ•°æ®ï¼‰
                        # æˆ–è€…åŒ…å«embed/linkå¼•ç”¨
                        if 'a:blip' in para_xml_full or 'r:embed' in para_xml_full or 'r:link' in para_xml_full:
                            has_actual_image_element = True
                    # æˆ–è€…ç›´æ¥åŒ…å«a:blipä¸”æœ‰å¼•ç”¨
                    elif 'a:blip' in para_xml_full and ('r:embed' in para_xml_full or 'r:link' in para_xml_full):
                        has_actual_image_element = True
                except:
                    pass
                
                # å¦‚æœæ²¡æœ‰å®é™…çš„å›¾ç‰‡å…ƒç´ ï¼Œåªæ˜¯è¯¯åˆ¤ï¼Œè·³è¿‡
                if not has_actual_image_element:
                    has_image = False
            
            # å¦‚æœæ‰¾åˆ°å›¾ç‰‡ï¼Œå¼ºåˆ¶è®¾ç½®æ®µè½å¯¹é½ä¸ºå±…ä¸­
            if has_image:
                paragraph.alignment = WD_PARAGRAPH_ALIGNMENT.CENTER
            
            # å¦‚æœæ‰¾åˆ°å›¾ç‰‡ï¼Œæ£€æŸ¥åé¢å‡ ä¸ªæ®µè½æ˜¯å¦æœ‰å›¾é¢˜
            if has_image:
                # æ£€æŸ¥å½“å‰æ®µè½åŠåé¢æœ€å¤š5ä¸ªæ®µè½æ˜¯å¦æœ‰å›¾é¢˜
                is_caption = False
                caption_paragraph_idx = None
                
                # æ£€æŸ¥èŒƒå›´ï¼šå½“å‰æ®µè½ + åé¢5ä¸ªæ®µè½
                check_range = min(6, len(document.paragraphs) - idx)
                for offset in range(check_range):
                    check_idx = idx + offset
                    if check_idx >= len(document.paragraphs):
                        break
                    check_para = document.paragraphs[check_idx]
                    check_text = check_para.text.strip() if check_para.text else ""
                    
                    # åˆ¤æ–­æ˜¯å¦æ˜¯å›¾é¢˜ï¼šä»¥"å›¾"å¼€å¤´ï¼Œä¸”åŒ…å«æ•°å­—ï¼ˆå¦‚"å›¾1-1"ã€"å›¾2.1"ç­‰ï¼‰
                    # æˆ–è€…ä»¥"æµç¨‹å›¾"å¼€å¤´ï¼ˆå¦‚"æµç¨‹å›¾1-1"ã€"æµç¨‹å›¾2.1"ç­‰ï¼‰
                    if check_text and len(check_text) < 100:
                        # æ£€æŸ¥æ˜¯å¦åŒ…å«å›¾å·æ ¼å¼ï¼ˆå›¾X-Xã€å›¾X.Xç­‰ï¼‰
                        if (check_text.startswith("å›¾") and (re.search(r'å›¾\s*\d+[\.\-]\d+', check_text) or re.search(r'å›¾\s*\d+', check_text))):
                            is_caption = True
                            caption_paragraph_idx = check_idx
                            break
                        # æ£€æŸ¥æ˜¯å¦æ˜¯æµç¨‹å›¾æ ‡é¢˜ï¼ˆæµç¨‹å›¾X-Xã€æµç¨‹å›¾X.Xç­‰ï¼‰
                        elif (check_text.startswith("æµç¨‹å›¾") and (re.search(r'æµç¨‹å›¾\s*\d+[\.\-]\d+', check_text) or re.search(r'æµç¨‹å›¾\s*\d+', check_text))):
                            is_caption = True
                            caption_paragraph_idx = check_idx
                            break
                    
                    # å¦‚æœæ£€æŸ¥çš„æ®µè½å·²ç»æœ‰å¤§é‡æ–‡å­—ï¼Œè¯´æ˜å›¾é¢˜ä¸å¤ªå¯èƒ½åœ¨æ›´åé¢äº†
                    if offset > 0 and len(check_text) > 50 and not check_text.startswith("å›¾"):
                        break
                
                # å¦‚æœæ‰¾åˆ°å›¾é¢˜ï¼Œå¼ºåˆ¶è®¾ç½®å›¾é¢˜æ®µè½å±…ä¸­å¯¹é½
                if is_caption and caption_paragraph_idx is not None:
                    caption_para = document.paragraphs[caption_paragraph_idx]
                    caption_para.alignment = WD_PARAGRAPH_ALIGNMENT.CENTER
                
                # å¦‚æœæ²¡æœ‰æ‰¾åˆ°å›¾é¢˜ï¼Œè®°å½•é—®é¢˜
                if not is_caption:
                    # è·å–å›¾ç‰‡æ‰€åœ¨ä½ç½®çš„ä¸Šä¸‹æ–‡ï¼ˆå‰åå„ä¸€æ®µï¼‰
                    context_before = ""
                    context_after = ""
                    if idx > 0:
                        context_before = document.paragraphs[idx - 1].text.strip()[:50]
                    if idx + 1 < len(document.paragraphs):
                        context_after = document.paragraphs[idx + 1].text.strip()[:50]
                    
                    issues.append({
                        "paragraph_index": idx,
                        "type": "missing_figure_caption",
                        "message": "å›¾ç‰‡åç¼ºå°‘å›¾é¢˜è¯´æ˜",
                        "context_before": context_before,
                        "context_after": context_after,
                        "suggestion": "è¯·åœ¨å›¾ç‰‡åæ·»åŠ å›¾é¢˜ï¼Œæ ¼å¼å¦‚ï¼šå›¾X-X å›¾ç‰‡è¯´æ˜"
                    })
                    missing_caption_indices.append(idx)
        
        # ä¸å†åœ¨æ–‡æ¡£ä¸­æ’å…¥æ ‡è®°ï¼Œåªè®°å½•é—®é¢˜åˆ°issuesä¸­
        # æœ€ç»ˆæ–‡æ¡£åº”è¯¥çœ‹èµ·æ¥åƒæ ‡å‡†æ–‡æ¡£ï¼Œä¸æ˜¾ç¤ºä¿®æ”¹ç—•è¿¹
        
        return issues

    def _check_reference_citations(self, document: Document) -> list:
        """æ£€æµ‹å‚è€ƒæ–‡çŒ®å¼•ç”¨æ ‡æ³¨ï¼Œæ£€æŸ¥æ­£æ–‡ä¸­æ˜¯å¦æœ‰å¼•ç”¨æ ‡æ³¨ï¼Œè¿”å›ç¼ºå¤±å¼•ç”¨çš„é—®é¢˜åˆ—è¡¨
        æ³¨æ„ï¼šä¸åœ¨æ–‡æ¡£ä¸­æ’å…¥æ ‡è®°ï¼Œåªè®°å½•é—®é¢˜åˆ°issuesä¸­ï¼Œä¿æŒæ–‡æ¡£å¹²å‡€
        """
        issues = []
        
        # 1. æ‰¾åˆ°å‚è€ƒæ–‡çŒ®éƒ¨åˆ†çš„èµ·å§‹ä½ç½®ï¼ˆä»åå¾€å‰æŸ¥æ‰¾ï¼Œæ‰¾åˆ°æœ€åä¸€ä¸ª"å‚è€ƒæ–‡çŒ®"æ ‡é¢˜ï¼‰
        reference_start_idx = None
        reference_section_text = ""
        
        # ä»åå¾€å‰æŸ¥æ‰¾ï¼Œæ‰¾åˆ°æœ€åä¸€ä¸ª"å‚è€ƒæ–‡çŒ®"æ ‡é¢˜ï¼ˆé¿å…åŒ¹é…åˆ°ç›®å½•ä¸­çš„"å‚è€ƒæ–‡çŒ®"ï¼‰
        for idx in range(len(document.paragraphs) - 1, -1, -1):
            paragraph = document.paragraphs[idx]
            para_text = paragraph.text.strip() if paragraph.text else ""
            # æ£€æµ‹å‚è€ƒæ–‡çŒ®æ ‡é¢˜ï¼ˆå¯èƒ½åŒ…å«"å‚è€ƒæ–‡çŒ®"ã€"References"ã€"å‚è€ƒä¹¦ç›®"ç­‰ï¼‰
            if re.search(r'å‚è€ƒ(æ–‡çŒ®|ä¹¦ç›®)', para_text) or para_text.lower().startswith('references') or para_text.lower().startswith('bibliography'):
                # ç¡®ä¿æ˜¯æ ‡é¢˜æ ¼å¼ï¼ˆé€šå¸¸è¾ƒçŸ­ï¼Œä¸”å¯èƒ½æ˜¯å±…ä¸­æˆ–å•ç‹¬ä¸€è¡Œï¼‰
                if len(para_text) < 50 or para_text in ["å‚è€ƒæ–‡çŒ®", "References", "å‚è€ƒä¹¦ç›®", "Bibliography"]:
                    reference_start_idx = idx
                    # æ”¶é›†å‚è€ƒæ–‡çŒ®éƒ¨åˆ†çš„å†…å®¹ï¼ˆæœ€å¤šæ”¶é›†100ä¸ªæ®µè½ï¼‰
                    ref_paragraphs = []
                    for i in range(idx, min(idx + 100, len(document.paragraphs))):
                        ref_paragraphs.append(document.paragraphs[i].text.strip() if document.paragraphs[i].text else "")
                    reference_section_text = "\n".join(ref_paragraphs)
                    break
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°å‚è€ƒæ–‡çŒ®éƒ¨åˆ†ï¼Œæç¤ºç”¨æˆ·
        if reference_start_idx is None:
            issues.append({
                "type": "no_reference_section",
                "message": "æœªæ‰¾åˆ°å‚è€ƒæ–‡çŒ®éƒ¨åˆ†",
                "suggestion": "è¯·åœ¨æ–‡æ¡£æœ«å°¾æ·»åŠ å‚è€ƒæ–‡çŒ®éƒ¨åˆ†ï¼Œæ ‡é¢˜ä¸º'å‚è€ƒæ–‡çŒ®'"
            })
            return issues
        
        # 2. æå–å‚è€ƒæ–‡çŒ®åˆ—è¡¨ï¼ˆé€šå¸¸ä»¥æ•°å­—ç¼–å·å¼€å¤´ï¼Œå¦‚ [1]ã€1. ç­‰ï¼‰
        reference_items = []
        reference_patterns = [
            r'^\[\d+\]',  # [1] æ ¼å¼
            r'^\d+\.',    # 1. æ ¼å¼
            r'^\(\d+\)',  # (1) æ ¼å¼
        ]
        
        for idx in range(reference_start_idx + 1, min(reference_start_idx + 100, len(document.paragraphs))):
            para = document.paragraphs[idx]
            # è·å–åŸå§‹æ–‡æœ¬ï¼Œä¸stripï¼Œä»¥ä¾¿æ£€æŸ¥å¼€å¤´æ ¼å¼
            para_text_raw = para.text if para.text else ""
            para_text = para_text_raw.strip()
            
            # å¦‚æœé‡åˆ°æ–°çš„ç« èŠ‚æ ‡é¢˜ï¼Œåœæ­¢æ”¶é›†
            if len(para_text) < 50 and (para_text.startswith("ç¬¬") or para_text.startswith("Chapter") or 
                                         para_text.startswith("é™„å½•") or para_text.startswith("Appendix")):
                break
            
            # æ’é™¤ç« èŠ‚æ ‡é¢˜ï¼ˆå¦‚"1.2"ã€"1.2.1"ã€"ç¬¬ä¸€ç« "ç­‰ï¼‰
            is_section_title = False
            # æ£€æŸ¥æ˜¯å¦æ˜¯ç« èŠ‚æ ‡é¢˜æ ¼å¼
            if re.match(r'^\d+\.\d+', para_text) or re.match(r'^\d+\.\d+\.\d+', para_text):  # 1.2 æˆ– 1.2.1 æ ¼å¼
                # å¦‚æœæ®µè½è¾ƒçŸ­ï¼ˆé€šå¸¸æ˜¯æ ‡é¢˜ï¼‰ï¼Œä¸”ä¸åŒ…å«å‚è€ƒæ–‡çŒ®ç‰¹å¾ï¼Œåˆ™ä¸æ˜¯å‚è€ƒæ–‡çŒ®
                if len(para_text) < 100:
                    is_section_title = True
            # æ£€æŸ¥æ˜¯å¦æ˜¯ç« èŠ‚æ ‡é¢˜ï¼ˆå¦‚"ç¬¬ä¸€ç« "ã€"ç¬¬1ç« "ç­‰ï¼‰
            if re.match(r'^ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å\d]+ç« |^ç¬¬\d+ç« |^Chapter\s+\d+', para_text):
                is_section_title = True
            # æ£€æŸ¥æ˜¯å¦æ˜¯æ ‡é¢˜æ ·å¼
            if para.style and ("æ ‡é¢˜" in para.style.name or "heading" in para.style.name.lower()):
                is_section_title = True
            
            # å¦‚æœç¡®å®šæ˜¯ç« èŠ‚æ ‡é¢˜ï¼Œè·³è¿‡
            if is_section_title:
                continue
            
            # æ£€æŸ¥æ˜¯å¦ç¬¦åˆå‚è€ƒæ–‡çŒ®æ ¼å¼
            is_reference = False
            ref_number = None
            
            # é¦–å…ˆå°è¯•ä»æ®µè½å¼€å¤´æå–ç¼–å·ï¼ˆæ›´å‡†ç¡®ï¼‰
            # æ£€æŸ¥å¸¸è§çš„å‚è€ƒæ–‡çŒ®ç¼–å·æ ¼å¼
            # æ³¨æ„ï¼šå‚è€ƒæ–‡çŒ®æ ¼å¼å¯èƒ½æ˜¯ [1]  ä½œè€…å...ï¼ˆ[1]åé¢æœ‰å¤šä¸ªç©ºæ ¼ï¼‰
            # æ”¹è¿›ï¼šä½¿ç”¨ search è€Œä¸æ˜¯ matchï¼Œå…è®¸å‰é¢æœ‰å°‘é‡ç©ºæ ¼
            number_match = None
            
            # æ£€æŸ¥ [æ•°å­—] æ ¼å¼ï¼ˆä¼˜å…ˆæ£€æŸ¥ï¼Œå› ä¸ºè¿™æ˜¯æœ€å¸¸è§çš„æ ¼å¼ï¼‰
            # åªæ”¯æŒåŠè§’æ–¹æ‹¬å· [æ•°å­—]ï¼ˆå‚è€ƒæ–‡çŒ®æ ‡æ³¨ä¸€å®šå¸¦è‹±æ–‡ç‰ˆçš„æ–¹æ‹¬å·ï¼‰
            # ä½¿ç”¨ search æŸ¥æ‰¾ï¼Œä½†æ£€æŸ¥æ˜¯å¦åœ¨æ®µè½å¼€å¤´ï¼ˆå…è®¸å‰é¢æœ‰å°‘é‡ç©ºæ ¼ï¼‰
            bracket_match = re.search(r'\[(\d+)\]', para_text)
            
            if bracket_match:
                # æ£€æŸ¥ [æ•°å­—] æ˜¯å¦åœ¨æ®µè½å¼€å¤´ï¼ˆå…è®¸å‰é¢æœ‰å°‘é‡ç©ºæ ¼ï¼‰
                bracket_pos = para_text.find(bracket_match.group(0))
                # æ”¹è¿›ï¼šå…è®¸ [æ•°å­—] åœ¨æ®µè½å¼€å¤´10ä¸ªå­—ç¬¦å†…ï¼Œæé«˜å®¹é”™æ€§
                if bracket_pos <= 10:  # [æ•°å­—] åœ¨æ®µè½å¼€å¤´10ä¸ªå­—ç¬¦å†…
                    # è¿›ä¸€æ­¥éªŒè¯ï¼šç¡®ä¿ [æ•°å­—] åé¢æœ‰å†…å®¹ï¼ˆä¸æ˜¯å•ç‹¬çš„ [2]ï¼‰
                    bracket_end = bracket_pos + len(bracket_match.group(0))
                    remaining_after_bracket = para_text[bracket_end:].strip()
                    # å¦‚æœ [æ•°å­—] åé¢æœ‰å†…å®¹ï¼ˆè‡³å°‘5ä¸ªå­—ç¬¦ï¼‰ï¼Œè®¤ä¸ºæ˜¯å‚è€ƒæ–‡çŒ®
                    if len(remaining_after_bracket) >= 5:
                        is_reference = True
                        ref_number = int(bracket_match.group(1))
                        print(f"[DocumentService] é€šè¿‡åŠè§’æ–¹æ‹¬å· [æ•°å­—] æ ¼å¼è¯†åˆ«å‚è€ƒæ–‡çŒ®: {ref_number} (ä½ç½®: {bracket_pos}, åç»­æ–‡æœ¬é•¿åº¦: {len(remaining_after_bracket)})")
            
            # å¦‚æœè¿˜æ²¡æœ‰è¯†åˆ«ï¼Œç»§ç»­æ£€æŸ¥å…¶ä»–æ ¼å¼
            if not is_reference:
                if re.match(r'^\d+\.', para_text):  # 1. æ ¼å¼
                    number_match = re.search(r'^\d+', para_text)
                    if number_match:
                        is_reference = True
                        ref_number = int(number_match.group())
                        print(f"[DocumentService] é€šè¿‡ æ•°å­—. æ ¼å¼è¯†åˆ«å‚è€ƒæ–‡çŒ®: {ref_number}")
                elif re.match(r'^\(\d+\)', para_text):  # (1) æ ¼å¼
                    number_match = re.search(r'\d+', para_text)
                    if number_match:
                        is_reference = True
                        ref_number = int(number_match.group())
                        print(f"[DocumentService] é€šè¿‡ (æ•°å­—) æ ¼å¼è¯†åˆ«å‚è€ƒæ–‡çŒ®: {ref_number}")
                else:
                    # å°è¯•å…¶ä»–æ ¼å¼ï¼šå¯èƒ½æ˜¯ç©ºæ ¼åˆ†éš”çš„ç¼–å·ï¼Œå¦‚ "1 ä½œè€…å..."
                    number_match = re.match(r'^(\d+)\s+', para_text)
                    if number_match:
                        # æ£€æŸ¥åé¢æ˜¯å¦æœ‰å‚è€ƒæ–‡çŒ®ç‰¹å¾
                        remaining_text = para_text[len(number_match.group(0)):].strip()
                        # å¦‚æœåé¢æœ‰ä½œè€…åã€å¹´ä»½ç­‰ç‰¹å¾ï¼Œå¯èƒ½æ˜¯å‚è€ƒæ–‡çŒ®
                        has_year = re.search(r'\d{4}', remaining_text)
                        has_author = re.search(r'[ï¼Œ,]\s*\d{4}|[A-Z][a-z]+\s+[A-Z]', remaining_text)
                        if has_year or (has_author and len(remaining_text) > 20):
                            is_reference = True
                            ref_number = int(number_match.group(1))
                            print(f"[DocumentService] é€šè¿‡ æ•°å­—ç©ºæ ¼ æ ¼å¼è¯†åˆ«å‚è€ƒæ–‡çŒ®: {ref_number}")
            
            # å¦‚æœè¿˜æ²¡æœ‰è¯†åˆ«ä¸ºå‚è€ƒæ–‡çŒ®ï¼Œä½†æ®µè½è¾ƒé•¿ä¸”åŒ…å«ä½œè€…ã€å¹´ä»½ç­‰ä¿¡æ¯ï¼Œä¹Ÿå¯èƒ½æ˜¯å‚è€ƒæ–‡çŒ®
            # ä½†å¿…é¡»æ’é™¤ç« èŠ‚æ ‡é¢˜
            if not is_reference and len(para_text) > 20:
                # æ£€æŸ¥æ˜¯å¦åŒ…å«å¸¸è§çš„å‚è€ƒæ–‡çŒ®ç‰¹å¾ï¼ˆä½œè€…åã€å¹´ä»½ã€æœŸåˆŠåç­‰ï¼‰
                # å‚è€ƒæ–‡çŒ®é€šå¸¸åŒ…å«ï¼šä½œè€…ã€å¹´ä»½ã€æœŸåˆŠåã€å‡ºç‰ˆç¤¾ç­‰
                # æ”¹è¿›ï¼šæ”¯æŒæ›´å¤šå¹´ä»½æ ¼å¼ï¼ˆä¸­æ–‡å’Œè‹±æ–‡ï¼‰
                has_author_pattern_cn = re.search(r'[ï¼Œ,]\s*\d{4}[ï¼Œ,]', para_text)  # ä¸­æ–‡æ ¼å¼ï¼šå¹´ä»½å‰åæœ‰é€—å·
                has_author_pattern_en = re.search(r'[A-Z][a-z]+\.[A-Z]', para_text)  # è‹±æ–‡æ ¼å¼ï¼šä½œè€…åï¼ˆå¦‚ A. I.ï¼‰
                has_journal_pattern = re.search(r'\[[JC]\]|æœŸåˆŠ|å­¦æŠ¥|Journal|Conference', para_text, re.IGNORECASE)  # æœŸåˆŠæ ‡è¯† [J] æˆ– [C]
                has_publisher_pattern = re.search(r'å‡ºç‰ˆç¤¾|Press|Publishing', para_text, re.IGNORECASE)  # å‡ºç‰ˆç¤¾
                has_year = re.search(r'\d{4}', para_text)  # å¹´ä»½ï¼ˆ4ä½æ•°å­—ï¼‰
                
                # æ”¹è¿›è¯†åˆ«é€»è¾‘ï¼šæ”¯æŒè‹±æ–‡å‚è€ƒæ–‡çŒ®æ ¼å¼
                # å‚è€ƒæ–‡çŒ®å¿…é¡»åŒæ—¶æ»¡è¶³ï¼šæœ‰å¹´ä»½ï¼Œä¸”ï¼ˆæœ‰ä½œè€…æ¨¡å¼æˆ–æœŸåˆŠæ ‡è¯†æˆ–å‡ºç‰ˆç¤¾ï¼‰ï¼Œä¸”æ®µè½è¾ƒé•¿
                # æˆ–è€…ï¼šæœ‰ [æ•°å­—] æ ¼å¼åœ¨å¼€å¤´ï¼Œä¸”æœ‰å¹´ä»½å’ŒæœŸåˆŠæ ‡è¯†
                # åªæ”¯æŒåŠè§’æ–¹æ‹¬å·ï¼ˆå‚è€ƒæ–‡çŒ®æ ‡æ³¨ä¸€å®šå¸¦è‹±æ–‡ç‰ˆçš„æ–¹æ‹¬å·ï¼‰
                has_bracket_at_start = False
                bracket_match_at_start = re.search(r'\[(\d+)\]', para_text)
                if bracket_match_at_start:
                    bracket_pos = para_text.find(bracket_match_at_start.group(0))
                    if bracket_pos <= 10:  # [æ•°å­—] åœ¨æ®µè½å¼€å¤´10ä¸ªå­—ç¬¦å†…
                        has_bracket_at_start = True
                
                # å¦‚æœæ®µè½å¼€å¤´æœ‰ [æ•°å­—] æ ¼å¼ï¼Œä¸”æœ‰å¹´ä»½å’ŒæœŸåˆŠæ ‡è¯†ï¼Œè®¤ä¸ºæ˜¯å‚è€ƒæ–‡çŒ®
                if has_bracket_at_start and has_year and has_journal_pattern:
                    is_reference = True
                    ref_number = int(bracket_match_at_start.group(1))
                    print(f"[DocumentService] é€šè¿‡ [æ•°å­—]+å¹´ä»½+æœŸåˆŠæ ‡è¯† è¯†åˆ«å‚è€ƒæ–‡çŒ®: {ref_number}")
                # æˆ–è€…æ»¡è¶³ä¼ ç»Ÿçš„è¯†åˆ«æ¡ä»¶
                elif has_year and (has_author_pattern_cn or has_author_pattern_en or has_journal_pattern or has_publisher_pattern) and len(para_text) > 30:
                    is_reference = True
                    # å°è¯•ä»æ®µè½å¼€å¤´æå–ç¼–å·ï¼ˆæ›´å®½æ¾çš„åŒ¹é…ï¼‰
                    # å¯èƒ½æ ¼å¼ï¼šæ•°å­—å¼€å¤´ï¼Œåé¢è·Ÿç©ºæ ¼æˆ–æ ‡ç‚¹ï¼Œæˆ–è€… [æ•°å­—] æ ¼å¼
                    # åªå°è¯• [æ•°å­—] æ ¼å¼ï¼ˆåªæ”¯æŒåŠè§’æ–¹æ‹¬å·ï¼‰
                    bracket_match = re.search(r'\[(\d+)\]', para_text)
                    if bracket_match:
                        bracket_pos = para_text.find(bracket_match.group(0))
                        if bracket_pos <= 10:  # åœ¨æ®µè½å¼€å¤´10ä¸ªå­—ç¬¦å†…
                            ref_number = int(bracket_match.group(1))
                    else:
                        # å°è¯•æ•°å­—å¼€å¤´æ ¼å¼
                        number_match = re.search(r'^(\d+)', para_text)
                        if number_match:
                            ref_number = int(number_match.group(1))
                        else:
                            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ç¼–å·ï¼Œä½¿ç”¨åºå·ï¼ˆä½†è¿™ç§æƒ…å†µåº”è¯¥å¾ˆå°‘ï¼‰
                            ref_number = len(reference_items) + 1
                    print(f"[DocumentService] é€šè¿‡å†…å®¹ç‰¹å¾è¯†åˆ«å‚è€ƒæ–‡çŒ®: {ref_number} (å¹´ä»½: {has_year is not None}, æœŸåˆŠ: {has_journal_pattern is not None}, ä½œè€…: {has_author_pattern_cn is not None or has_author_pattern_en is not None})")
            
            if is_reference:
                # å¦‚æœè¿˜æ˜¯æ²¡æœ‰ç¼–å·ï¼Œå°è¯•ä»æ®µè½å¼€å¤´æå–ï¼ˆæ›´å®½æ¾çš„åŒ¹é…ï¼‰
                if ref_number is None:
                    # å°è¯•åŒ¹é…ï¼šæ•°å­—å¼€å¤´ï¼Œåé¢è·Ÿç©ºæ ¼ã€ç‚¹ã€æ–¹æ‹¬å·ã€åœ†æ‹¬å·ç­‰
                    number_match = re.match(r'^(\d+)', para_text)
                    if number_match:
                        ref_number = int(number_match.group(1))
                    else:
                        # å¦‚æœè¿˜æ˜¯æ²¡æœ‰ï¼Œä½¿ç”¨åºå·ï¼ˆç¡®ä¿æ¯ä¸ªå‚è€ƒæ–‡çŒ®éƒ½æœ‰ç¼–å·ï¼‰
                        ref_number = len(reference_items) + 1
                        print(f"[DocumentService] è­¦å‘Šï¼šå‚è€ƒæ–‡çŒ®æ²¡æœ‰æ˜ç¡®ç¼–å·ï¼Œä½¿ç”¨åºå· {ref_number}: {para_text[:50]}")
                
                reference_items.append({
                    "index": ref_number,
                    "number": ref_number,  # ç¡®ä¿ç¼–å·ä¸€è‡´
                    "text": para_text[:100],  # åªä¿å­˜å‰100ä¸ªå­—ç¬¦
                    "paragraph_index": idx,
                    "paragraph": para,  # ä¿å­˜æ®µè½å¯¹è±¡ï¼Œç”¨äºåç»­ä¿®æ”¹
                })
                print(f"[DocumentService] è¯†åˆ«å‚è€ƒæ–‡çŒ® {ref_number}: {para_text[:50]}")
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°å‚è€ƒæ–‡çŒ®æ¡ç›®ï¼Œæç¤º
        if not reference_items:
            issues.append({
                "type": "no_reference_items",
                "message": "å‚è€ƒæ–‡çŒ®éƒ¨åˆ†ä¸ºç©ºæˆ–æ ¼å¼ä¸æ­£ç¡®",
                "suggestion": "è¯·ç¡®ä¿å‚è€ƒæ–‡çŒ®éƒ¨åˆ†åŒ…å«ç¼–å·çš„å‚è€ƒæ–‡çŒ®æ¡ç›®"
            })
            return issues
        
        # 2.5. æ£€æŸ¥å‚è€ƒæ–‡çŒ®æ•°é‡æ˜¯å¦æ»¡è¶³è¦æ±‚ï¼ˆè‡³å°‘10ç¯‡ï¼‰
        reference_count = len(reference_items)
        min_required = REFERENCE_REQUIREMENTS.get("min_total", 10)
        if reference_count < min_required:
            issues.append({
                "type": "insufficient_references",
                "message": f"å‚è€ƒæ–‡çŒ®æ•°é‡ä¸è¶³ï¼šå½“å‰ {reference_count} ç¯‡ï¼Œè‡³å°‘éœ€è¦ {min_required} ç¯‡",
                "suggestion": f"è¯·æ·»åŠ æ›´å¤šå‚è€ƒæ–‡çŒ®ï¼Œè‡³å°‘éœ€è¦ {min_required} ç¯‡",
                "current_count": reference_count,
                "required_count": min_required,
                "missing_count": min_required - reference_count
            })
        
        # 3. æ£€æŸ¥æ­£æ–‡ä¸­æ˜¯å¦æœ‰å¼•ç”¨æ ‡æ³¨ï¼Œå¹¶æ‰¾å‡ºè¢«å¼•ç”¨çš„å‚è€ƒæ–‡çŒ®ç¼–å·
        # æ­£æ–‡éƒ¨åˆ†ï¼šä»å°é¢ç»“æŸåˆ°å‚è€ƒæ–‡çŒ®éƒ¨åˆ†ä¹‹å‰
        body_start_idx = self._find_body_start_index(document)
        print(f"[DocumentService] æ­£æ–‡å¼€å§‹ä½ç½®: {body_start_idx}, å‚è€ƒæ–‡çŒ®å¼€å§‹ä½ç½®: {reference_start_idx}")
        
        body_text = ""
        body_paragraphs = []
        # è®°å½•æ¯ä¸ªå¼•ç”¨æ‰€åœ¨çš„æ®µè½ç´¢å¼•ï¼ˆç”¨äºè®¡ç®—é¡µç ï¼‰
        citation_locations = {}  # {ref_number: [paragraph_index1, paragraph_index2, ...]}
        
        # ä»æ­£æ–‡å¼€å§‹åˆ°å‚è€ƒæ–‡çŒ®ä¹‹å‰çš„æ‰€æœ‰æ®µè½ï¼ˆåŒ…æ‹¬çŸ­æ®µè½ï¼Œå› ä¸ºå¼•ç”¨å¯èƒ½åœ¨å›¾ç‰‡è¯´æ˜ç­‰çŸ­æ®µè½ä¸­ï¼‰
        # æ”¹è¿›ï¼šç¡®ä¿èƒ½æ­£ç¡®æå–æ®µè½æ–‡æœ¬ï¼ŒåŒ…æ‹¬æ‰€æœ‰ runs çš„æ–‡æœ¬
        for idx in range(body_start_idx, reference_start_idx):
            para = document.paragraphs[idx]
            # æ–¹æ³•1ï¼šä½¿ç”¨ para.textï¼ˆè¿™æ˜¯æœ€å¯é çš„æ–¹æ³•ï¼Œä¼šè‡ªåŠ¨åˆå¹¶æ‰€æœ‰ runsï¼‰
            para_text = para.text.strip() if para.text else ""
            
            # æ–¹æ³•2ï¼šå¦‚æœ para.text ä¸ºç©ºï¼Œå°è¯•æ‰‹åŠ¨åˆå¹¶æ‰€æœ‰ runs çš„æ–‡æœ¬
            if not para_text:
                para_text = "".join([run.text for run in para.runs if run.text]).strip()
            
            # æ–¹æ³•3ï¼šå¦‚æœè¿˜æ˜¯ä¸ºç©ºï¼Œå°è¯•ä» XML ä¸­æå–æ–‡æœ¬ï¼ˆæœ€åçš„æ‰‹æ®µï¼‰
            if not para_text:
                try:
                    para_xml = str(para._element.xml)
                    # æå–æ‰€æœ‰æ–‡æœ¬èŠ‚ç‚¹
                    import xml.etree.ElementTree as ET
                    root = ET.fromstring(para_xml)
                    texts = []
                    for elem in root.iter():
                        if elem.text:
                            texts.append(elem.text)
                    para_text = "".join(texts).strip()
                except:
                    pass
            
            # æ£€æŸ¥æ‰€æœ‰æ®µè½ï¼ˆåŒ…æ‹¬çŸ­æ®µè½ï¼‰ï¼Œå› ä¸ºå¼•ç”¨å¯èƒ½åœ¨å›¾ç‰‡è¯´æ˜ã€è¡¨æ ¼è¯´æ˜ç­‰çŸ­æ®µè½ä¸­
            if len(para_text) > 0:  # åªè¦æœ‰å†…å®¹å°±æ£€æŸ¥
                body_text += para_text + " "
                body_paragraphs.append((idx, para_text))
                
                # æ³¨æ„ï¼šä¸åœ¨éå†æ®µè½æ—¶æ£€æµ‹æ™®é€šæ–‡æœ¬ä¸­çš„å¼•ç”¨
                # åªæ£€æµ‹ä¸Šæ ‡æ ¼å¼çš„å¼•ç”¨ï¼ˆé€šè¿‡æ£€æŸ¥runsçš„æ ¼å¼ï¼‰
                
                # è°ƒè¯•ï¼šå¦‚æœæ®µè½åŒ…å« [4] æˆ– [5]ï¼Œæ‰“å°è¯¦ç»†ä¿¡æ¯
                if '[4]' in para_text or '[5]' in para_text:
                    print(f"[DocumentService] è°ƒè¯•ï¼šæ®µè½ {idx} åŒ…å«å¼•ç”¨")
                    print(f"[DocumentService] æ®µè½æ–‡æœ¬: {para_text}")
                    print(f"[DocumentService] para.text: {para.text if para.text else 'None'}")
                    print(f"[DocumentService] runsæ•°é‡: {len(para.runs)}")
                    for run_idx, run in enumerate(para.runs):
                        print(f"[DocumentService]   run {run_idx}: '{run.text}' (ä¸Šæ ‡: {run.font.superscript if run.font else 'N/A'})")
        
        # è°ƒè¯•ï¼šæ£€æŸ¥ body_text ä¸­æ˜¯å¦åŒ…å« [4] å’Œ [5]
        print(f"[DocumentService] æ­£æ–‡æ–‡æœ¬æ€»é•¿åº¦: {len(body_text)} å­—ç¬¦")
        if '[4]' in body_text:
            # æ‰¾åˆ°æ‰€æœ‰ [4] çš„ä½ç½®
            positions = []
            start = 0
            while True:
                pos = body_text.find('[4]', start)
                if pos == -1:
                    break
                positions.append(pos)
                start = pos + 1
            print(f"[DocumentService] åœ¨æ­£æ–‡ä¸­æ‰¾åˆ° {len(positions)} ä¸ª [4]ï¼Œä½ç½®: {positions}")
            for pos in positions[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ª
                context = body_text[max(0, pos-30):min(len(body_text), pos+30)]
                print(f"[DocumentService]   [4] ä¸Šä¸‹æ–‡: ...{context}...")
        else:
            print(f"[DocumentService] è­¦å‘Šï¼šæ­£æ–‡æ–‡æœ¬ä¸­æœªæ‰¾åˆ° [4]")
        
        if '[5]' in body_text:
            # æ‰¾åˆ°æ‰€æœ‰ [5] çš„ä½ç½®
            positions = []
            start = 0
            while True:
                pos = body_text.find('[5]', start)
                if pos == -1:
                    break
                positions.append(pos)
                start = pos + 1
            print(f"[DocumentService] åœ¨æ­£æ–‡ä¸­æ‰¾åˆ° {len(positions)} ä¸ª [5]ï¼Œä½ç½®: {positions}")
            for pos in positions[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ª
                context = body_text[max(0, pos-30):min(len(body_text), pos+30)]
                print(f"[DocumentService]   [5] ä¸Šä¸‹æ–‡: ...{context}...")
        else:
            print(f"[DocumentService] è­¦å‘Šï¼šæ­£æ–‡æ–‡æœ¬ä¸­æœªæ‰¾åˆ° [5]")
        
        # æ£€æµ‹å¼•ç”¨æ ‡æ³¨çš„å¸¸è§æ ¼å¼ï¼Œå¹¶æå–è¢«å¼•ç”¨çš„å‚è€ƒæ–‡çŒ®ç¼–å·
        # æ”¹è¿›ï¼šæ”¯æŒæ›´å¤šæ ¼å¼ï¼ŒåŒ…æ‹¬å¤šä¸ªç¼–å·çš„å®Œæ•´æå–
        citation_patterns = [
            (r'\[(\d+)\]', 'single'),                    # [1] æ ¼å¼
            (r'\[(\d+)[,\s]+(\d+)\]', 'range_comma'),   # [1,2,3] æ ¼å¼ï¼ˆé€—å·åˆ†éš”ï¼Œä½†åªåŒ¹é…ä¸¤ä¸ªæ•°å­—ï¼‰
            (r'\[(\d+)[\-\s]+(\d+)\]', 'range_dash'),   # [1-5] æˆ– [1 5] æ ¼å¼ï¼ˆè¿å­—ç¬¦æˆ–ç©ºæ ¼åˆ†éš”ï¼‰
            (r'\((\d+)\)', 'paren_single'),              # (1) æ ¼å¼ï¼ˆåœ†æ‹¬å·ï¼‰
            (r'ï¼ˆ(\d+)ï¼‰', 'paren_single_cn'),          # ï¼ˆ1ï¼‰æ ¼å¼ï¼ˆä¸­æ–‡åœ†æ‹¬å·ï¼‰
            (r'\((\d+)[,\s]+(\d+)\)', 'paren_range'),  # (1,2,3) æ ¼å¼
            (r'ï¼ˆ(\d+)[,\s]+(\d+)ï¼‰', 'paren_range_cn'), # ï¼ˆ1,2,3ï¼‰æ ¼å¼
            # æ³¨æ„ï¼šå¹´ä»½æ ¼å¼ (2020) ä¸æå–ä¸ºå‚è€ƒæ–‡çŒ®ç¼–å·ï¼Œå› ä¸ºå¯èƒ½æ˜¯ä½œè€…-å¹´ä»½å¼•ç”¨æ ¼å¼
        ]
        
        cited_reference_numbers = set()  # è¢«å¼•ç”¨çš„å‚è€ƒæ–‡çŒ®ç¼–å·é›†åˆ
        
        # æ ¹æ®ç”¨æˆ·è¦æ±‚ï¼šåªæœ‰ä¸Šæ ‡æ ¼å¼çš„ [æ•°å­—] æ‰ç®—æ–‡çŒ®å¼•ç”¨ï¼Œåˆ«çš„éƒ½ä¸ç®—
        # ä¸å†æ£€æµ‹æ™®é€šæ–‡æœ¬ä¸­çš„å¼•ç”¨æ ¼å¼ï¼Œåªæ£€æµ‹ä¸Šæ ‡æ ¼å¼çš„å¼•ç”¨ï¼ˆé€šè¿‡æ£€æŸ¥runsçš„æ ¼å¼ï¼‰
        print(f"[DocumentService] å¼€å§‹æ£€æµ‹å¼•ç”¨ï¼Œæ­£æ–‡æ–‡æœ¬é•¿åº¦: {len(body_text)}")
        print(f"[DocumentService] æ³¨æ„ï¼šåªæ£€æµ‹ä¸Šæ ‡æ ¼å¼çš„å¼•ç”¨ï¼Œæ™®é€šæ–‡æœ¬ä¸­çš„å¼•ç”¨ä¸ç®—")
        
        # åªæ£€æµ‹ä¸Šæ ‡æ ¼å¼çš„å¼•ç”¨ï¼ˆé€šè¿‡æ£€æŸ¥runsçš„æ ¼å¼ï¼‰
        # æ ¹æ®ç”¨æˆ·è¦æ±‚ï¼šåªæœ‰ä¸Šæ ‡æ ¼å¼çš„ [æ•°å­—] æ‰ç®—æ–‡çŒ®å¼•ç”¨ï¼Œåˆ«çš„éƒ½ä¸ç®—
        # æ¯•ä¸šè®ºæ–‡ä¸­ï¼Œå¼•ç”¨é€šå¸¸æ˜¯åœ¨æ–‡å­—ä¸Šæ–¹åŠ å…¥ [1], [2] è¿™ç§æ ¼å¼ï¼Œé€šå¸¸æ˜¯ä¸Šæ ‡æ ¼å¼
        for idx in range(body_start_idx, reference_start_idx):
            para = document.paragraphs[idx]
            for run in para.runs:
                run_text = run.text.strip() if run.text else ""
                if not run_text:
                    continue
                
                # åªæ£€æŸ¥ä¸Šæ ‡æ ¼å¼ï¼ˆè¿™æ˜¯å”¯ä¸€ç®—ä½œå¼•ç”¨çš„æ ¼å¼ï¼‰
                if run.font.superscript:
                    # ä¸Šæ ‡æ ¼å¼çš„å¼•ç”¨å¯èƒ½æ˜¯ï¼š
                    # 1. çº¯æ•°å­—ï¼š1, 2, 3
                    # 2. æ–¹æ‹¬å·æ•°å­—ï¼š[1], [2], [3]
                    # 3. å¤šä¸ªæ•°å­—ï¼š[1,2,3] æˆ– [1-5]
                    
                    # æ£€æŸ¥æ–¹æ‹¬å·æ ¼å¼çš„ä¸Šæ ‡å¼•ç”¨ [1], [2] ç­‰ï¼ˆåªæ”¯æŒåŠè§’æ–¹æ‹¬å·ï¼‰
                    # å…ˆæ£€æµ‹åŠè§’æ–¹æ‹¬å·
                    bracket_matches = re.finditer(r'\[(\d+)\]', run_text)
                    for match in bracket_matches:
                        try:
                            num = int(match.group(1))
                            if 1 <= num <= 1000:
                                cited_reference_numbers.add(num)
                                # è®°å½•å¼•ç”¨ä½ç½®ï¼ˆé¿å…é‡å¤è®°å½•ï¼‰
                                if num not in citation_locations:
                                    citation_locations[num] = []
                                # åªæœ‰å½“è¿™ä¸ªæ®µè½ç´¢å¼•è¿˜æ²¡æœ‰è®°å½•æ—¶æ‰æ·»åŠ ï¼Œé¿å…é‡å¤
                                if idx not in citation_locations[num]:
                                    citation_locations[num].append(idx)
                                print(f"[DocumentService] æ£€æµ‹åˆ°ä¸Šæ ‡æ ¼å¼å¼•ç”¨ [{num}]")
                        except ValueError:
                            pass
                    
                    # æ£€æŸ¥å¤šä¸ªç¼–å·çš„ä¸Šæ ‡å¼•ç”¨ [1,2,3,4,5] æˆ– [1-5]ï¼ˆæ”¹è¿›ï¼šæ”¯æŒä»»æ„æ•°é‡çš„ç¼–å·ï¼Œåªæ”¯æŒåŠè§’æ–¹æ‹¬å·ï¼‰
                    # å…ˆæ£€æµ‹å¤šä¸ªç¼–å·æ ¼å¼ [1,2,3,4,5]ï¼ˆåŠè§’ï¼‰
                    multi_bracket_pattern = r'\[(\d+(?:[,\s]+\d+)+)\]'
                    multi_matches = re.finditer(multi_bracket_pattern, run_text)
                    for match in multi_matches:
                        try:
                            numbers_str = match.group(1)  # æå–æ‹¬å·å†…çš„å†…å®¹
                            # æå–æ‰€æœ‰æ•°å­—
                            numbers = re.findall(r'\d+', numbers_str)
                            for num_str in numbers:
                                num = int(num_str.strip())
                                if 1 <= num <= 1000:
                                    cited_reference_numbers.add(num)
                                    # è®°å½•å¼•ç”¨ä½ç½®ï¼ˆé¿å…é‡å¤è®°å½•ï¼‰
                                    if num not in citation_locations:
                                        citation_locations[num] = []
                                    # åªæœ‰å½“è¿™ä¸ªæ®µè½ç´¢å¼•è¿˜æ²¡æœ‰è®°å½•æ—¶æ‰æ·»åŠ ï¼Œé¿å…é‡å¤
                                    if idx not in citation_locations[num]:
                                        citation_locations[num].append(idx)
                                    print(f"[DocumentService] æ£€æµ‹åˆ°ä¸Šæ ‡æ ¼å¼å¤šä¸ªç¼–å·å¼•ç”¨ [{num}]")
                        except ValueError:
                            pass
                    
                    # å†æ£€æµ‹èŒƒå›´æ ¼å¼ [1-5] æˆ–ä¸¤ä¸ªç¼–å· [1,2]ï¼ˆåªæ”¯æŒåŠè§’æ–¹æ‹¬å·ï¼‰
                    range_matches = re.finditer(r'\[(\d+)[,\-\s]+(\d+)\]', run_text)
                    for match in range_matches:
                        try:
                            # æå–æ‰€æœ‰æ•°å­—
                            numbers_str = match.group(0).strip('[]')
                            if ',' in numbers_str:
                                # é€—å·åˆ†éš”ï¼š[1,2] æˆ– [1,2,3]
                                for num_str in numbers_str.split(','):
                                    num = int(num_str.strip())
                                    if 1 <= num <= 1000:
                                        cited_reference_numbers.add(num)
                                        # è®°å½•å¼•ç”¨ä½ç½®ï¼ˆé¿å…é‡å¤è®°å½•ï¼‰
                                        if num not in citation_locations:
                                            citation_locations[num] = []
                                        # åªæœ‰å½“è¿™ä¸ªæ®µè½ç´¢å¼•è¿˜æ²¡æœ‰è®°å½•æ—¶æ‰æ·»åŠ ï¼Œé¿å…é‡å¤
                                        if idx not in citation_locations[num]:
                                            citation_locations[num].append(idx)
                                        print(f"[DocumentService] æ£€æµ‹åˆ°ä¸Šæ ‡æ ¼å¼é€—å·åˆ†éš”å¼•ç”¨ [{num}]")
                            elif '-' in numbers_str:
                                # è¿å­—ç¬¦åˆ†éš”ï¼š[1-5]
                                parts = numbers_str.split('-')
                                if len(parts) == 2:
                                    start = int(parts[0].strip())
                                    end = int(parts[1].strip())
                                    if 1 <= start <= end <= 1000:
                                        for num in range(start, end + 1):
                                            cited_reference_numbers.add(num)
                                            # è®°å½•å¼•ç”¨ä½ç½®ï¼ˆé¿å…é‡å¤è®°å½•ï¼‰
                                            if num not in citation_locations:
                                                citation_locations[num] = []
                                            # åªæœ‰å½“è¿™ä¸ªæ®µè½ç´¢å¼•è¿˜æ²¡æœ‰è®°å½•æ—¶æ‰æ·»åŠ ï¼Œé¿å…é‡å¤
                                            if idx not in citation_locations[num]:
                                                citation_locations[num].append(idx)
                                        print(f"[DocumentService] æ£€æµ‹åˆ°ä¸Šæ ‡æ ¼å¼èŒƒå›´å¼•ç”¨ [{start}-{end}]")
                        except ValueError:
                            pass
                    
                    # æ³¨æ„ï¼šæ ¹æ®ç”¨æˆ·è¦æ±‚ï¼Œåªæœ‰ä¸Šæ ‡æ ¼å¼çš„ [æ•°å­—] æ‰ç®—å¼•ç”¨
                    # çº¯æ•°å­—çš„ä¸Šæ ‡ï¼ˆæ²¡æœ‰æ–¹æ‹¬å·çš„ï¼‰ä¸ç®—å¼•ç”¨ï¼Œæ‰€ä»¥ä¸å†æ£€æµ‹
                
                # æ³¨æ„ï¼šä¸å†æ£€æµ‹æ™®é€šæ–‡æœ¬ä¸­çš„å¼•ç”¨æ ¼å¼
                # åªæ£€æµ‹ä¸Šæ ‡æ ¼å¼çš„å¼•ç”¨ï¼ˆå·²åœ¨ä¸Šé¢çš„ if run.font.superscript ä¸­å¤„ç†ï¼‰
        
        # 4. æ‰¾å‡ºæœªè¢«å¼•ç”¨çš„å‚è€ƒæ–‡çŒ®
        # è°ƒè¯•ä¿¡æ¯ï¼šæ‰“å°æ£€æµ‹åˆ°çš„å‚è€ƒæ–‡çŒ®ç¼–å·å’Œå¼•ç”¨ç¼–å·
        print(f"[DocumentService] æ£€æµ‹åˆ° {len(reference_items)} æ¡å‚è€ƒæ–‡çŒ®")
        print(f"[DocumentService] å‚è€ƒæ–‡çŒ®ç¼–å·: {[ref['number'] for ref in reference_items]}")
        print(f"[DocumentService] æ­£æ–‡ä¸­å¼•ç”¨çš„ç¼–å·: {sorted(cited_reference_numbers)}")
        print(f"[DocumentService] æ­£æ–‡æ–‡æœ¬é•¿åº¦: {len(body_text)} å­—ç¬¦")
        print(f"[DocumentService] æ­£æ–‡æ®µè½æ•°é‡: {len(body_paragraphs)}")
        
        # é¢å¤–è°ƒè¯•ï¼šæ£€æŸ¥æ­£æ–‡ä¸­æ˜¯å¦åŒ…å« [4] å’Œ [5]
        if '[4]' in body_text:
            print(f"[DocumentService] è°ƒè¯•ï¼šæ­£æ–‡ä¸­åŒ…å« [4]")
        if '[5]' in body_text:
            print(f"[DocumentService] è°ƒè¯•ï¼šæ­£æ–‡ä¸­åŒ…å« [5]")
        if '[4,5]' in body_text or '[4, 5]' in body_text:
            print(f"[DocumentService] è°ƒè¯•ï¼šæ­£æ–‡ä¸­åŒ…å« [4,5] æ ¼å¼")
        
        uncited_references = []
        for ref_item in reference_items:
            ref_num = ref_item["number"]
            # æ£€æŸ¥æ˜¯å¦çœŸæ­£è¢«å¼•ç”¨ï¼šå¿…é¡»åœ¨ cited_reference_numbers ä¸­ï¼Œå¹¶ä¸”æœ‰ä½ç½®è®°å½•
            # å¦‚æœä¸åœ¨å¼•ç”¨é›†åˆä¸­ï¼Œæˆ–è€…æ²¡æœ‰ä½ç½®è®°å½•ï¼Œéƒ½ç»Ÿä¸€æ ‡è®°ä¸ºæœªå¼•ç”¨
            locations = citation_locations.get(ref_num, [])
            if ref_num not in cited_reference_numbers or not locations:
                uncited_references.append(ref_item)
                print(f"[DocumentService] æœªå¼•ç”¨çš„å‚è€ƒæ–‡çŒ®: {ref_num} - {ref_item['text'][:50]}")
        
        print(f"[DocumentService] æœªå¼•ç”¨çš„å‚è€ƒæ–‡çŒ®æ•°é‡: {len(uncited_references)}")
        print(f"[DocumentService] å¼•ç”¨ä½ç½®è®°å½•: {citation_locations}")
        
        # 5. åœ¨å‚è€ƒæ–‡çŒ®æ®µè½ä¸­æ ‡è®°å¼•ç”¨ä¿¡æ¯
        # é€»è¾‘ï¼šåªæ ‡è®°æœªæ‰¾åˆ°å¼•ç”¨çš„å‚è€ƒæ–‡çŒ®
        # 1. æ‰¾åˆ°å¼•ç”¨çš„ï¼šä¸æ·»åŠ ä»»ä½•æ ‡è®°
        # 2. æœªæ‰¾åˆ°å¼•ç”¨çš„ï¼šæ˜¾ç¤º"æœªæ‰¾åˆ°æ ‡æ³¨é¡µ"ï¼ˆçº¢è‰²æ ‡è®°ï¼‰
        for ref_item in reference_items:
            ref_num = ref_item["number"]
            para = ref_item["paragraph"]
            
            # è·å–å¼•ç”¨ä½ç½®ï¼ˆæ®µè½ç´¢å¼•åˆ—è¡¨ï¼‰
            locations = citation_locations.get(ref_num, [])
            
            # æ£€æŸ¥æ˜¯å¦æ‰¾åˆ°äº†å¼•ç”¨ï¼šå¿…é¡»åœ¨ cited_reference_numbers ä¸­ï¼Œå¹¶ä¸”æœ‰ä½ç½®è®°å½•
            # ä¸å†åœ¨æ–‡æ¡£ä¸­æ ‡è®°ï¼Œåªè®°å½•é—®é¢˜åˆ°issuesä¸­
            # æœ€ç»ˆæ–‡æ¡£åº”è¯¥çœ‹èµ·æ¥åƒæ ‡å‡†æ–‡æ¡£ï¼Œä¸æ˜¾ç¤ºä¿®æ”¹ç—•è¿¹
            if ref_num in cited_reference_numbers and locations:
                # æ‰¾åˆ°äº†å¼•ç”¨ï¼Œä¸æ·»åŠ ä»»ä½•æ ‡è®°
                print(f"[DocumentService] å‚è€ƒæ–‡çŒ® {ref_num} å·²æ‰¾åˆ°å¼•ç”¨")
            else:
                # æœªæ‰¾åˆ°æ ‡æ³¨é¡µç ï¼Œåªè®°å½•åˆ°æ—¥å¿—ï¼Œä¸ä¿®æ”¹æ–‡æ¡£
                print(f"[DocumentService] å‚è€ƒæ–‡çŒ® {ref_num} æœªæ‰¾åˆ°æ ‡æ³¨é¡µï¼ˆä»…è®°å½•ï¼Œä¸ä¿®æ”¹æ–‡æ¡£ï¼‰")
        
        # 6. ç”Ÿæˆé—®é¢˜æŠ¥å‘Š
        # ç»Ÿè®¡æœªæ‰¾åˆ°æ ‡æ³¨é¡µçš„å‚è€ƒæ–‡çŒ®æ•°é‡
        uncited_refs = [ref for ref in reference_items 
                       if ref["number"] not in cited_reference_numbers 
                       or not citation_locations.get(ref["number"], [])]
        if uncited_refs:
            issues.append({
                "type": "uncited_references",
                "message": f"å‘ç° {len(uncited_refs)} æ¡å‚è€ƒæ–‡çŒ®æœªæ‰¾åˆ°æ ‡æ³¨é¡µ",
                "suggestion": "è¯·åœ¨æ­£æ–‡ä¸­æ·»åŠ å¼•ç”¨æ ‡æ³¨ï¼Œæˆ–åˆ é™¤æœªè¢«å¼•ç”¨çš„å‚è€ƒæ–‡çŒ®",
                "uncited_count": len(uncited_refs),
                "uncited_references": [
                    {
                        "number": ref["number"],
                        "text_preview": ref["text"][:80] + "..."
                    }
                    for ref in uncited_refs[:10]  # åªæ˜¾ç¤ºå‰10ä¸ª
                ]
            })
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°å¼•ç”¨æ ‡æ³¨ï¼Œæç¤ºç”¨æˆ·
        if not cited_reference_numbers and len(reference_items) > 0:
            # æ‰¾åˆ°æ­£æ–‡æ®µè½ä¸­å¯èƒ½ç¼ºå°‘å¼•ç”¨çš„ä½ç½®
            missing_citation_paragraphs = []
            for para_idx, para_text in body_paragraphs:
                # å¦‚æœæ®µè½è¾ƒé•¿ï¼ˆå¯èƒ½æ˜¯æ­£æ–‡ï¼‰ï¼Œä½†æ²¡æœ‰å¼•ç”¨æ ‡æ³¨ï¼Œè®°å½•
                if len(para_text) > 100:
                    # æ£€æŸ¥æ®µè½æ˜¯å¦åŒ…å«å¯èƒ½å¼•ç”¨çš„å†…å®¹ï¼ˆå¦‚"ç ”ç©¶"ã€"æ–‡çŒ®"ã€"è¡¨æ˜"ç­‰å­¦æœ¯è¯æ±‡ï¼‰
                    academic_keywords = ['ç ”ç©¶', 'æ–‡çŒ®', 'è¡¨æ˜', 'å‘ç°', 'æå‡º', 'åˆ†æ', 'æ–¹æ³•', 'ç†è®º', 'æ¨¡å‹']
                    if any(keyword in para_text for keyword in academic_keywords):
                        missing_citation_paragraphs.append({
                            "paragraph_index": para_idx,
                            "text_preview": para_text[:80] + "..."
                        })
            
            if missing_citation_paragraphs:
                issues.append({
                    "type": "missing_citations",
                    "message": f"æ­£æ–‡ä¸­ç¼ºå°‘å‚è€ƒæ–‡çŒ®å¼•ç”¨æ ‡æ³¨ï¼ˆå‘ç° {len(reference_items)} æ¡å‚è€ƒæ–‡çŒ®ï¼Œä½†æ­£æ–‡ä¸­æœªæ‰¾åˆ°å¼•ç”¨æ ‡æ³¨ï¼‰",
                    "suggestion": "è¯·åœ¨æ­£æ–‡ä¸­æ·»åŠ å¼•ç”¨æ ‡æ³¨ï¼Œæ ¼å¼å¦‚ï¼š[1] æˆ– [1,2,3] æˆ– (ä½œè€…, å¹´ä»½)",
                    "reference_count": len(reference_items),
                    "missing_citation_paragraphs": missing_citation_paragraphs[:10]  # åªæ˜¾ç¤ºå‰10ä¸ª
                })
            else:
                issues.append({
                    "type": "missing_citations",
                    "message": f"æ­£æ–‡ä¸­ç¼ºå°‘å‚è€ƒæ–‡çŒ®å¼•ç”¨æ ‡æ³¨ï¼ˆå‘ç° {len(reference_items)} æ¡å‚è€ƒæ–‡çŒ®ï¼Œä½†æ­£æ–‡ä¸­æœªæ‰¾åˆ°å¼•ç”¨æ ‡æ³¨ï¼‰",
                    "suggestion": "è¯·åœ¨æ­£æ–‡ä¸­æ·»åŠ å¼•ç”¨æ ‡æ³¨ï¼Œæ ¼å¼å¦‚ï¼š[1] æˆ– [1,2,3] æˆ– (ä½œè€…, å¹´ä»½)",
                    "reference_count": len(reference_items)
                })
        
        return issues

    def _check_excessive_blanks(self, document: Document) -> list:
        """
        æ£€æµ‹æ–‡æ¡£ä¸­çš„å¤§æ®µç©ºç™½
        
        è§„åˆ™ï¼š
        - åªåœ¨æ­£æ–‡éƒ¨åˆ†æ£€æµ‹ç©ºç™½è¡Œ
        - å°é¢ã€è¯šä¿¡æ‰¿è¯ºã€æ‘˜è¦ã€ç›®å½•ç­‰éƒ¨åˆ†ä¸æ£€æµ‹ç©ºç™½è¡Œ
        - å…ˆè¯†åˆ«å¤§ç« èŠ‚ï¼ˆ1ã€2ã€3æˆ–ä¸€ã€äºŒã€ä¸‰å¼€å¤´ï¼Œå­—ä½“ä¸‰å·çº¦16ç£…ï¼‰
        - åªåœ¨å¤§ç« èŠ‚å†…éƒ¨æ£€æµ‹ç©ºç™½è¡Œï¼ˆè¿ç»­2ä¸ªä»¥ä¸Šç©ºç™½æ®µè½ï¼‰
        - ç« èŠ‚ä¹‹é—´ä¸éœ€è¦æ£€æµ‹ç©ºç™½è¡Œ
        
        Returns:
            é—®é¢˜åˆ—è¡¨
        """
        issues = []
        
        # 1. ä½¿ç”¨ _find_section_ranges è·å–æ­£æ–‡èŒƒå›´
        # æ˜ç¡®æ’é™¤å°é¢ã€è¯šä¿¡æ‰¿è¯ºã€æ‘˜è¦ã€Abstractã€ç›®å½•ç­‰éƒ¨åˆ†ï¼Œè¿™äº›éƒ¨åˆ†å®Œå…¨ä¸æ£€æµ‹ç©ºç™½è¡Œ
        section_ranges = self._find_section_ranges(document)
        body_start_idx = None
        body_end_idx = len(document.paragraphs)
        
        # è·å–æ­£æ–‡èŒƒå›´
        if "body" in section_ranges:
            body_start_idx, body_end_idx = section_ranges["body"]
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ­£æ–‡èŒƒå›´ï¼Œä½¿ç”¨åŸæ¥çš„æ–¹æ³•æŸ¥æ‰¾
        if body_start_idx is None:
            body_start_idx = self._find_body_start_index(document)
            body_end_idx = len(document.paragraphs)
        
        # 2. æ‰¾åˆ°å‚è€ƒæ–‡çŒ®å¼€å§‹ä½ç½®ï¼ˆä½œä¸ºæ£€æµ‹ç»“æŸä½ç½®ï¼‰
        reference_start_idx = None
        for idx, paragraph in enumerate(document.paragraphs):
            para_text = paragraph.text.strip() if paragraph.text else ""
            if re.search(r'å‚è€ƒ(æ–‡çŒ®|ä¹¦ç›®)', para_text) or para_text.lower().startswith('references') or para_text.lower().startswith('bibliography'):
                reference_start_idx = idx
                break
        
        # 3. æ‰¾åˆ°è‡´è°¢éƒ¨åˆ†ï¼ˆå¦‚æœå­˜åœ¨ï¼Œä¹Ÿè¦æ’é™¤ï¼‰
        acknowledgement_start_idx = None
        for idx, paragraph in enumerate(document.paragraphs):
            para_text = paragraph.text.strip() if paragraph.text else ""
            if re.search(r'^(è‡´è°¢|Acknowledgement)', para_text, re.IGNORECASE):
                acknowledgement_start_idx = idx
                break
        
        # ç¡®å®šæ£€æµ‹èŒƒå›´ï¼šåªåœ¨æ­£æ–‡èŒƒå›´å†…æ£€æµ‹ç©ºç™½è¡Œ
        check_start_idx = body_start_idx
        if check_start_idx is None:
            return issues
        
        # æ£€æµ‹ç»“æŸä½ç½®ï¼šæ­£æ–‡ç»“æŸä½ç½®ã€å‚è€ƒæ–‡çŒ®å¼€å§‹æˆ–è‡´è°¢å¼€å§‹ï¼Œå–è¾ƒæ—©çš„
        check_end_idx = body_end_idx
        if reference_start_idx is not None and reference_start_idx < check_end_idx:
            check_end_idx = reference_start_idx
        if acknowledgement_start_idx is not None and acknowledgement_start_idx < check_end_idx:
            check_end_idx = acknowledgement_start_idx
        
        if check_start_idx >= check_end_idx:
            return issues
        
        # è·å–è¯šä¿¡æ‰¿è¯ºå’Œæ‘˜è¦çš„èŒƒå›´ï¼Œç¡®ä¿ä¸åˆ é™¤å®ƒä»¬ä¹‹é—´çš„å†…å®¹
        integrity_start = None
        integrity_end = None
        abstract_zh_start = None
        if "integrity" in section_ranges:
            integrity_start, integrity_end = section_ranges["integrity"]
        if "abstract_zh" in section_ranges:
            abstract_zh_start, _ = section_ranges["abstract_zh"]
        
        # 2. è¯†åˆ«å¤§ç« èŠ‚æ ‡é¢˜
        # å¤§ç« èŠ‚ç‰¹å¾ï¼šæ•°å­—ï¼ˆ1ã€2ã€3ã€4ã€5ã€6ã€7ã€8ç­‰ï¼‰æˆ–ä¸­æ–‡ä¸€ã€äºŒã€ä¸‰å¼€å¤´ï¼Œå­—ä½“ä¸‰å·ï¼ˆçº¦16ç£…ï¼‰
        def is_major_chapter_title(paragraph) -> bool:
            para_text = paragraph.text.strip() if paragraph.text else ""
            if not para_text:
                return False
            
            # æ£€æŸ¥æ˜¯å¦ä»¥æ•°å­—ï¼ˆ1-9ï¼‰æˆ–ä¸­æ–‡ä¸€ã€äºŒã€ä¸‰å¼€å¤´
            # æ”¯æŒæ ¼å¼ï¼š1 ç»ªè®ºã€1. ç»ªè®ºã€4. å‰”é™¤ç²—å¤§è¯¯å·®ã€ç¬¬ä¸€ç« ã€ç¬¬1ç« ã€ç¬¬4ç« ã€ä¸€ ç»ªè®ºç­‰
            major_chapter_patterns = [
                r'^\d+\s+',  # 1 ã€2 ã€3ã€4ã€5ã€6ã€7ã€8 ç­‰å¼€å¤´ï¼ˆæ•°å­—+ç©ºæ ¼ï¼‰
                r'^\d+\.',  # 1.ã€2.ã€3.ã€4.ã€5. ç­‰å¼€å¤´ï¼ˆæ•°å­—+ç‚¹ï¼‰
                r'^[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]\s+',  # ä¸€ ã€äºŒ ã€ä¸‰ å¼€å¤´ï¼ˆä¸­æ–‡æ•°å­—+ç©ºæ ¼ï¼‰
                r'^ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]ç« ',  # ç¬¬ä¸€ç« ã€ç¬¬äºŒç« ç­‰
                r'^ç¬¬\d+ç« ',  # ç¬¬1ç« ã€ç¬¬2ç« ã€ç¬¬3ç« ã€ç¬¬4ç« ç­‰
                r'^\d+\s+[^\d]',  # 1 ç»ªè®ºã€2 æ¦‚è¿°ã€4 å‰”é™¤ç²—å¤§è¯¯å·®ç­‰ï¼ˆæ•°å­—+ç©ºæ ¼+éæ•°å­—ï¼‰
            ]
            
            # å…ˆæ£€æŸ¥æ–‡æœ¬æ¨¡å¼
            pattern_matched = False
            for pattern in major_chapter_patterns:
                if re.match(pattern, para_text):
                    pattern_matched = True
                    break
            
            if not pattern_matched:
                return False
            
            # æ£€æŸ¥å­—ä½“å¤§å°æ˜¯å¦ä¸ºä¸‰å·ï¼ˆçº¦16ç£…ï¼Œå…è®¸14-18ç£…çš„èŒƒå›´ï¼Œå› ä¸ºå¯èƒ½æœ‰äº›åå·®ï¼‰
            # å¤§ç« èŠ‚å¿…é¡»æ˜¯ä¸‰å·å­—ä½“ï¼Œä¸èƒ½ä»…å‡­æ–‡æœ¬æ¨¡å¼åˆ¤æ–­
            has_three_size_font = False
            for run in paragraph.runs:
                if run.text.strip():
                    font_size = run.font.size.pt if run.font.size else None
                    if font_size is not None:
                        # ä¸‰å·å­—é€šå¸¸æ˜¯16ç£…ï¼Œå…è®¸14-18ç£…çš„èŒƒå›´
                        if 14 <= font_size <= 18:
                            has_three_size_font = True
                            break
            
            # å¤§ç« èŠ‚å¿…é¡»åŒæ—¶æ»¡è¶³ï¼šæ–‡æœ¬æ¨¡å¼åŒ¹é…ï¼ˆæ•°å­—æˆ–ä¸­æ–‡æ•°å­—å¼€å¤´ï¼‰AND ä¸‰å·å­—ä½“
            # å¦‚æœåªæœ‰æ–‡æœ¬æ¨¡å¼åŒ¹é…ä½†æ²¡æœ‰ä¸‰å·å­—ä½“ï¼Œä¸æ˜¯å¤§ç« èŠ‚ï¼ˆå¯èƒ½æ˜¯å°èŠ‚æ ‡é¢˜æˆ–å…¶ä»–æ ¼å¼ï¼‰
            return has_three_size_font
        
        # 3. è¯†åˆ«æ‰€æœ‰å¤§ç« èŠ‚çš„è¾¹ç•Œï¼ˆåªåœ¨æ­£æ–‡èŒƒå›´å†…è¯†åˆ«ï¼‰
        major_chapters = []  # [(start_idx, end_idx), ...]
        current_chapter_start = None
        
        # ç¡®ä¿æ£€æµ‹èŒƒå›´ä»æ­£æ–‡å¼€å§‹ï¼Œä¸åŒ…æ‹¬æ‘˜è¦ã€Abstractã€ç›®å½•ç­‰
        excluded_keywords = ['æ‘˜è¦', 'Abstract', 'ç›®å½•', 'Contents', 'å…³é”®è¯', 'Key words', 'KeyWords']
        
        for idx in range(check_start_idx, check_end_idx):
            paragraph = document.paragraphs[idx]
            para_text = paragraph.text.strip() if paragraph.text else ""
            
            # å†æ¬¡æ£€æŸ¥æ˜¯å¦åœ¨æ’é™¤éƒ¨åˆ†å†…ï¼ˆåŒé‡ä¿é™©ï¼‰
            is_excluded = False
            for keyword in excluded_keywords:
                if re.search(rf'^{re.escape(keyword)}', para_text, re.IGNORECASE):
                    is_excluded = True
                    break
            
            if is_excluded:
                continue
            
            if is_major_chapter_title(paragraph):
                # å¦‚æœä¹‹å‰æœ‰ç« èŠ‚ï¼Œç»“æŸä¹‹å‰çš„ç« èŠ‚
                if current_chapter_start is not None:
                    major_chapters.append((current_chapter_start, idx))
                # å¼€å§‹æ–°çš„å¤§ç« èŠ‚
                current_chapter_start = idx
        
        # å¤„ç†æœ€åä¸€ä¸ªç« èŠ‚
        if current_chapter_start is not None:
            major_chapters.append((current_chapter_start, check_end_idx))
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°å¤§ç« èŠ‚ï¼Œå°†æ•´ä¸ªæ£€æµ‹èŒƒå›´ä½œä¸ºä¸€ä¸ªç« èŠ‚å¤„ç†
        # è¿™æ ·å¯ä»¥ç¡®ä¿å³ä½¿æ²¡æœ‰è¯†åˆ«åˆ°å¤§ç« èŠ‚ï¼Œä¹Ÿèƒ½æ£€æµ‹ç©ºç™½è¡Œ
        if not major_chapters:
            major_chapters = [(check_start_idx, check_end_idx)]
        
        # è°ƒè¯•ä¿¡æ¯ï¼šæ‰“å°è¯†åˆ«åˆ°çš„å¤§ç« èŠ‚
        # print(f"[ç©ºç™½è¡Œæ£€æµ‹] è¯†åˆ«åˆ° {len(major_chapters)} ä¸ªå¤§ç« èŠ‚: {major_chapters}")
        
        # 4. åªåœ¨å¤§ç« èŠ‚å†…éƒ¨æ£€æµ‹ç©ºç™½è¡Œï¼ˆç¡®ä¿ä¸åœ¨æ‘˜è¦ã€Abstractã€ç›®å½•ç­‰éƒ¨åˆ†ï¼‰
        def is_blank_paragraph(paragraph) -> bool:
            para_text = paragraph.text.strip() if paragraph.text else ""
            return len(para_text) == 0
        
        def has_page_break(paragraph) -> bool:
            """æ£€æŸ¥æ®µè½æ˜¯å¦åŒ…å«åˆ†é¡µç¬¦"""
            # æ£€æŸ¥æ®µè½æ ¼å¼ä¸­çš„åˆ†é¡µç¬¦
            if paragraph.paragraph_format.page_break_before:
                return True
            # æ£€æŸ¥runsä¸­çš„åˆ†é¡µç¬¦
            for run in paragraph.runs:
                if hasattr(run, 'element'):
                    run_xml = str(run.element.xml)
                    if 'w:br' in run_xml and 'type="page"' in run_xml:
                        return True
            return False
        
        # æ’é™¤å…³é”®è¯åˆ—è¡¨ï¼ˆæ‘˜è¦ã€Abstractã€ç›®å½•ç­‰éƒ¨åˆ†å®Œå…¨ä¸æ£€æµ‹ç©ºç™½è¡Œï¼‰
        excluded_keywords = ['æ‘˜è¦', 'Abstract', 'ç›®å½•', 'Contents', 'å…³é”®è¯', 'Key words', 'KeyWords']
        
        # å¦‚æœå¤§ç« èŠ‚èŒƒå›´ä¸ºç©ºï¼Œç›´æ¥åœ¨æ•´ä¸ªæ£€æµ‹èŒƒå›´å†…æ£€æµ‹ç©ºç™½è¡Œ
        if not major_chapters:
            # åœ¨æ•´ä¸ªæ£€æµ‹èŒƒå›´å†…æ£€æµ‹ç©ºç™½è¡Œ
            consecutive_blanks = 0
            blank_start_idx = None
            
            for idx in range(check_start_idx, check_end_idx):
                paragraph = document.paragraphs[idx]
                para_text = paragraph.text.strip() if paragraph.text else ""
                
                # æ£€æŸ¥æ˜¯å¦åœ¨æ’é™¤éƒ¨åˆ†å†…
                is_excluded = False
                for keyword in excluded_keywords:
                    if re.search(rf'^{re.escape(keyword)}', para_text, re.IGNORECASE):
                        is_excluded = True
                        break
                
                if is_excluded:
                    consecutive_blanks = 0
                    blank_start_idx = None
                    continue
                
                # æ£€æŸ¥æ˜¯å¦åœ¨è¯šä¿¡æ‰¿è¯ºå’Œæ‘˜è¦ä¹‹é—´ï¼Œå¦‚æœæ˜¯ï¼Œåˆ™ä¸åˆ é™¤ä»»ä½•å†…å®¹
                is_between_integrity_and_abstract = False
                if integrity_end is not None and abstract_zh_start is not None:
                    if blank_start_idx is not None:
                        if integrity_end <= blank_start_idx < abstract_zh_start:
                            is_between_integrity_and_abstract = True
                    elif integrity_end <= idx < abstract_zh_start:
                        is_between_integrity_and_abstract = True
                
                if is_between_integrity_and_abstract:
                    # åœ¨è¯šä¿¡æ‰¿è¯ºå’Œæ‘˜è¦ä¹‹é—´ï¼Œä¸åˆ é™¤ä»»ä½•å†…å®¹ï¼Œé‡ç½®è®¡æ•°
                    consecutive_blanks = 0
                    blank_start_idx = None
                    continue
                
                if is_blank_paragraph(paragraph):
                    if consecutive_blanks == 0:
                        blank_start_idx = idx
                    consecutive_blanks += 1
                else:
                    # é‡åˆ°éç©ºç™½æ®µè½
                    if consecutive_blanks >= 2 and blank_start_idx is not None:
                        # ç›´æ¥åˆ é™¤è¿ç»­ç©ºç™½æ®µè½
                        deleted_count = 0
                        for delete_idx in range(blank_start_idx + consecutive_blanks - 1, blank_start_idx - 1, -1):
                            if delete_idx < len(document.paragraphs):
                                para_to_delete = document.paragraphs[delete_idx]
                                if is_blank_paragraph(para_to_delete):
                                    # æ£€æŸ¥æ˜¯å¦åŒ…å«åˆ†é¡µç¬¦ï¼Œå¦‚æœåŒ…å«åˆ™ä¸åˆ é™¤ï¼ˆé¿å…å¯¼è‡´ç©ºç™½é¡µï¼‰
                                    if has_page_break(para_to_delete):
                                        continue
                                    para_to_delete._element.getparent().remove(para_to_delete._element)
                                    deleted_count += 1
                        
                        if deleted_count > 0:
                            issues.append({
                                "type": "excessive_blanks_in_chapter",
                                "message": f"å·²åˆ é™¤ç¬¬ {blank_start_idx + 1} æ®µåˆ°ç¬¬ {blank_start_idx + consecutive_blanks} æ®µä¹‹é—´çš„ {deleted_count} ä¸ªè¿ç»­ç©ºç™½æ®µè½",
                                "suggestion": "å·²è‡ªåŠ¨åˆ é™¤ç« èŠ‚å†…çš„å¤šä½™ç©ºç™½",
                                "blank_start": blank_start_idx,
                                "blank_count": deleted_count,
                                "paragraph_indices": list(range(blank_start_idx, blank_start_idx + consecutive_blanks))
                            })
                    
                    consecutive_blanks = 0
                    blank_start_idx = None
            
            # å¤„ç†æœ«å°¾çš„è¿ç»­ç©ºç™½
            if consecutive_blanks >= 2 and blank_start_idx is not None:
                deleted_count = 0
                for delete_idx in range(blank_start_idx + consecutive_blanks - 1, blank_start_idx - 1, -1):
                    if delete_idx < len(document.paragraphs):
                        para_to_delete = document.paragraphs[delete_idx]
                        if is_blank_paragraph(para_to_delete):
                            # æ£€æŸ¥ï¼šç¡®ä¿ä¸åˆ é™¤åŒ…å«å­—æ®µä»£ç çš„æ®µè½ï¼ˆå¦‚TOCå­—æ®µï¼‰
                            para_xml = para_to_delete._element.xml if hasattr(para_to_delete._element, 'xml') else ""
                            if 'TOC' in para_xml or 'w:fldChar' in para_xml or 'w:instrText' in para_xml:
                                # åŒ…å«å­—æ®µä»£ç ï¼Œä¸åˆ é™¤
                                continue
                            # æ£€æŸ¥æ˜¯å¦åŒ…å«åˆ†é¡µç¬¦ï¼Œå¦‚æœåŒ…å«åˆ™ä¸åˆ é™¤ï¼ˆé¿å…å¯¼è‡´ç©ºç™½é¡µï¼‰
                            if has_page_break(para_to_delete):
                                continue
                            para_to_delete._element.getparent().remove(para_to_delete._element)
                            deleted_count += 1
                
                if deleted_count > 0:
                    issues.append({
                        "type": "excessive_blanks_in_chapter",
                        "message": f"å·²åˆ é™¤ç¬¬ {blank_start_idx + 1} æ®µåˆ°ç¬¬ {blank_start_idx + consecutive_blanks} æ®µä¹‹é—´çš„ {deleted_count} ä¸ªè¿ç»­ç©ºç™½æ®µè½",
                        "suggestion": "å·²è‡ªåŠ¨åˆ é™¤ç« èŠ‚å†…çš„å¤šä½™ç©ºç™½",
                        "blank_start": blank_start_idx,
                        "blank_count": deleted_count,
                        "paragraph_indices": list(range(blank_start_idx, blank_start_idx + consecutive_blanks))
                    })
        
        for chapter_start, chapter_end in major_chapters:
            consecutive_blanks = 0
            blank_start_idx = None
            
            # åœ¨å¤§ç« èŠ‚å†…éƒ¨éå†
            for idx in range(chapter_start + 1, chapter_end):  # +1 è·³è¿‡ç« èŠ‚æ ‡é¢˜æœ¬èº«
                # ç¡®ä¿ç´¢å¼•åœ¨æ£€æµ‹èŒƒå›´å†…ï¼ˆä»æ­£æ–‡å¼€å§‹ï¼Œä¸åŒ…æ‹¬æ‘˜è¦ã€ç›®å½•ç­‰ï¼‰
                if idx < check_start_idx:
                    continue
                
                paragraph = document.paragraphs[idx]
                para_text = paragraph.text.strip() if paragraph.text else ""
                
                # æ£€æŸ¥æ˜¯å¦åœ¨æ’é™¤éƒ¨åˆ†å†…ï¼ˆæ‘˜è¦ã€Abstractã€ç›®å½•ç­‰éƒ¨åˆ†å®Œå…¨ä¸æ£€æµ‹ï¼‰
                is_excluded = False
                for keyword in excluded_keywords:
                    if re.search(rf'^{re.escape(keyword)}', para_text, re.IGNORECASE):
                        is_excluded = True
                        break
                
                # æ£€æŸ¥æ®µè½æ˜¯å¦åŒ…å«ç›®å½•å­—æ®µä»£ç ï¼ˆTOCå­—æ®µï¼‰ï¼Œå¦‚æœåŒ…å«åˆ™ä¸åˆ é™¤
                if not is_excluded:
                    # æ£€æŸ¥æ®µè½XMLä¸­æ˜¯å¦åŒ…å«TOCå­—æ®µ
                    para_xml = paragraph._element.xml if hasattr(paragraph._element, 'xml') else ""
                    if 'TOC' in para_xml or 'w:fldChar' in para_xml or 'w:instrText' in para_xml:
                        is_excluded = True
                
                if is_excluded:
                    # å¦‚æœåœ¨æ’é™¤éƒ¨åˆ†å†…ï¼Œé‡ç½®ç©ºç™½è®¡æ•°ï¼Œä¸æ£€æµ‹
                    consecutive_blanks = 0
                    blank_start_idx = None
                    continue
                
                # æ£€æŸ¥æ˜¯å¦åœ¨è¯šä¿¡æ‰¿è¯ºå’Œæ‘˜è¦ä¹‹é—´ï¼Œå¦‚æœæ˜¯ï¼Œåˆ™ä¸åˆ é™¤ä»»ä½•å†…å®¹
                is_between_integrity_and_abstract = False
                if integrity_end is not None and abstract_zh_start is not None:
                    if blank_start_idx is not None:
                        if integrity_end <= blank_start_idx < abstract_zh_start:
                            is_between_integrity_and_abstract = True
                    elif integrity_end <= idx < abstract_zh_start:
                        is_between_integrity_and_abstract = True
                
                if is_between_integrity_and_abstract:
                    # åœ¨è¯šä¿¡æ‰¿è¯ºå’Œæ‘˜è¦ä¹‹é—´ï¼Œä¸åˆ é™¤ä»»ä½•å†…å®¹ï¼Œé‡ç½®è®¡æ•°
                    consecutive_blanks = 0
                    blank_start_idx = None
                    continue
                
                if is_blank_paragraph(paragraph):
                    if consecutive_blanks == 0:
                        blank_start_idx = idx
                    consecutive_blanks += 1
                else:
                    # é‡åˆ°éç©ºç™½æ®µè½
                    if consecutive_blanks >= 2 and blank_start_idx is not None:
                        # æ£€æŸ¥ç©ºç™½è¡Œæ˜¯å¦åœ¨ç« èŠ‚è¾¹ç•Œå¤„ï¼ˆç›®å½•å’Œæ­£æ–‡ä¹‹é—´ã€å¤§ç« èŠ‚ä¹‹é—´ï¼‰
                        # å¦‚æœç©ºç™½è¡Œç´§é‚»å¤§ç« èŠ‚æ ‡é¢˜ï¼Œåˆ™ä¸åˆ é™¤ï¼ˆè¿™æ˜¯ç« èŠ‚é—´çš„ç©ºç™½ï¼Œåº”è¯¥ä¿ç•™ï¼‰
                        is_at_chapter_boundary = False
                        
                        # æ£€æŸ¥ç©ºç™½è¡Œä¹‹åæ˜¯å¦æœ‰å¤§ç« èŠ‚æ ‡é¢˜ï¼ˆå¦‚æœç©ºç™½è¡Œåé¢æ˜¯å¤§ç« èŠ‚æ ‡é¢˜ï¼Œè¿™æ˜¯ç« èŠ‚é—´çš„ç©ºç™½ï¼Œä¸åˆ é™¤ï¼‰
                        for next_idx in range(blank_start_idx + consecutive_blanks, min(blank_start_idx + consecutive_blanks + 3, len(document.paragraphs))):
                            if next_idx < len(document.paragraphs):
                                next_para = document.paragraphs[next_idx]
                                if is_major_chapter_title(next_para):
                                    is_at_chapter_boundary = True
                                    break
                        
                        # æ£€æŸ¥ç©ºç™½è¡Œä¹‹å‰æ˜¯å¦æœ‰å¤§ç« èŠ‚æ ‡é¢˜ï¼ˆå¦‚æœç©ºç™½è¡Œå‰é¢æ˜¯å¤§ç« èŠ‚æ ‡é¢˜ï¼Œè¿™ä¹Ÿæ˜¯ç« èŠ‚é—´çš„ç©ºç™½ï¼Œä¸åˆ é™¤ï¼‰
                        if not is_at_chapter_boundary:
                            for prev_idx in range(max(0, blank_start_idx - 2), blank_start_idx):
                                if prev_idx < len(document.paragraphs):
                                    prev_para = document.paragraphs[prev_idx]
                                    if is_major_chapter_title(prev_para):
                                        is_at_chapter_boundary = True
                                        break
                        
                        # æ£€æŸ¥ç©ºç™½è¡Œæ˜¯å¦åœ¨ç›®å½•å’Œæ­£æ–‡ä¹‹é—´
                        # å¦‚æœç©ºç™½è¡Œä¹‹å‰æœ‰"ç›®å½•"å…³é”®è¯ï¼Œä¸”ç©ºç™½è¡Œä¹‹åæœ‰æ­£æ–‡å¼€å§‹æ ‡è®°ï¼ˆå¦‚"1 ç§°é‡æŠ€æœ¯å’Œè¡¡å™¨çš„å‘å±•"ï¼‰ï¼Œåˆ™ä¸åˆ é™¤
                        if not is_at_chapter_boundary:
                            has_toc_before = False
                            has_body_after = False
                            
                            # æ£€æŸ¥ç©ºç™½è¡Œä¹‹å‰æ˜¯å¦æœ‰"ç›®å½•"å…³é”®è¯ï¼ˆæ‰©å¤§æ£€æŸ¥èŒƒå›´åˆ°20ä¸ªæ®µè½ï¼‰
                            for prev_idx in range(max(0, blank_start_idx - 20), blank_start_idx):
                                if prev_idx < len(document.paragraphs):
                                    prev_text = document.paragraphs[prev_idx].text.strip() if document.paragraphs[prev_idx].text else ""
                                    if re.search(r'^(ç›®å½•|Contents)', prev_text, re.IGNORECASE):
                                        has_toc_before = True
                                        break
                            
                            # æ£€æŸ¥ç©ºç™½è¡Œä¹‹åæ˜¯å¦æœ‰æ­£æ–‡å¼€å§‹æ ‡è®°ï¼ˆå¦‚"1 ç§°é‡æŠ€æœ¯å’Œè¡¡å™¨çš„å‘å±•"ã€"ç¬¬ä¸€ç« "ç­‰ï¼‰
                            if has_toc_before:
                                for next_idx in range(blank_start_idx + consecutive_blanks, min(blank_start_idx + consecutive_blanks + 10, len(document.paragraphs))):
                                    if next_idx < len(document.paragraphs):
                                        next_text = document.paragraphs[next_idx].text.strip() if document.paragraphs[next_idx].text else ""
                                        # æ£€æŸ¥æ˜¯å¦æ˜¯æ­£æ–‡å¼€å§‹æ ‡è®°
                                        if (re.match(r'^[1-9]\s+', next_text) or  # 1 ç§°é‡æŠ€æœ¯å’Œè¡¡å™¨çš„å‘å±•
                                            re.match(r'^[1-9]\.', next_text) or  # 1. ç»ªè®º
                                            re.match(r'^ç¬¬ä¸€ç« ', next_text) or  # ç¬¬ä¸€ç« 
                                            re.match(r'^ç¬¬1ç« ', next_text) or  # ç¬¬1ç« 
                                            re.match(r'^ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]ç« ', next_text) or  # ç¬¬ä¸€ç« ã€ç¬¬äºŒç« ç­‰
                                            next_text == "ç»ªè®º" or next_text == "æ¦‚è¿°"):  # ç»ªè®ºã€æ¦‚è¿°
                                            has_body_after = True
                                            break
                            
                            # å¦‚æœç©ºç™½è¡Œåœ¨ç›®å½•å’Œæ­£æ–‡ä¹‹é—´ï¼Œä¸åˆ é™¤
                            if has_toc_before and has_body_after:
                                is_at_chapter_boundary = True
                        
                        # æ£€æŸ¥ç©ºç™½è¡Œä¹‹å‰æ˜¯å¦æœ‰å°èŠ‚æ ‡é¢˜ï¼ˆå¦‚"4. å‰”é™¤ç²—å¤§è¯¯å·®"ï¼‰ï¼Œå¦‚æœæ˜¯å°èŠ‚æ ‡é¢˜åçš„ç©ºç™½ï¼Œåº”è¯¥åˆ é™¤
                        # å°èŠ‚æ ‡é¢˜æ ¼å¼ï¼šæ•°å­—. æ–‡å­—ï¼ˆå¦‚"4. å‰”é™¤ç²—å¤§è¯¯å·®"ï¼‰
                        if is_at_chapter_boundary:
                            # å¦‚æœç©ºç™½è¡Œä¹‹å‰æ˜¯å°èŠ‚æ ‡é¢˜ï¼ˆä¸æ˜¯å¤§ç« èŠ‚ï¼‰ï¼Œåˆ™åº”è¯¥åˆ é™¤
                            for prev_idx in range(max(0, blank_start_idx - 3), blank_start_idx):
                                if prev_idx < len(document.paragraphs):
                                    prev_para = document.paragraphs[prev_idx]
                                    prev_text = prev_para.text.strip() if prev_para.text else ""
                                    # æ£€æŸ¥æ˜¯å¦æ˜¯å°èŠ‚æ ‡é¢˜æ ¼å¼ï¼ˆæ•°å­—. æ–‡å­—ï¼Œä½†ä¸æ˜¯å¤§ç« èŠ‚ï¼‰
                                    if prev_text and re.match(r'^\d+\.\s+', prev_text):
                                        # è¿›ä¸€æ­¥ç¡®è®¤ä¸æ˜¯å¤§ç« èŠ‚ï¼ˆå¤§ç« èŠ‚å¿…é¡»æ˜¯1ã€2ã€3å¼€å¤´ä¸”ä¸‰å·å­—ä½“ï¼‰
                                        if not is_major_chapter_title(prev_para):
                                            # æ˜¯å°èŠ‚æ ‡é¢˜ï¼Œä¸æ˜¯å¤§ç« èŠ‚ï¼Œåº”è¯¥åˆ é™¤ç©ºç™½è¡Œ
                                            is_at_chapter_boundary = False
                                            break
                        
                        # åªæœ‰ä¸åœ¨ç« èŠ‚è¾¹ç•Œå¤„çš„ç©ºç™½è¡Œæ‰åˆ é™¤
                        if not is_at_chapter_boundary:
                            # åœ¨å¤§ç« èŠ‚å†…éƒ¨å‘ç°è¿ç»­ç©ºç™½ï¼Œç›´æ¥åˆ é™¤è¿™äº›ç©ºç™½æ®µè½
                            # ä»åå¾€å‰åˆ é™¤ï¼Œé¿å…ç´¢å¼•å˜åŒ–
                            deleted_count = 0
                            for delete_idx in range(blank_start_idx + consecutive_blanks - 1, blank_start_idx - 1, -1):
                                if delete_idx < len(document.paragraphs):
                                    para_to_delete = document.paragraphs[delete_idx]
                                    # ç¡®è®¤æ˜¯ç©ºç™½æ®µè½å†åˆ é™¤
                                    if is_blank_paragraph(para_to_delete):
                                        # å†æ¬¡æ£€æŸ¥ï¼šç¡®ä¿ä¸åˆ é™¤åŒ…å«å­—æ®µä»£ç çš„æ®µè½ï¼ˆå¦‚TOCå­—æ®µï¼‰
                                        para_xml = para_to_delete._element.xml if hasattr(para_to_delete._element, 'xml') else ""
                                        if 'TOC' in para_xml or 'w:fldChar' in para_xml or 'w:instrText' in para_xml:
                                            # åŒ…å«å­—æ®µä»£ç ï¼Œä¸åˆ é™¤
                                            continue
                                        # æ£€æŸ¥æ˜¯å¦åŒ…å«åˆ†é¡µç¬¦ï¼Œå¦‚æœåŒ…å«åˆ™ä¸åˆ é™¤ï¼ˆé¿å…å¯¼è‡´ç©ºç™½é¡µï¼‰
                                        if has_page_break(para_to_delete):
                                            continue
                                        # åˆ é™¤æ®µè½
                                        para_to_delete._element.getparent().remove(para_to_delete._element)
                                        deleted_count += 1
                            
                            # è®°å½•åˆ é™¤çš„ç©ºç™½æ®µè½ä¿¡æ¯ï¼ˆç”¨äºæŠ¥å‘Šï¼‰
                            if deleted_count > 0:
                                issues.append({
                                    "type": "excessive_blanks_in_chapter",
                                    "message": f"å·²åˆ é™¤ç¬¬ {blank_start_idx + 1} æ®µåˆ°ç¬¬ {blank_start_idx + consecutive_blanks} æ®µä¹‹é—´çš„ {deleted_count} ä¸ªè¿ç»­ç©ºç™½æ®µè½ï¼ˆå¤§ç« èŠ‚å†…ï¼‰",
                                    "suggestion": "å·²è‡ªåŠ¨åˆ é™¤ç« èŠ‚å†…çš„å¤šä½™ç©ºç™½",
                                    "blank_start": blank_start_idx,
                                    "blank_count": deleted_count,
                                    "paragraph_indices": list(range(blank_start_idx, blank_start_idx + consecutive_blanks))
                                })
                    
                    consecutive_blanks = 0
                    blank_start_idx = None
            
            # å¤„ç†ç« èŠ‚æœ«å°¾çš„è¿ç»­ç©ºç™½
            if consecutive_blanks >= 2 and blank_start_idx is not None:
                # å†æ¬¡ç¡®è®¤ä¸åœ¨æ’é™¤éƒ¨åˆ†å†…
                is_excluded = False
                if blank_start_idx < len(document.paragraphs) and blank_start_idx >= check_start_idx:
                    para_text = document.paragraphs[blank_start_idx].text.strip() if document.paragraphs[blank_start_idx].text else ""
                    for keyword in excluded_keywords:
                        if re.search(rf'^{re.escape(keyword)}', para_text, re.IGNORECASE):
                            is_excluded = True
                            break
                
                if not is_excluded and blank_start_idx >= check_start_idx:
                    # æ£€æŸ¥ç©ºç™½è¡Œæ˜¯å¦åœ¨ç« èŠ‚è¾¹ç•Œå¤„ï¼ˆå¦‚æœç©ºç™½è¡Œåé¢æ˜¯å¤§ç« èŠ‚æ ‡é¢˜ï¼Œä¸åˆ é™¤ï¼‰
                    is_at_chapter_boundary = False
                    
                    # æ£€æŸ¥ç©ºç™½è¡Œä¹‹åæ˜¯å¦æœ‰å¤§ç« èŠ‚æ ‡é¢˜ï¼ˆè™½ç„¶å·²ç»åˆ°ç« èŠ‚æœ«å°¾ï¼Œä½†ä¹Ÿè¦æ£€æŸ¥ï¼‰
                    for next_idx in range(blank_start_idx + consecutive_blanks, min(blank_start_idx + consecutive_blanks + 3, len(document.paragraphs))):
                        if next_idx < len(document.paragraphs):
                            next_para = document.paragraphs[next_idx]
                            if is_major_chapter_title(next_para):
                                is_at_chapter_boundary = True
                                break
                    
                    # æ£€æŸ¥ç©ºç™½è¡Œä¹‹å‰æ˜¯å¦æœ‰å¤§ç« èŠ‚æ ‡é¢˜
                    if not is_at_chapter_boundary:
                        for prev_idx in range(max(0, blank_start_idx - 2), blank_start_idx):
                            if prev_idx < len(document.paragraphs):
                                prev_para = document.paragraphs[prev_idx]
                                if is_major_chapter_title(prev_para):
                                    is_at_chapter_boundary = True
                                    break
                    
                    # æ£€æŸ¥ç©ºç™½è¡Œæ˜¯å¦åœ¨ç›®å½•å’Œæ­£æ–‡ä¹‹é—´ï¼ˆå¤„ç†ç« èŠ‚æœ«å°¾çš„è¿ç»­ç©ºç™½æ—¶ä¹Ÿè¦æ£€æŸ¥ï¼‰
                    if not is_at_chapter_boundary:
                        has_toc_before = False
                        has_body_after = False
                        
                        # æ£€æŸ¥ç©ºç™½è¡Œä¹‹å‰æ˜¯å¦æœ‰"ç›®å½•"å…³é”®è¯ï¼ˆæ‰©å¤§æ£€æŸ¥èŒƒå›´åˆ°20ä¸ªæ®µè½ï¼‰
                        for prev_idx in range(max(0, blank_start_idx - 20), blank_start_idx):
                            if prev_idx < len(document.paragraphs):
                                prev_text = document.paragraphs[prev_idx].text.strip() if document.paragraphs[prev_idx].text else ""
                                if re.search(r'^(ç›®å½•|Contents)', prev_text, re.IGNORECASE):
                                    has_toc_before = True
                                    break
                        
                        # æ£€æŸ¥ç©ºç™½è¡Œä¹‹åæ˜¯å¦æœ‰æ­£æ–‡å¼€å§‹æ ‡è®°ï¼ˆå¦‚"1 ç§°é‡æŠ€æœ¯å’Œè¡¡å™¨çš„å‘å±•"ã€"ç¬¬ä¸€ç« "ç­‰ï¼‰
                        if has_toc_before:
                            for next_idx in range(blank_start_idx + consecutive_blanks, min(blank_start_idx + consecutive_blanks + 10, len(document.paragraphs))):
                                if next_idx < len(document.paragraphs):
                                    next_text = document.paragraphs[next_idx].text.strip() if document.paragraphs[next_idx].text else ""
                                    # æ£€æŸ¥æ˜¯å¦æ˜¯æ­£æ–‡å¼€å§‹æ ‡è®°
                                    if (re.match(r'^[1-9]\s+', next_text) or  # 1 ç§°é‡æŠ€æœ¯å’Œè¡¡å™¨çš„å‘å±•
                                        re.match(r'^[1-9]\.', next_text) or  # 1. ç»ªè®º
                                        re.match(r'^ç¬¬ä¸€ç« ', next_text) or  # ç¬¬ä¸€ç« 
                                        re.match(r'^ç¬¬1ç« ', next_text) or  # ç¬¬1ç« 
                                        re.match(r'^ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]ç« ', next_text) or  # ç¬¬ä¸€ç« ã€ç¬¬äºŒç« ç­‰
                                        next_text == "ç»ªè®º" or next_text == "æ¦‚è¿°"):  # ç»ªè®ºã€æ¦‚è¿°
                                        has_body_after = True
                                        break
                        
                        # å¦‚æœç©ºç™½è¡Œåœ¨ç›®å½•å’Œæ­£æ–‡ä¹‹é—´ï¼Œä¸åˆ é™¤
                        if has_toc_before and has_body_after:
                            is_at_chapter_boundary = True
                    
                    # åªæœ‰ä¸åœ¨ç« èŠ‚è¾¹ç•Œå¤„çš„ç©ºç™½è¡Œæ‰åˆ é™¤
                    if not is_at_chapter_boundary:
                        # ç›´æ¥åˆ é™¤ç« èŠ‚æœ«å°¾çš„è¿ç»­ç©ºç™½æ®µè½
                        # ä»åå¾€å‰åˆ é™¤ï¼Œé¿å…ç´¢å¼•å˜åŒ–
                        deleted_count = 0
                        for delete_idx in range(blank_start_idx + consecutive_blanks - 1, blank_start_idx - 1, -1):
                            if delete_idx < len(document.paragraphs):
                                para_to_delete = document.paragraphs[delete_idx]
                                # ç¡®è®¤æ˜¯ç©ºç™½æ®µè½å†åˆ é™¤
                                if is_blank_paragraph(para_to_delete):
                                    # å†æ¬¡æ£€æŸ¥ï¼šç¡®ä¿ä¸åˆ é™¤åŒ…å«å­—æ®µä»£ç çš„æ®µè½ï¼ˆå¦‚TOCå­—æ®µï¼‰
                                    para_xml = para_to_delete._element.xml if hasattr(para_to_delete._element, 'xml') else ""
                                    if 'TOC' in para_xml or 'w:fldChar' in para_xml or 'w:instrText' in para_xml:
                                        # åŒ…å«å­—æ®µä»£ç ï¼Œä¸åˆ é™¤
                                        continue
                                    # æ£€æŸ¥æ˜¯å¦åŒ…å«åˆ†é¡µç¬¦ï¼Œå¦‚æœåŒ…å«åˆ™ä¸åˆ é™¤ï¼ˆé¿å…å¯¼è‡´ç©ºç™½é¡µï¼‰
                                    if has_page_break(para_to_delete):
                                        continue
                                    # åˆ é™¤æ®µè½
                                    para_to_delete._element.getparent().remove(para_to_delete._element)
                                    deleted_count += 1
                        
                        # è®°å½•åˆ é™¤çš„ç©ºç™½æ®µè½ä¿¡æ¯ï¼ˆç”¨äºæŠ¥å‘Šï¼‰
                        if deleted_count > 0:
                            issues.append({
                                "type": "excessive_blanks_in_chapter",
                                "message": f"å·²åˆ é™¤ç¬¬ {blank_start_idx + 1} æ®µåˆ°ç¬¬ {blank_start_idx + consecutive_blanks} æ®µä¹‹é—´çš„ {deleted_count} ä¸ªè¿ç»­ç©ºç™½æ®µè½ï¼ˆå¤§ç« èŠ‚å†…ï¼‰",
                                "suggestion": "å·²è‡ªåŠ¨åˆ é™¤ç« èŠ‚å†…çš„å¤šä½™ç©ºç™½",
                                "blank_start": blank_start_idx,
                                "blank_count": deleted_count,
                                "paragraph_indices": list(range(blank_start_idx, blank_start_idx + consecutive_blanks))
                            })
        
        # ç©ºç™½æ®µè½å·²ç›´æ¥åˆ é™¤ï¼Œä¸éœ€è¦æ ‡è®°
        return issues

    def _diagnose_integrity_abstract_separation(self, document: Document) -> Dict:
        """
        è¯Šæ–­è¯šä¿¡æ‰¿è¯ºå’Œæ‘˜è¦ä¹‹é—´çš„åˆ†é¡µæƒ…å†µ
        
        Returns:
            è¯Šæ–­ä¿¡æ¯å­—å…¸
        """
        diagnosis = {
            "integrity_found": False,
            "abstract_found": False,
            "integrity_start_idx": None,
            "abstract_start_idx": None,
            "has_page_break_between": False,
            "page_break_locations": [],
            "paragraphs_between": [],
            "issue": None
        }
        
        # æŸ¥æ‰¾è¯šä¿¡æ‰¿è¯º
        integrity_pattern = re.compile(r'è¯š\s*ä¿¡\s*æ‰¿\s*è¯º', re.IGNORECASE)
        for idx, paragraph in enumerate(document.paragraphs):
            para_text = paragraph.text.strip() if paragraph.text else ""
            if integrity_pattern.search(para_text) and not diagnosis["integrity_found"]:
                diagnosis["integrity_found"] = True
                diagnosis["integrity_start_idx"] = idx
                self._log_to_file(f"[è¯Šæ–­] æ‰¾åˆ°è¯šä¿¡æ‰¿è¯ºï¼Œæ®µè½ç´¢å¼•: {idx}, æ–‡æœ¬: {para_text[:50]}")
                break
        
        # æŸ¥æ‰¾æ‘˜è¦
        abstract_pattern = re.compile(r'^æ‘˜\s*è¦', re.IGNORECASE)
        for idx, paragraph in enumerate(document.paragraphs):
            para_text = paragraph.text.strip() if paragraph.text else ""
            if abstract_pattern.match(para_text) and not diagnosis["abstract_found"]:
                diagnosis["abstract_found"] = True
                diagnosis["abstract_start_idx"] = idx
                self._log_to_file(f"[è¯Šæ–­] æ‰¾åˆ°æ‘˜è¦ï¼Œæ®µè½ç´¢å¼•: {idx}, æ–‡æœ¬: {para_text[:50]}")
                break
        
        if not diagnosis["integrity_found"] or not diagnosis["abstract_found"]:
            diagnosis["issue"] = "æœªæ‰¾åˆ°è¯šä¿¡æ‰¿è¯ºæˆ–æ‘˜è¦"
            return diagnosis
        
        if diagnosis["abstract_start_idx"] <= diagnosis["integrity_start_idx"]:
            diagnosis["issue"] = "æ‘˜è¦åœ¨è¯šä¿¡æ‰¿è¯ºä¹‹å‰ï¼Œé¡ºåºå¼‚å¸¸"
            return diagnosis
        
        # æ£€æŸ¥è¯šä¿¡æ‰¿è¯ºå’Œæ‘˜è¦ä¹‹é—´çš„æ®µè½
        start_idx = diagnosis["integrity_start_idx"]
        end_idx = diagnosis["abstract_start_idx"]
        
        self._log_to_file(f"[è¯Šæ–­] è¯šä¿¡æ‰¿è¯ºå’Œæ‘˜è¦ä¹‹é—´çš„æ®µè½ç´¢å¼•: {start_idx} åˆ° {end_idx}")
        
        # æ£€æŸ¥æ¯ä¸ªæ®µè½æ˜¯å¦æœ‰åˆ†é¡µç¬¦
        for idx in range(start_idx, end_idx):
            paragraph = document.paragraphs[idx]
            para_text = paragraph.text.strip() if paragraph.text else ""
            
            # æ£€æŸ¥æ®µè½æ ¼å¼ä¸­çš„åˆ†é¡µç¬¦
            has_page_break = False
            if paragraph.paragraph_format.page_break_before:
                has_page_break = True
                diagnosis["page_break_locations"].append({
                    "index": idx,
                    "type": "paragraph_format.page_break_before",
                    "text": para_text[:50]
                })
                self._log_to_file(f"[è¯Šæ–­] æ®µè½ {idx} æœ‰åˆ†é¡µç¬¦ (paragraph_format.page_break_before): {para_text[:50]}")
            
            # æ£€æŸ¥runsä¸­çš„åˆ†é¡µç¬¦
            for run_idx, run in enumerate(paragraph.runs):
                if hasattr(run, 'element'):
                    run_xml = str(run.element.xml)
                    if 'w:br' in run_xml and 'type="page"' in run_xml:
                        has_page_break = True
                        diagnosis["page_break_locations"].append({
                            "index": idx,
                            "type": f"run_{run_idx}_page_break",
                            "text": para_text[:50]
                        })
                        self._log_to_file(f"[è¯Šæ–­] æ®µè½ {idx}, Run {run_idx} æœ‰åˆ†é¡µç¬¦: {para_text[:50]}")
            
            # è®°å½•æ®µè½ä¿¡æ¯
            diagnosis["paragraphs_between"].append({
                "index": idx,
                "text": para_text[:100],
                "has_page_break": has_page_break,
                "is_blank": len(para_text) == 0
            })
        
        # æ£€æŸ¥æ‘˜è¦æ ‡é¢˜æœ¬èº«æ˜¯å¦æœ‰åˆ†é¡µç¬¦
        abstract_para = document.paragraphs[diagnosis["abstract_start_idx"]]
        if abstract_para.paragraph_format.page_break_before:
            diagnosis["has_page_break_between"] = True
            diagnosis["page_break_locations"].append({
                "index": diagnosis["abstract_start_idx"],
                "type": "abstract_title_page_break_before",
                "text": abstract_para.text.strip()[:50]
            })
            self._log_to_file(f"[è¯Šæ–­] æ‘˜è¦æ ‡é¢˜æœ¬èº«æœ‰åˆ†é¡µç¬¦ (page_break_before)")
        
        # æ£€æŸ¥æ‘˜è¦æ ‡é¢˜çš„runsä¸­æ˜¯å¦æœ‰åˆ†é¡µç¬¦
        for run_idx, run in enumerate(abstract_para.runs):
            if hasattr(run, 'element'):
                run_xml = str(run.element.xml)
                if 'w:br' in run_xml and 'type="page"' in run_xml:
                    diagnosis["has_page_break_between"] = True
                    diagnosis["page_break_locations"].append({
                        "index": diagnosis["abstract_start_idx"],
                        "type": f"abstract_title_run_{run_idx}_page_break",
                        "text": abstract_para.text.strip()[:50]
                    })
                    self._log_to_file(f"[è¯Šæ–­] æ‘˜è¦æ ‡é¢˜çš„Run {run_idx} æœ‰åˆ†é¡µç¬¦")
        
        # æ£€æŸ¥å‰ä¸€ä¸ªæ®µè½æ˜¯å¦æœ‰åˆ†é¡µç¬¦
        if diagnosis["abstract_start_idx"] > 0:
            prev_para = document.paragraphs[diagnosis["abstract_start_idx"] - 1]
            if prev_para.paragraph_format.page_break_before:
                diagnosis["has_page_break_between"] = True
                diagnosis["page_break_locations"].append({
                    "index": diagnosis["abstract_start_idx"] - 1,
                    "type": "prev_paragraph_page_break_before",
                    "text": prev_para.text.strip()[:50]
                })
                self._log_to_file(f"[è¯Šæ–­] æ‘˜è¦å‰ä¸€ä¸ªæ®µè½æœ‰åˆ†é¡µç¬¦ (page_break_before)")
            
            for run_idx, run in enumerate(prev_para.runs):
                if hasattr(run, 'element'):
                    run_xml = str(run.element.xml)
                    if 'w:br' in run_xml and 'type="page"' in run_xml:
                        diagnosis["has_page_break_between"] = True
                        diagnosis["page_break_locations"].append({
                            "index": diagnosis["abstract_start_idx"] - 1,
                            "type": f"prev_paragraph_run_{run_idx}_page_break",
                            "text": prev_para.text.strip()[:50]
                        })
                        self._log_to_file(f"[è¯Šæ–­] æ‘˜è¦å‰ä¸€ä¸ªæ®µè½çš„Run {run_idx} æœ‰åˆ†é¡µç¬¦")
        
        if not diagnosis["has_page_break_between"]:
            diagnosis["issue"] = "è¯šä¿¡æ‰¿è¯ºå’Œæ‘˜è¦ä¹‹é—´æ²¡æœ‰åˆ†é¡µç¬¦"
        else:
            diagnosis["issue"] = None
        
        return diagnosis

    def _ensure_integrity_abstract_separation(self, document: Document) -> bool:
        """
        ç¡®ä¿è¯šä¿¡æ‰¿è¯ºå’Œæ‘˜è¦åˆ†å¼€åœ¨ä¸åŒé¡µ
        
        å¦‚æœå®ƒä»¬ä¹‹é—´æ²¡æœ‰åˆ†é¡µç¬¦ï¼Œåœ¨æ‘˜è¦æ ‡é¢˜å‰æ·»åŠ åˆ†é¡µç¬¦
        
        Returns:
            bool: æ˜¯å¦è¿›è¡Œäº†ä¿®å¤
        """
        # 1. æŸ¥æ‰¾è¯šä¿¡æ‰¿è¯ºå’Œæ‘˜è¦çš„ä½ç½®
        section_ranges = self._find_section_ranges(document)
        
        self._log_to_file(f"[ä¿®å¤] æŸ¥æ‰¾ç»“æœ: {list(section_ranges.keys())}")
        
        if "integrity" not in section_ranges or "abstract_zh" not in section_ranges:
            self._log_to_file(f"[ä¿®å¤] âŒ æœªæ‰¾åˆ°è¯šä¿¡æ‰¿è¯ºæˆ–æ‘˜è¦ï¼Œè·³è¿‡åˆ†é¡µä¿®å¤")
            if "integrity" not in section_ranges:
                self._log_to_file(f"[ä¿®å¤]   ç¼ºå°‘: integrity")
            if "abstract_zh" not in section_ranges:
                self._log_to_file(f"[ä¿®å¤]   ç¼ºå°‘: abstract_zh")
            return False
        
        integrity_start, integrity_end = section_ranges["integrity"]
        abstract_zh_start, _ = section_ranges["abstract_zh"]
        
        self._log_to_file(f"[ä¿®å¤] è¯šä¿¡æ‰¿è¯ºèŒƒå›´: {integrity_start} åˆ° {integrity_end}")
        self._log_to_file(f"[ä¿®å¤] æ‘˜è¦èµ·å§‹ä½ç½®: {abstract_zh_start}")
        
        # 2. æ£€æŸ¥æ‘˜è¦æ ‡é¢˜å‰æ˜¯å¦æœ‰åˆ†é¡µç¬¦
        if abstract_zh_start >= len(document.paragraphs):
            self._log_to_file(f"[ä¿®å¤] âš ï¸ æ‘˜è¦ä½ç½®è¶…å‡ºæ–‡æ¡£èŒƒå›´")
            return False
        
        abstract_para = document.paragraphs[abstract_zh_start]
        
        # æ£€æŸ¥æ‘˜è¦æ ‡é¢˜æœ¬èº«æ˜¯å¦æœ‰åˆ†é¡µç¬¦
        if abstract_para.paragraph_format.page_break_before:
            self._log_to_file(f"[ä¿®å¤] âœ… æ‘˜è¦æ ‡é¢˜å·²æœ‰åˆ†é¡µç¬¦ (page_break_before)")
            return False  # å·²ç»æœ‰åˆ†é¡µç¬¦
        
        # æ£€æŸ¥æ‘˜è¦æ ‡é¢˜çš„runsä¸­æ˜¯å¦æœ‰åˆ†é¡µç¬¦
        for run in abstract_para.runs:
            if hasattr(run, 'element'):
                run_xml = str(run.element.xml)
                if 'w:br' in run_xml and 'type="page"' in run_xml:
                    self._log_to_file(f"[ä¿®å¤] âœ… æ‘˜è¦æ ‡é¢˜çš„runsä¸­å·²æœ‰åˆ†é¡µç¬¦")
                    return False  # å·²ç»æœ‰åˆ†é¡µç¬¦
        
        # æ£€æŸ¥å‰ä¸€ä¸ªæ®µè½æ˜¯å¦æœ‰åˆ†é¡µç¬¦
        if abstract_zh_start > 0:
            prev_para = document.paragraphs[abstract_zh_start - 1]
            if prev_para.paragraph_format.page_break_before:
                self._log_to_file(f"[ä¿®å¤] âœ… æ‘˜è¦å‰ä¸€ä¸ªæ®µè½å·²æœ‰åˆ†é¡µç¬¦ (page_break_before)")
                return False  # å·²ç»æœ‰åˆ†é¡µç¬¦
            
            for run in prev_para.runs:
                if hasattr(run, 'element'):
                    run_xml = str(run.element.xml)
                    if 'w:br' in run_xml and 'type="page"' in run_xml:
                        self._log_to_file(f"[ä¿®å¤] âœ… æ‘˜è¦å‰ä¸€ä¸ªæ®µè½çš„runsä¸­å·²æœ‰åˆ†é¡µç¬¦")
                        return False  # å·²ç»æœ‰åˆ†é¡µç¬¦
        
        # 3. æ²¡æœ‰åˆ†é¡µç¬¦ï¼Œå¼ºåˆ¶æ·»åŠ åˆ†é¡µç¬¦
        self._log_to_file(f"[ä¿®å¤] âš ï¸ è¯šä¿¡æ‰¿è¯ºå’Œæ‘˜è¦ä¹‹é—´æ²¡æœ‰åˆ†é¡µç¬¦ï¼Œå¼ºåˆ¶æ·»åŠ åˆ†é¡µç¬¦")
        
        # æ–¹æ³•1ï¼šåœ¨æ‘˜è¦æ ‡é¢˜æ®µè½è®¾ç½®åˆ†é¡µç¬¦
        abstract_para.paragraph_format.page_break_before = True
        self._log_to_file(f"[ä¿®å¤] æ–¹æ³•1ï¼šå·²åœ¨æ‘˜è¦æ ‡é¢˜æ®µè½è®¾ç½®åˆ†é¡µç¬¦ (page_break_before)")
        
        # æ–¹æ³•3ï¼šåœ¨æ‘˜è¦æ ‡é¢˜çš„runsä¸­æ·»åŠ åˆ†é¡µç¬¦ï¼ˆæœ€å¯é çš„æ–¹æ³•ï¼‰
        # å¦‚æœæ‘˜è¦æ ‡é¢˜æœ‰runsï¼Œåœ¨ç¬¬ä¸€ä¸ªrunå‰æ·»åŠ åˆ†é¡µç¬¦
        if abstract_para.runs:
            # è·å–ç¬¬ä¸€ä¸ªrun
            first_run = abstract_para.runs[0]
            # åœ¨ç¬¬ä¸€ä¸ªrunå‰æ’å…¥åˆ†é¡µç¬¦ï¼ˆä½¿ç”¨æ­£ç¡®çš„XMLæ ¼å¼ï¼‰
            br_xml = '<w:br xmlns:w="http://schemas.openxmlformats.org/wordprocessingml/2006/main" w:type="page"/>'
            br = parse_xml(br_xml)
            first_run._element.getparent().insert(0, br)
            self._log_to_file(f"[ä¿®å¤] âœ… å·²åœ¨æ‘˜è¦æ ‡é¢˜çš„ç¬¬ä¸€ä¸ªrunå‰æ·»åŠ åˆ†é¡µç¬¦")
        else:
            # å¦‚æœæ²¡æœ‰runsï¼Œåˆ›å»ºä¸€ä¸ªrunå¹¶æ·»åŠ åˆ†é¡µç¬¦
            run = abstract_para.add_run()
            br_xml = '<w:br xmlns:w="http://schemas.openxmlformats.org/wordprocessingml/2006/main" w:type="page"/>'
            br = parse_xml(br_xml)
            run._element.getparent().insert(0, br)
            self._log_to_file(f"[ä¿®å¤] âœ… å·²åˆ›å»ºrunå¹¶æ·»åŠ åˆ†é¡µç¬¦")
        
        self._log_to_file(f"[ä¿®å¤] âœ… å·²ä½¿ç”¨å¤šç§æ–¹æ³•å¼ºåˆ¶æ·»åŠ åˆ†é¡µç¬¦ï¼Œç¡®ä¿è¯šä¿¡æ‰¿è¯ºå’Œæ‘˜è¦åˆ†å¼€")
        return True

    def _ensure_abstract_separation(self, document: Document) -> bool:
        """
        ç¡®ä¿ä¸­æ–‡æ‘˜è¦å’Œè‹±æ–‡æ‘˜è¦åˆ†å¼€åœ¨ä¸åŒé¡µ
        
        Returns:
            bool: æ˜¯å¦è¿›è¡Œäº†ä¿®å¤
        """
        # 1. æŸ¥æ‰¾ä¸­æ–‡æ‘˜è¦å’Œè‹±æ–‡æ‘˜è¦çš„ä½ç½®
        section_ranges = self._find_section_ranges(document)
        
        if "abstract_zh" not in section_ranges:
            self._log_to_file(f"[ä¿®å¤] âŒ æœªæ‰¾åˆ°ä¸­æ–‡æ‘˜è¦ï¼Œè·³è¿‡åˆ†é¡µä¿®å¤")
            return False
        
        if "abstract_en" not in section_ranges:
            self._log_to_file(f"[ä¿®å¤] âŒ æœªæ‰¾åˆ°è‹±æ–‡æ‘˜è¦ï¼Œè·³è¿‡åˆ†é¡µä¿®å¤")
            self._log_to_file(f"[ä¿®å¤] å·²æ‰¾åˆ°çš„section: {list(section_ranges.keys())}")
            # å°è¯•é‡æ–°æŸ¥æ‰¾è‹±æ–‡æ‘˜è¦ï¼ˆå¯èƒ½æ˜¯å¤§å°å†™é—®é¢˜ï¼‰
            for idx in range(0, len(document.paragraphs)):
                para_text = document.paragraphs[idx].text.strip() if document.paragraphs[idx].text else ""
                if re.match(r'^abstract', para_text, re.IGNORECASE):
                    self._log_to_file(f"[ä¿®å¤] é‡æ–°æ‰¾åˆ°è‹±æ–‡æ‘˜è¦ï¼Œæ®µè½ç´¢å¼•: {idx}, æ–‡æœ¬: {para_text[:50]}")
                    # æ‰‹åŠ¨è®¾ç½®è‹±æ–‡æ‘˜è¦èŒƒå›´
                    section_ranges["abstract_en"] = (idx, len(document.paragraphs))
                    break
            if "abstract_en" not in section_ranges:
                return False
        
        abstract_zh_start, abstract_zh_end = section_ranges["abstract_zh"]
        abstract_en_start, _ = section_ranges["abstract_en"]
        
        self._log_to_file(f"[ä¿®å¤] ä¸­æ–‡æ‘˜è¦èŒƒå›´: {abstract_zh_start} åˆ° {abstract_zh_end}")
        self._log_to_file(f"[ä¿®å¤] è‹±æ–‡æ‘˜è¦èµ·å§‹ä½ç½®: {abstract_en_start}")
        
        # 2. æ£€æŸ¥è‹±æ–‡æ‘˜è¦æ ‡é¢˜å‰æ˜¯å¦æœ‰åˆ†é¡µç¬¦
        if abstract_en_start >= len(document.paragraphs):
            self._log_to_file(f"[ä¿®å¤] âš ï¸ è‹±æ–‡æ‘˜è¦ä½ç½®è¶…å‡ºæ–‡æ¡£èŒƒå›´")
            return False
        
        abstract_en_para = document.paragraphs[abstract_en_start]
        
        # æ£€æŸ¥è‹±æ–‡æ‘˜è¦æ ‡é¢˜æœ¬èº«æ˜¯å¦æœ‰åˆ†é¡µç¬¦
        if abstract_en_para.paragraph_format.page_break_before:
            self._log_to_file(f"[ä¿®å¤] âœ… è‹±æ–‡æ‘˜è¦æ ‡é¢˜å·²æœ‰åˆ†é¡µç¬¦ (page_break_before)")
            return False  # å·²ç»æœ‰åˆ†é¡µç¬¦
        
        # æ£€æŸ¥è‹±æ–‡æ‘˜è¦æ ‡é¢˜çš„runsä¸­æ˜¯å¦æœ‰åˆ†é¡µç¬¦
        for run in abstract_en_para.runs:
            if hasattr(run, 'element'):
                run_xml = str(run.element.xml)
                if 'w:br' in run_xml and 'type="page"' in run_xml:
                    self._log_to_file(f"[ä¿®å¤] âœ… è‹±æ–‡æ‘˜è¦æ ‡é¢˜çš„runsä¸­å·²æœ‰åˆ†é¡µç¬¦")
                    return False  # å·²ç»æœ‰åˆ†é¡µç¬¦
        
        # æ£€æŸ¥å‰ä¸€ä¸ªæ®µè½æ˜¯å¦æœ‰åˆ†é¡µç¬¦
        if abstract_en_start > 0:
            prev_para = document.paragraphs[abstract_en_start - 1]
            if prev_para.paragraph_format.page_break_before:
                self._log_to_file(f"[ä¿®å¤] âœ… è‹±æ–‡æ‘˜è¦å‰ä¸€ä¸ªæ®µè½å·²æœ‰åˆ†é¡µç¬¦ (page_break_before)")
                return False  # å·²ç»æœ‰åˆ†é¡µç¬¦
            
            for run in prev_para.runs:
                if hasattr(run, 'element'):
                    run_xml = str(run.element.xml)
                    if 'w:br' in run_xml and 'type="page"' in run_xml:
                        self._log_to_file(f"[ä¿®å¤] âœ… è‹±æ–‡æ‘˜è¦å‰ä¸€ä¸ªæ®µè½çš„runsä¸­å·²æœ‰åˆ†é¡µç¬¦")
                        return False  # å·²ç»æœ‰åˆ†é¡µç¬¦
        
        # 3. æ²¡æœ‰åˆ†é¡µç¬¦ï¼Œå¼ºåˆ¶æ·»åŠ åˆ†é¡µç¬¦
        self._log_to_file(f"[ä¿®å¤] âš ï¸ ä¸­æ–‡æ‘˜è¦å’Œè‹±æ–‡æ‘˜è¦ä¹‹é—´æ²¡æœ‰åˆ†é¡µç¬¦ï¼Œå¼ºåˆ¶æ·»åŠ åˆ†é¡µç¬¦")
        
        # æ–¹æ³•1ï¼šåœ¨è‹±æ–‡æ‘˜è¦æ ‡é¢˜æ®µè½è®¾ç½®åˆ†é¡µç¬¦
        abstract_en_para.paragraph_format.page_break_before = True
        
        # æ–¹æ³•2ï¼šåœ¨è‹±æ–‡æ‘˜è¦æ ‡é¢˜çš„runsä¸­æ·»åŠ åˆ†é¡µç¬¦ï¼ˆæœ€å¯é çš„æ–¹æ³•ï¼‰
        if abstract_en_para.runs:
            # è·å–ç¬¬ä¸€ä¸ªrun
            first_run = abstract_en_para.runs[0]
            # åœ¨ç¬¬ä¸€ä¸ªrunå‰æ’å…¥åˆ†é¡µç¬¦
            br_xml = '<w:br xmlns:w="http://schemas.openxmlformats.org/wordprocessingml/2006/main" w:type="page"/>'
            br = parse_xml(br_xml)
            first_run._element.getparent().insert(0, br)
            self._log_to_file(f"[ä¿®å¤] âœ… å·²åœ¨è‹±æ–‡æ‘˜è¦æ ‡é¢˜çš„ç¬¬ä¸€ä¸ªrunå‰æ·»åŠ åˆ†é¡µç¬¦")
        else:
            # å¦‚æœæ²¡æœ‰runsï¼Œåˆ›å»ºä¸€ä¸ªrunå¹¶æ·»åŠ åˆ†é¡µç¬¦
            run = abstract_en_para.add_run()
            br_xml = '<w:br xmlns:w="http://schemas.openxmlformats.org/wordprocessingml/2006/main" w:type="page"/>'
            br = parse_xml(br_xml)
            run._element.getparent().insert(0, br)
            self._log_to_file(f"[ä¿®å¤] âœ… å·²åˆ›å»ºrunå¹¶æ·»åŠ åˆ†é¡µç¬¦")
        
        self._log_to_file(f"[ä¿®å¤] âœ… å·²ä½¿ç”¨å¤šç§æ–¹æ³•å¼ºåˆ¶æ·»åŠ åˆ†é¡µç¬¦ï¼Œç¡®ä¿ä¸­æ–‡æ‘˜è¦å’Œè‹±æ–‡æ‘˜è¦åˆ†å¼€")
        return True

    def _check_and_remove_blank_pages(self, document: Document) -> list:
        """
        æ£€æµ‹å¹¶åˆ é™¤æ•´é¡µç©ºç™½é¡µ
        
        è§„åˆ™ï¼š
        - åœ¨æ•´ä¸ªæ–‡æ¡£ä¸­æ£€æµ‹æ•´é¡µç©ºç™½ï¼ˆåŒ…æ‹¬å°é¢ã€è¯šä¿¡æ‰¿è¯ºã€æ‘˜è¦ã€ç›®å½•ã€æ­£æ–‡ç­‰æ‰€æœ‰éƒ¨åˆ†ï¼‰
        - å°é¢ã€è¯šä¿¡æ‰¿è¯ºã€æ‘˜è¦ã€ç›®å½•ç­‰éƒ¨åˆ†çš„ç©ºç™½è¡Œä¸åˆ é™¤ï¼Œä½†æ•´é¡µç©ºç™½è¦åˆ é™¤
        - æ£€æµ‹è¿ç»­çš„ç©ºç™½æ®µè½ï¼Œå¦‚æœè¿™äº›ç©ºç™½æ®µè½å¯¼è‡´æ•´é¡µç©ºç™½ï¼Œåˆ™åˆ é™¤
        - ä¸å…è®¸æ•´é¡µç©ºç™½é¡µå­˜åœ¨
        
        Returns:
            é—®é¢˜åˆ—è¡¨
        """
        issues = []
        
        # æ£€æµ‹æ•´é¡µç©ºç™½é¡µçš„æ–¹æ³•ï¼š
        # 1. æŸ¥æ‰¾è¿ç»­çš„å¤§é‡ç©ºç™½æ®µè½ï¼ˆå¯èƒ½æ˜¯æ•´é¡µç©ºç™½ï¼‰
        # 2. æ£€æŸ¥è¿™äº›ç©ºç™½æ®µè½æ˜¯å¦åŒ…å«åˆ†é¡µç¬¦
        # 3. å¦‚æœç¡®è®¤æ˜¯æ•´é¡µç©ºç™½ï¼Œåˆ é™¤è¿™äº›ç©ºç™½æ®µè½
        
        # å®šä¹‰æ•´é¡µç©ºç™½çš„é˜ˆå€¼ï¼š
        # - è¿ç»­10ä¸ªä»¥ä¸Šç©ºç™½æ®µè½å¯èƒ½æ˜¯æ•´é¡µç©ºç™½
        # - è¿ç»­5ä¸ªä»¥ä¸Šç©ºç™½æ®µè½ï¼Œä¸”å‰åæœ‰åˆ†é¡µç¬¦ï¼Œå¯èƒ½æ˜¯åªæœ‰é¡µçœ‰çš„ç©ºç™½é¡µ
        BLANK_PAGE_THRESHOLD = 10
        BLANK_PAGE_WITH_HEADER_THRESHOLD = 5  # åªæœ‰é¡µçœ‰çš„ç©ºç™½é¡µé˜ˆå€¼
        
        def has_page_break(paragraph) -> bool:
            """æ£€æŸ¥æ®µè½æ˜¯å¦åŒ…å«åˆ†é¡µç¬¦"""
            # æ£€æŸ¥æ®µè½æ ¼å¼ä¸­çš„åˆ†é¡µç¬¦
            if paragraph.paragraph_format.page_break_before:
                return True
            # æ£€æŸ¥runsä¸­çš„åˆ†é¡µç¬¦
            for run in paragraph.runs:
                if hasattr(run, 'element'):
                    run_xml = str(run.element.xml)
                    if 'w:br' in run_xml and 'type="page"' in run_xml:
                        return True
            return False
        
        consecutive_blanks = 0
        blank_start_idx = None
        
        # è·å–è¯šä¿¡æ‰¿è¯ºå’Œæ‘˜è¦çš„èŒƒå›´ï¼Œç¡®ä¿ä¸åˆ é™¤å®ƒä»¬ä¹‹é—´çš„å†…å®¹
        section_ranges = self._find_section_ranges(document)
        integrity_start = None
        integrity_end = None
        abstract_zh_start = None
        abstract_zh_end = None
        abstract_en_start = None
        abstract_en_end = None
        if "integrity" in section_ranges:
            integrity_start, integrity_end = section_ranges["integrity"]
        if "abstract_zh" in section_ranges:
            abstract_zh_start, abstract_zh_end = section_ranges["abstract_zh"]
        if "abstract_en" in section_ranges:
            abstract_en_start, abstract_en_end = section_ranges["abstract_en"]
            self._log_to_file(f"[ç©ºç™½é¡µæ£€æµ‹] è‹±æ–‡æ‘˜è¦èŒƒå›´: {abstract_en_start} åˆ° {abstract_en_end}")
        else:
            self._log_to_file(f"[ç©ºç™½é¡µæ£€æµ‹] âš ï¸ æœªæ‰¾åˆ°è‹±æ–‡æ‘˜è¦èŒƒå›´")
        
        # åœ¨æ•´ä¸ªæ–‡æ¡£ä¸­æ£€æµ‹æ•´é¡µç©ºç™½
        # ä½¿ç”¨whileå¾ªç¯ï¼Œå› ä¸ºåˆ é™¤æ®µè½åç´¢å¼•ä¼šå˜åŒ–
        idx = 0
        while idx < len(document.paragraphs):
            paragraph = document.paragraphs[idx]
            para_text = paragraph.text.strip() if paragraph.text else ""
            
            # æ£€æŸ¥æ˜¯å¦åœ¨è¯šä¿¡æ‰¿è¯ºå’Œæ‘˜è¦ä¹‹é—´
            # å…è®¸åˆ é™¤ç©ºç™½æ®µè½ï¼Œä½†ä¸åˆ é™¤åŒ…å«åˆ†é¡µç¬¦çš„æ®µè½
            is_between_integrity_and_abstract = False
            if integrity_end is not None and abstract_zh_start is not None:
                if integrity_end <= idx < abstract_zh_start:
                    is_between_integrity_and_abstract = True
            
            # æ£€æŸ¥æ˜¯å¦åœ¨è‹±æ–‡æ‘˜è¦ä¹‹åï¼ˆå¯èƒ½æ˜¯ç©ºç™½é¡µï¼‰
            is_after_abstract_en = False
            if abstract_en_end is not None:
                if idx >= abstract_en_end:
                    is_after_abstract_en = True
                    # æ·»åŠ è¯Šæ–­æ—¥å¿—ï¼ˆä»…è®°å½•å‰å‡ ä¸ªæ®µè½ï¼Œé¿å…æ—¥å¿—è¿‡å¤šï¼‰
                    is_blank = len(para_text) == 0
                    if idx == abstract_en_end or (idx < abstract_en_end + 5 and is_blank):
                        self._log_to_file(f"[ç©ºç™½é¡µæ£€æµ‹] æ®µè½ {idx} åœ¨è‹±æ–‡æ‘˜è¦ä¹‹åï¼ˆabstract_en_end={abstract_en_end}ï¼‰ï¼Œæ–‡æœ¬: '{para_text[:30]}'ï¼Œæ˜¯å¦ç©ºç™½: {is_blank}")
            
            if is_between_integrity_and_abstract:
                # åœ¨è¯šä¿¡æ‰¿è¯ºå’Œæ‘˜è¦ä¹‹é—´ï¼Œåªåˆ é™¤ç©ºç™½æ®µè½ï¼ˆä¸åŒ…å«åˆ†é¡µç¬¦çš„ï¼‰
                # è¿™æ ·å¯ä»¥åˆ é™¤å¤šä½™çš„ç©ºç™½é¡µï¼Œä½†ä¿ç•™åˆ†é¡µç¬¦
                if is_blank and not has_page_break(paragraph):
                    # ç©ºç™½æ®µè½ä¸”ä¸åŒ…å«åˆ†é¡µç¬¦ï¼Œå¯ä»¥åˆ é™¤
                    if consecutive_blanks == 0:
                        blank_start_idx = idx
                    consecutive_blanks += 1
                    # å¦‚æœè¿ç»­ç©ºç™½æ®µè½è¾ƒå¤šï¼Œå¯èƒ½æ˜¯ç©ºç™½é¡µï¼Œæ ‡è®°ä¸ºå¯åˆ é™¤
                    if consecutive_blanks >= BLANK_PAGE_WITH_HEADER_THRESHOLD:
                        # æ£€æŸ¥å‰åæ˜¯å¦æœ‰åˆ†é¡µç¬¦
                        has_break_before = False
                        if blank_start_idx > 0 and blank_start_idx - 1 < len(document.paragraphs):
                            prev_para = document.paragraphs[blank_start_idx - 1]
                            if prev_para.paragraph_format.page_break_before or any('w:br' in str(run.element.xml) and 'type="page"' in str(run.element.xml) for run in prev_para.runs if hasattr(run, 'element')):
                                has_break_before = True
                        
                        has_break_after = False
                        if idx + 1 < len(document.paragraphs):
                            next_para = document.paragraphs[idx + 1]
                            if next_para.paragraph_format.page_break_before or any('w:br' in str(run.element.xml) and 'type="page"' in str(run.element.xml) for run in next_para.runs if hasattr(run, 'element')):
                                has_break_after = True
                        
                        # å¦‚æœå‰åæœ‰åˆ†é¡µç¬¦ï¼Œè¯´æ˜æ˜¯ç©ºç™½é¡µï¼Œåˆ é™¤è¿™äº›ç©ºç™½æ®µè½
                        if has_break_before or has_break_after:
                            delete_end = min(blank_start_idx + consecutive_blanks - 1, len(document.paragraphs) - 1)
                            deleted_count = 0
                            for delete_idx in range(delete_end, blank_start_idx - 1, -1):
                                if delete_idx >= 0 and delete_idx < len(document.paragraphs):
                                    para_to_delete = document.paragraphs[delete_idx]
                                    if len(para_to_delete.text.strip()) == 0 and not has_page_break(para_to_delete):
                                        para_to_delete._element.getparent().remove(para_to_delete._element)
                                        deleted_count += 1
                                        if delete_idx < idx:
                                            idx -= 1
                            
                            if deleted_count > 0:
                                issues.append({
                                    "type": "blank_page_removed",
                                    "message": f"å·²åˆ é™¤è¯šä¿¡æ‰¿è¯ºå’Œæ‘˜è¦ä¹‹é—´çš„ {deleted_count} ä¸ªç©ºç™½æ®µè½ï¼ˆç©ºç™½é¡µï¼‰",
                                    "suggestion": "å·²è‡ªåŠ¨åˆ é™¤ç©ºç™½é¡µ",
                                    "blank_start": blank_start_idx,
                                    "blank_count": deleted_count,
                                })
                                consecutive_blanks = 0
                                blank_start_idx = None
                                continue
                else:
                    # éç©ºç™½æ®µè½æˆ–åŒ…å«åˆ†é¡µç¬¦ï¼Œé‡ç½®è®¡æ•°
                    consecutive_blanks = 0
                    blank_start_idx = None
                idx += 1
                continue
            
            # æ£€æŸ¥æ˜¯å¦åœ¨è‹±æ–‡æ‘˜è¦ä¹‹åï¼Œå¦‚æœæ˜¯ç©ºç™½æ®µè½ï¼Œéœ€è¦ç‰¹åˆ«å¤„ç†
            if is_after_abstract_en:
                is_blank = len(para_text) == 0
                if is_blank:
                    if consecutive_blanks == 0:
                        blank_start_idx = idx
                        self._log_to_file(f"[ç©ºç™½é¡µæ£€æµ‹] åœ¨è‹±æ–‡æ‘˜è¦åå‘ç°ç©ºç™½æ®µè½å¼€å§‹ï¼Œæ®µè½ç´¢å¼•: {idx}")
                    consecutive_blanks += 1
                    # å¦‚æœè¿ç»­ç©ºç™½æ®µè½è¾ƒå¤šï¼Œå¯èƒ½æ˜¯ç©ºç™½é¡µï¼Œéœ€è¦åˆ é™¤
                    if consecutive_blanks >= BLANK_PAGE_WITH_HEADER_THRESHOLD:
                        self._log_to_file(f"[ç©ºç™½é¡µæ£€æµ‹] è‹±æ–‡æ‘˜è¦åè¿ç»­ç©ºç™½æ®µè½è¾¾åˆ°é˜ˆå€¼: {consecutive_blanks}ï¼Œå¼€å§‹æ£€æŸ¥æ˜¯å¦ä¸ºç©ºç™½é¡µ")
                        # æ£€æŸ¥å‰åæ˜¯å¦æœ‰åˆ†é¡µç¬¦
                        has_break_before = False
                        if blank_start_idx > 0 and blank_start_idx - 1 < len(document.paragraphs):
                            prev_para = document.paragraphs[blank_start_idx - 1]
                            if prev_para.paragraph_format.page_break_before or any('w:br' in str(run.element.xml) and 'type="page"' in str(run.element.xml) for run in prev_para.runs if hasattr(run, 'element')):
                                has_break_before = True
                        
                        has_break_after = False
                        if idx + 1 < len(document.paragraphs):
                            next_para = document.paragraphs[idx + 1]
                            if next_para.paragraph_format.page_break_before or any('w:br' in str(run.element.xml) and 'type="page"' in str(run.element.xml) for run in next_para.runs if hasattr(run, 'element')):
                                has_break_after = True
                        
                        # å¦‚æœå‰åæœ‰åˆ†é¡µç¬¦ï¼Œæˆ–è€…è¿ç»­ç©ºç™½æ®µè½å¾ˆå¤šï¼Œè¯´æ˜æ˜¯ç©ºç™½é¡µï¼Œåˆ é™¤è¿™äº›ç©ºç™½æ®µè½
                        if has_break_before or has_break_after or consecutive_blanks >= BLANK_PAGE_THRESHOLD:
                            self._log_to_file(f"[ç©ºç™½é¡µæ£€æµ‹] ç¡®è®¤è‹±æ–‡æ‘˜è¦åæœ‰ç©ºç™½é¡µï¼Œhas_break_before={has_break_before}, has_break_after={has_break_after}, consecutive_blanks={consecutive_blanks}")
                            delete_end = min(blank_start_idx + consecutive_blanks - 1, len(document.paragraphs) - 1)
                            deleted_count = 0
                            for delete_idx in range(delete_end, blank_start_idx - 1, -1):
                                if delete_idx >= 0 and delete_idx < len(document.paragraphs):
                                    para_to_delete = document.paragraphs[delete_idx]
                                    if len(para_to_delete.text.strip()) == 0 and not has_page_break(para_to_delete):
                                        para_to_delete._element.getparent().remove(para_to_delete._element)
                                        deleted_count += 1
                                        if delete_idx < idx:
                                            idx -= 1
                            
                            if deleted_count > 0:
                                self._log_to_file(f"[ç©ºç™½é¡µæ£€æµ‹] âœ… å·²åˆ é™¤è‹±æ–‡æ‘˜è¦åçš„ {deleted_count} ä¸ªç©ºç™½æ®µè½ï¼ˆç©ºç™½é¡µï¼‰ï¼Œä»æ®µè½ {blank_start_idx} åˆ° {delete_end}")
                                issues.append({
                                    "type": "blank_page_removed",
                                    "message": f"å·²åˆ é™¤è‹±æ–‡æ‘˜è¦åçš„ {deleted_count} ä¸ªç©ºç™½æ®µè½ï¼ˆç©ºç™½é¡µï¼‰",
                                    "suggestion": "å·²è‡ªåŠ¨åˆ é™¤ç©ºç™½é¡µ",
                                    "blank_start": blank_start_idx,
                                    "blank_count": deleted_count,
                                })
                                consecutive_blanks = 0
                                blank_start_idx = None
                                continue
                    idx += 1
                    continue
                else:
                    # é‡åˆ°éç©ºç™½æ®µè½ï¼Œæ£€æŸ¥ä¹‹å‰æ˜¯å¦æœ‰å¤§é‡ç©ºç™½éœ€è¦åˆ é™¤
                    if consecutive_blanks >= BLANK_PAGE_WITH_HEADER_THRESHOLD and blank_start_idx is not None:
                        # æ£€æŸ¥ç©ºç™½æ®µè½å‰æ˜¯å¦æœ‰åˆ†é¡µç¬¦
                        has_break_before = False
                        if blank_start_idx > 0 and blank_start_idx - 1 < len(document.paragraphs):
                            prev_para = document.paragraphs[blank_start_idx - 1]
                            if prev_para.paragraph_format.page_break_before or any('w:br' in str(run.element.xml) and 'type="page"' in str(run.element.xml) for run in prev_para.runs if hasattr(run, 'element')):
                                has_break_before = True
                        
                        # å¦‚æœå‰é¢æœ‰åˆ†é¡µç¬¦ï¼Œæˆ–è€…è¿ç»­ç©ºç™½æ®µè½å¾ˆå¤šï¼Œè¯´æ˜æ˜¯ç©ºç™½é¡µï¼Œåˆ é™¤è¿™äº›ç©ºç™½æ®µè½
                        if has_break_before or consecutive_blanks >= BLANK_PAGE_THRESHOLD:
                            delete_end = min(blank_start_idx + consecutive_blanks - 1, len(document.paragraphs) - 1)
                            deleted_count = 0
                            for delete_idx in range(delete_end, blank_start_idx - 1, -1):
                                if delete_idx >= 0 and delete_idx < len(document.paragraphs):
                                    para_to_delete = document.paragraphs[delete_idx]
                                    if len(para_to_delete.text.strip()) == 0 and not has_page_break(para_to_delete):
                                        para_to_delete._element.getparent().remove(para_to_delete._element)
                                        deleted_count += 1
                                        if delete_idx < idx:
                                            idx -= 1
                            
                            if deleted_count > 0:
                                issues.append({
                                    "type": "blank_page_removed",
                                    "message": f"å·²åˆ é™¤è‹±æ–‡æ‘˜è¦åçš„ {deleted_count} ä¸ªç©ºç™½æ®µè½ï¼ˆç©ºç™½é¡µï¼‰",
                                    "suggestion": "å·²è‡ªåŠ¨åˆ é™¤ç©ºç™½é¡µ",
                                    "blank_start": blank_start_idx,
                                    "blank_count": deleted_count,
                                })
                                consecutive_blanks = 0
                                blank_start_idx = None
                                continue
                    # é‡ç½®è®¡æ•°
                    consecutive_blanks = 0
                    blank_start_idx = None
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯ç©ºç™½æ®µè½
            is_blank = len(para_text) == 0
            
            if is_blank:
                if consecutive_blanks == 0:
                    blank_start_idx = idx
                consecutive_blanks += 1
                idx += 1
            else:
                # é‡åˆ°éç©ºç™½æ®µè½
                # å¦‚æœä¹‹å‰æœ‰å¤§é‡è¿ç»­ç©ºç™½ï¼ˆå¯èƒ½æ˜¯æ•´é¡µç©ºç™½ï¼‰ï¼Œæ£€æŸ¥æ˜¯å¦éœ€è¦åˆ é™¤
                # æˆ–è€…æœ‰ä¸­ç­‰æ•°é‡çš„ç©ºç™½ä¸”å‰åæœ‰åˆ†é¡µç¬¦ï¼ˆå¯èƒ½æ˜¯åªæœ‰é¡µçœ‰çš„ç©ºç™½é¡µï¼‰
                if (consecutive_blanks >= BLANK_PAGE_THRESHOLD or 
                    (consecutive_blanks >= BLANK_PAGE_WITH_HEADER_THRESHOLD and blank_start_idx is not None)) and blank_start_idx is not None:
                    # æ£€æŸ¥è¿™äº›ç©ºç™½æ®µè½å‰åæ˜¯å¦æœ‰åˆ†é¡µç¬¦ï¼Œå¦‚æœæœ‰ï¼Œå¯èƒ½æ˜¯æ•´é¡µç©ºç™½
                    # æ£€æŸ¥ç©ºç™½æ®µè½ä¹‹å‰æ˜¯å¦æœ‰åˆ†é¡µç¬¦
                    has_break_before = False
                    if blank_start_idx > 0 and blank_start_idx - 1 < len(document.paragraphs):
                        prev_para = document.paragraphs[blank_start_idx - 1]
                        if prev_para.paragraph_format.page_break_before:
                            has_break_before = True
                        else:
                            for run in prev_para.runs:
                                if hasattr(run, 'element'):
                                    run_xml = str(run.element.xml)
                                    if 'w:br' in run_xml and 'type="page"' in run_xml:
                                        has_break_before = True
                                        break
                    
                    # æ£€æŸ¥ç©ºç™½æ®µè½ä¹‹åæ˜¯å¦æœ‰åˆ†é¡µç¬¦
                    has_break_after = False
                    if idx < len(document.paragraphs):
                        next_para = document.paragraphs[idx]
                        if next_para.paragraph_format.page_break_before:
                            has_break_after = True
                        else:
                            for run in next_para.runs:
                                if hasattr(run, 'element'):
                                    run_xml = str(run.element.xml)
                                    if 'w:br' in run_xml and 'type="page"' in run_xml:
                                        has_break_after = True
                                        break
                    
                    # å¦‚æœç©ºç™½æ®µè½å‰åéƒ½æœ‰åˆ†é¡µç¬¦ï¼Œæˆ–è€…ç©ºç™½æ®µè½æ•°é‡éå¸¸å¤šï¼Œå¯èƒ½æ˜¯æ•´é¡µç©ºç™½
                    # æˆ–è€…æœ‰ä¸­ç­‰æ•°é‡çš„ç©ºç™½ä¸”å‰åæœ‰åˆ†é¡µç¬¦ï¼ˆå¯èƒ½æ˜¯åªæœ‰é¡µçœ‰çš„ç©ºç™½é¡µï¼‰
                    # åˆ é™¤è¿™äº›ç©ºç™½æ®µè½ï¼Œä½†ä¿ç•™æœ€åä¸€ä¸ªï¼Œé¿å…å¯¼è‡´æ–°çš„æ•´é¡µç©ºç™½
                    should_delete = False
                    if consecutive_blanks >= BLANK_PAGE_THRESHOLD * 2:
                        # ç©ºç™½æ®µè½æ•°é‡éå¸¸å¤šï¼Œè‚¯å®šæ˜¯æ•´é¡µç©ºç™½
                        should_delete = True
                    elif consecutive_blanks >= BLANK_PAGE_THRESHOLD:
                        # ç©ºç™½æ®µè½æ•°é‡å¤šï¼Œå¯èƒ½æ˜¯æ•´é¡µç©ºç™½
                        should_delete = True
                    elif consecutive_blanks >= BLANK_PAGE_WITH_HEADER_THRESHOLD and (has_break_before or has_break_after):
                        # ä¸­ç­‰æ•°é‡çš„ç©ºç™½ä¸”å‰åæœ‰åˆ†é¡µç¬¦ï¼Œå¯èƒ½æ˜¯åªæœ‰é¡µçœ‰çš„ç©ºç™½é¡µ
                        should_delete = True
                    
                    if should_delete:
                        # åˆ é™¤ç©ºç™½æ®µè½ï¼Œä½†ä¿ç•™æœ€åä¸€ä¸ª
                        deleted_count = 0
                        # ä»åå¾€å‰åˆ é™¤ï¼Œä¿ç•™æœ€åä¸€ä¸ªç©ºç™½æ®µè½
                        delete_end = blank_start_idx + consecutive_blanks - 1
                        # ç¡®ä¿ç´¢å¼•åœ¨æœ‰æ•ˆèŒƒå›´å†…
                        delete_end = min(delete_end, len(document.paragraphs) - 1)
                        for delete_idx in range(delete_end, blank_start_idx, -1):
                            if delete_idx >= 0 and delete_idx < len(document.paragraphs):
                                para_to_delete = document.paragraphs[delete_idx]
                                if len(para_to_delete.text.strip()) == 0:
                                    # æ£€æŸ¥æ˜¯å¦åŒ…å«å­—æ®µä»£ç 
                                    para_xml = para_to_delete._element.xml if hasattr(para_to_delete._element, 'xml') else ""
                                    if 'TOC' in para_xml or 'w:fldChar' in para_xml or 'w:instrText' in para_xml:
                                        continue
                                    # æ£€æŸ¥æ˜¯å¦åŒ…å«åˆ†é¡µç¬¦ï¼Œå¦‚æœåŒ…å«åˆ™ä¸åˆ é™¤ï¼ˆé¿å…å¯¼è‡´ç©ºç™½é¡µï¼‰
                                    if has_page_break(para_to_delete):
                                        continue
                                    para_to_delete._element.getparent().remove(para_to_delete._element)
                                    deleted_count += 1
                                    # å¦‚æœåˆ é™¤çš„æ®µè½åœ¨å½“å‰ç´¢å¼•ä¹‹å‰ï¼Œéœ€è¦è°ƒæ•´ç´¢å¼•
                                    if delete_idx < idx:
                                        idx -= 1
                        
                        if deleted_count > 0:
                            issues.append({
                                "type": "blank_page_removed",
                                "message": f"å·²åˆ é™¤ç¬¬ {blank_start_idx + 1} æ®µåˆ°ç¬¬ {blank_start_idx + consecutive_blanks} æ®µä¹‹é—´çš„ {deleted_count} ä¸ªç©ºç™½æ®µè½ï¼ˆç–‘ä¼¼æ•´é¡µç©ºç™½ï¼‰",
                                "suggestion": "å·²è‡ªåŠ¨åˆ é™¤æ•´é¡µç©ºç™½é¡µ",
                                "blank_start": blank_start_idx,
                                "blank_count": deleted_count,
                            })
                            # åˆ é™¤æ®µè½åï¼Œé‡æ–°ä»åˆ é™¤ä½ç½®å¼€å§‹æ£€æŸ¥
                            idx = blank_start_idx
                            consecutive_blanks = 0
                            blank_start_idx = None
                            continue
                
                consecutive_blanks = 0
                blank_start_idx = None
                idx += 1
        
        # å¤„ç†æ–‡æ¡£æœ«å°¾çš„æ•´é¡µç©ºç™½
        # æ£€æŸ¥æœ«å°¾æ˜¯å¦æœ‰åˆ†é¡µç¬¦ï¼Œå¦‚æœæœ‰ï¼Œå¯èƒ½æ˜¯åªæœ‰é¡µçœ‰çš„ç©ºç™½é¡µ
        has_break_before_end = False
        if blank_start_idx is not None and blank_start_idx > 0 and blank_start_idx - 1 < len(document.paragraphs):
            prev_para = document.paragraphs[blank_start_idx - 1]
            if prev_para.paragraph_format.page_break_before:
                has_break_before_end = True
            else:
                for run in prev_para.runs:
                    if hasattr(run, 'element'):
                        run_xml = str(run.element.xml)
                        if 'w:br' in run_xml and 'type="page"' in run_xml:
                            has_break_before_end = True
                            break
        
        if ((consecutive_blanks >= BLANK_PAGE_THRESHOLD) or 
            (consecutive_blanks >= BLANK_PAGE_WITH_HEADER_THRESHOLD and has_break_before_end)) and blank_start_idx is not None:
            # åˆ é™¤æœ«å°¾çš„æ•´é¡µç©ºç™½ï¼Œä½†ä¿ç•™æœ€åä¸€ä¸ªç©ºç™½æ®µè½
            deleted_count = 0
            delete_end = min(blank_start_idx + consecutive_blanks - 1, len(document.paragraphs) - 1)
            for delete_idx in range(delete_end, blank_start_idx, -1):
                if delete_idx >= 0 and delete_idx < len(document.paragraphs):
                    para_to_delete = document.paragraphs[delete_idx]
                    if len(para_to_delete.text.strip()) == 0:
                        # æ£€æŸ¥æ˜¯å¦åŒ…å«å­—æ®µä»£ç 
                        para_xml = para_to_delete._element.xml if hasattr(para_to_delete._element, 'xml') else ""
                        if 'TOC' in para_xml or 'w:fldChar' in para_xml or 'w:instrText' in para_xml:
                            continue
                        # æ£€æŸ¥æ˜¯å¦åŒ…å«åˆ†é¡µç¬¦ï¼Œå¦‚æœåŒ…å«åˆ™ä¸åˆ é™¤ï¼ˆé¿å…å¯¼è‡´ç©ºç™½é¡µï¼‰
                        if has_page_break(para_to_delete):
                            continue
                        para_to_delete._element.getparent().remove(para_to_delete._element)
                        deleted_count += 1
            
            if deleted_count > 0:
                issues.append({
                    "type": "blank_page_removed",
                    "message": f"å·²åˆ é™¤æ–‡æ¡£æœ«å°¾ç¬¬ {blank_start_idx + 1} æ®µåˆ°ç¬¬ {blank_start_idx + consecutive_blanks} æ®µä¹‹é—´çš„ {deleted_count} ä¸ªç©ºç™½æ®µè½ï¼ˆç–‘ä¼¼æ•´é¡µç©ºç™½ï¼‰",
                    "suggestion": "å·²è‡ªåŠ¨åˆ é™¤æ•´é¡µç©ºç™½é¡µ",
                    "blank_start": blank_start_idx,
                    "blank_count": deleted_count,
                })
        
        return issues

    def _save_file_to_storage(self, key: str, content: bytes) -> bool:
        """
        ä¿å­˜æ–‡ä»¶åˆ°äº‘å­˜å‚¨
        
        Args:
            key: å­˜å‚¨é”®ï¼ˆè·¯å¾„ï¼‰
            content: æ–‡ä»¶å†…å®¹ï¼ˆå­—èŠ‚ï¼‰
        
        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        if not self.use_storage:
            return False
        try:
            file_obj = io.BytesIO(content)
            return self.storage.upload_file(key, file_obj)
        except Exception as e:
            print(f"[Storage] Failed to save {key}: {e}")
            return False

    def _load_file_from_storage(self, key: str) -> Optional[bytes]:
        """
        ä»äº‘å­˜å‚¨åŠ è½½æ–‡ä»¶
        
        Args:
            key: å­˜å‚¨é”®ï¼ˆè·¯å¾„ï¼‰
        
        Returns:
            æ–‡ä»¶å†…å®¹ï¼ˆå­—èŠ‚ï¼‰ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è¿”å› None
        """
        if not self.use_storage:
            return None
        try:
            return self.storage.download_file(key)
        except Exception as e:
            print(f"[Storage] Failed to load {key}: {e}")
            return None

    def _save_to_storage(self, document_id: str, files: Dict[str, Path]) -> None:
        """
        å°†æ–‡æ¡£æ–‡ä»¶ä¿å­˜åˆ°äº‘å­˜å‚¨
        
        Args:
            document_id: æ–‡æ¡£ID
            files: æ–‡ä»¶è·¯å¾„å­—å…¸
        """
        if not self.use_storage:
            return
        
        prefix = f"documents/{document_id}"
        
        # ä¿å­˜æ‰€æœ‰æ–‡ä»¶
        for file_type, file_path in files.items():
            if file_path.exists():
                # å¯¹äºPDFæ–‡ä»¶ï¼Œç¡®ä¿ä½¿ç”¨æ­£ç¡®çš„æ‰©å±•å
                if file_type == "pdf":
                    key = f"{prefix}/pdf.pdf"
                else:
                    key = f"{prefix}/{file_type}.{file_path.suffix[1:]}"  # å»æ‰ç‚¹å·
                
                file_size = file_path.stat().st_size
                print(f"[Storage] å‡†å¤‡ä¸Šä¼ æ–‡ä»¶: {file_type} -> {key}, å¤§å°: {file_size / 1024:.2f} KB")
                content = file_path.read_bytes()
                if self._save_file_to_storage(key, content):
                    print(f"[Storage] âœ… æˆåŠŸä¸Šä¼ : {key}")
                else:
                    print(f"[Storage] âŒ ä¸Šä¼ å¤±è´¥: {key}")
            else:
                print(f"[Storage] âš ï¸ æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡ä¸Šä¼ : {file_type} -> {file_path}")

    def _get_file_from_storage_or_local(self, document_id: str, file_type: str, extension: str, local_path: Path) -> Optional[Path]:
        """
        ä»äº‘å­˜å‚¨æˆ–æœ¬åœ°æ–‡ä»¶ç³»ç»Ÿè·å–æ–‡ä»¶
        
        Args:
            document_id: æ–‡æ¡£ID
            file_type: æ–‡ä»¶ç±»å‹ï¼ˆoriginal, final, preview, html, report, pdfï¼‰
            extension: æ–‡ä»¶æ‰©å±•åï¼ˆdocx, html, json, pdfï¼‰
            local_path: æœ¬åœ°æ–‡ä»¶è·¯å¾„ï¼ˆç”¨äºå›é€€ï¼‰
        
        Returns:
            æ–‡ä»¶è·¯å¾„ï¼ˆå¦‚æœæ‰¾åˆ°ï¼‰ï¼Œå¦åˆ™è¿”å› None
        """
        # ä¼˜å…ˆä»äº‘å­˜å‚¨è¯»å–
        if self.use_storage:
            key = f"documents/{document_id}/{file_type}.{extension}"
            print(f"[Storage] æŸ¥æ‰¾æ–‡ä»¶: key={key}, file_type={file_type}, extension={extension}")
            if self.storage.file_exists(key):
                print(f"[Storage] æ–‡ä»¶å­˜åœ¨äºäº‘å­˜å‚¨: {key}")
                content = self._load_file_from_storage(key)
                if content:
                    print(f"[Storage] æˆåŠŸä¸‹è½½æ–‡ä»¶: {key}, å¤§å°: {len(content) / 1024:.2f} KB")
                    # ç¡®ä¿æœ¬åœ°ç›®å½•å­˜åœ¨
                    local_path.parent.mkdir(parents=True, exist_ok=True)
                    # å†™å…¥æœ¬åœ°ä¸´æ—¶æ–‡ä»¶
                    local_path.write_bytes(content)
                    print(f"[Storage] å·²ä¿å­˜åˆ°æœ¬åœ°: {local_path}")
                    return local_path
                else:
                    print(f"[Storage] âš ï¸ æ–‡ä»¶å­˜åœ¨ä½†ä¸‹è½½å¤±è´¥: {key}")
            else:
                print(f"[Storage] âš ï¸ æ–‡ä»¶ä¸å­˜åœ¨äºäº‘å­˜å‚¨: {key}")
        
        # å›é€€åˆ°æœ¬åœ°æ–‡ä»¶ç³»ç»Ÿ
        print(f"[Storage] æ£€æŸ¥æœ¬åœ°æ–‡ä»¶: {local_path}")
        if local_path.exists():
            local_size = local_path.stat().st_size
            print(f"[Storage] âœ… æ‰¾åˆ°æœ¬åœ°æ–‡ä»¶: {local_path}, å¤§å°: {local_size / 1024:.2f} KB")
            return local_path
        else:
            print(f"[Storage] âš ï¸ æœ¬åœ°æ–‡ä»¶ä¸å­˜åœ¨: {local_path}")
        
        return None

    def _add_pdf_watermarks(self, pdf_path: Path, output_path: Path, watermark_text: str = "www.geshixiugai.cn", watermarks_per_page: int = 10) -> bool:
        """åœ¨PDFçš„æ¯ä¸€é¡µæ·»åŠ å¤šä¸ªæ°´å°
        
        Args:
            pdf_path: åŸå§‹PDFæ–‡ä»¶è·¯å¾„
            output_path: è¾“å‡ºPDFæ–‡ä»¶è·¯å¾„
            watermark_text: æ°´å°æ–‡æœ¬
            watermarks_per_page: æ¯é¡µæ°´å°æ•°é‡
        
        Returns:
            bool: æ˜¯å¦æˆåŠŸ
        """
        try:
            from pypdf import PdfReader, PdfWriter
            from reportlab.pdfgen import canvas
            from reportlab.lib.colors import red
            import io
            import math
            
            print(f"[PDFæ°´å°] å¼€å§‹ä¸ºPDFæ·»åŠ æ°´å°: {pdf_path}")
            print(f"[PDFæ°´å°] æ°´å°æ–‡æœ¬: {watermark_text}, æ¯é¡µæ°´å°æ•°: {watermarks_per_page}")
            
            # è¯»å–åŸå§‹PDF
            reader = PdfReader(str(pdf_path))
            writer = PdfWriter()
            
            # è·å–PDFé¡µæ•°
            num_pages = len(reader.pages)
            print(f"[PDFæ°´å°] PDFæ€»é¡µæ•°: {num_pages}")
            
            # ä¸ºæ¯ä¸€é¡µæ·»åŠ æ°´å°ï¼ŒåŒæ—¶æ£€æŸ¥å¹¶åˆ é™¤ç©ºç™½é¡µ
            pages_to_keep = []
            for page_num in range(num_pages):
                page = reader.pages[page_num]
                
                # è·å–é¡µé¢å°ºå¯¸
                page_box = page.mediabox
                page_width = float(page_box.width)
                page_height = float(page_box.height)
                
                # æ£€æŸ¥é¡µé¢æ˜¯å¦æ˜¯ç©ºç™½é¡µ
                # æå–é¡µé¢æ–‡æœ¬å†…å®¹
                try:
                    page_text = page.extract_text()
                    # å¦‚æœé¡µé¢æ–‡æœ¬ä¸ºç©ºæˆ–åªæœ‰ç©ºç™½å­—ç¬¦ï¼Œå¯èƒ½æ˜¯ç©ºç™½é¡µ
                    # ä½†ä¹Ÿè¦è€ƒè™‘é¡µçœ‰é¡µè„šï¼Œæ‰€ä»¥å¦‚æœæ–‡æœ¬é•¿åº¦å°äº10ä¸ªå­—ç¬¦ï¼Œè®¤ä¸ºæ˜¯ç©ºç™½é¡µ
                    if page_text and len(page_text.strip()) > 10:
                        # é¡µé¢æœ‰å†…å®¹ï¼Œä¿ç•™
                        pages_to_keep.append(page_num)
                        print(f"[PDFæ°´å°] ç¬¬ {page_num + 1} é¡µæœ‰å†…å®¹ï¼Œä¿ç•™")
                    else:
                        # é¡µé¢å¯èƒ½æ˜¯ç©ºç™½é¡µï¼Œæ£€æŸ¥æ˜¯å¦æœ‰å›¾åƒæˆ–å…¶ä»–å†…å®¹
                        # å¦‚æœé¡µé¢æœ‰å›¾åƒæˆ–å…¶ä»–å¯¹è±¡ï¼Œä¹Ÿä¿ç•™
                        if '/XObject' in page.get('/Resources', {}):
                            pages_to_keep.append(page_num)
                            print(f"[PDFæ°´å°] ç¬¬ {page_num + 1} é¡µæœ‰å›¾åƒï¼Œä¿ç•™")
                        else:
                            print(f"[PDFæ°´å°] ç¬¬ {page_num + 1} é¡µæ˜¯ç©ºç™½é¡µï¼Œå°†åˆ é™¤")
                except Exception as e:
                    # å¦‚æœæå–æ–‡æœ¬å¤±è´¥ï¼Œä¿ç•™é¡µé¢ï¼ˆå¯èƒ½æ˜¯æ‰«æä»¶æˆ–ç‰¹æ®Šæ ¼å¼ï¼‰
                    pages_to_keep.append(page_num)
                    print(f"[PDFæ°´å°] ç¬¬ {page_num + 1} é¡µæå–æ–‡æœ¬å¤±è´¥ï¼Œä¿ç•™: {e}")
                
                # å¦‚æœé¡µé¢éœ€è¦ä¿ç•™ï¼Œæ·»åŠ æ°´å°
                if page_num in pages_to_keep:
                    print(f"[PDFæ°´å°] å¤„ç†ç¬¬ {page_num + 1} é¡µ, å°ºå¯¸: {page_width}x{page_height}")
                    
                    # åˆ›å»ºæ°´å°PDFï¼ˆä½¿ç”¨reportlabï¼‰
                    watermark_pdf = io.BytesIO()
                    c = canvas.Canvas(watermark_pdf, pagesize=(page_width, page_height))
                    
                    # è®¾ç½®æ°´å°æ ·å¼ - æµ…çº¢è‰²ã€åŠé€æ˜ã€æ°´å¹³æ”¾ç½®
                    # ä½¿ç”¨æµ…çº¢è‰²ï¼ˆRGB: 255, 200, 200ï¼‰å¹¶è®¾ç½®é€æ˜åº¦
                    from reportlab.lib.colors import Color
                    light_red = Color(1.0, 0.78, 0.78, alpha=0.3)  # æµ…çº¢è‰²ï¼Œ30%é€æ˜åº¦
                    c.setFillColor(light_red)
                    
                    # æ ¹æ®é¡µé¢å¤§å°è®¡ç®—å­—ä½“å¤§å°ï¼Œé€‚ä¸­å³å¯
                    font_size = max(30, int(page_width / 20))
                    c.setFont("Helvetica-Bold", font_size)
                    
                    # è®¡ç®—æ–‡æœ¬å®½åº¦ï¼ˆç”¨äºå±…ä¸­æ˜¾ç¤ºï¼‰
                    text_width = c.stringWidth(watermark_text, "Helvetica-Bold", font_size)
                    
                    # æ¯é¡µæ°´å¹³æ”¾ç½®3ä¸ªæ°´å°ï¼Œå‡åŒ€åˆ†å¸ƒåœ¨A4çº¸ä¸Š
                    num_watermarks = 3
                    
                    # è®¡ç®—æ¯ä¸ªæ°´å°çš„ä½ç½®ï¼ˆæ°´å¹³å‡åŒ€åˆ†å¸ƒï¼‰
                    # ç•™å‡ºè¾¹è·ï¼Œç¡®ä¿æ°´å°ä¸ä¼šå¤ªé è¿‘è¾¹ç¼˜
                    margin_x = page_width / 10
                    margin_y = page_height / 10
                    usable_width = page_width - 2 * margin_x
                    usable_height = page_height - 2 * margin_y
                    
                    # è®¡ç®—æ°´å¹³é—´è·ï¼ˆ3ä¸ªæ°´å°ï¼Œ4ä¸ªé—´éš”ï¼Œæ°´å¹³æ–¹å‘å‡åŒ€åˆ†å¸ƒï¼‰
                    x_spacing = usable_width / (num_watermarks + 1)
                    
                    # å‚ç›´ä½ç½®ï¼šåœ¨é¡µé¢çš„ä¸Šã€ä¸­ã€ä¸‹ä¸‰ä¸ªä½ç½®å‡åŒ€åˆ†å¸ƒ
                    y_positions = [
                        margin_y + usable_height * 0.25,  # ä¸Š1/4ä½ç½®
                        margin_y + usable_height * 0.5,   # ä¸­é—´ä½ç½®
                        margin_y + usable_height * 0.75    # ä¸‹3/4ä½ç½®
                    ]
                    
                    # æ·»åŠ 3ä¸ªæ°´å°ï¼Œæ°´å¹³æ”¾ç½®ï¼Œå‡åŒ€åˆ†å¸ƒ
                    for i in range(num_watermarks):
                        # è®¡ç®—æ°´å¹³ä½ç½®ï¼ˆå‡åŒ€åˆ†å¸ƒï¼‰
                        x = margin_x + (i + 1) * x_spacing
                        # è®¡ç®—å‚ç›´ä½ç½®ï¼ˆä¸Šã€ä¸­ã€ä¸‹å‡åŒ€åˆ†å¸ƒï¼‰
                        y = y_positions[i]
                        
                        # ç»˜åˆ¶æ°´å°æ–‡æœ¬ï¼ˆæ°´å¹³æ”¾ç½®ï¼Œä¸æ—‹è½¬ï¼‰
                        c.saveState()
                        c.translate(x, y)
                        # ä¸æ—‹è½¬ï¼Œä¿æŒæ°´å¹³
                        # ä½¿ç”¨æµ…çº¢è‰²ï¼ŒåŠé€æ˜
                        c.setFillColor(light_red)
                        # å±…ä¸­æ˜¾ç¤ºæ–‡æœ¬
                        c.drawString(-text_width / 2, 0, watermark_text)
                        c.restoreState()
                    
                    watermark_count = num_watermarks
                    
                    c.save()
                    watermark_pdf.seek(0)
                    
                    # è¯»å–æ°´å°PDF
                    watermark_reader = PdfReader(watermark_pdf)
                    watermark_page = watermark_reader.pages[0]
                    
                    # åˆå¹¶æ°´å°åˆ°åŸé¡µé¢
                    page.merge_page(watermark_page)
                    
                    # æ·»åŠ åˆ°è¾“å‡ºPDF
                    writer.add_page(page)
                    
                    print(f"[PDFæ°´å°] ç¬¬ {page_num + 1} é¡µæ°´å°æ·»åŠ å®Œæˆï¼ˆå…± {watermark_count} ä¸ªæ°´å°ï¼‰")
            
            # ä¿å­˜è¾“å‡ºPDF
            with open(output_path, 'wb') as output_file:
                writer.write(output_file)
            
            # ç»Ÿè®¡åˆ é™¤çš„ç©ºç™½é¡µ
            deleted_pages = num_pages - len(pages_to_keep)
            if deleted_pages > 0:
                print(f"[PDFæ°´å°] âœ… å·²åˆ é™¤ {deleted_pages} ä¸ªç©ºç™½é¡µ")
            print(f"[PDFæ°´å°] âœ… æœ€ç»ˆPDFé¡µæ•°: {len(pages_to_keep)} (åŸå§‹: {num_pages})")
            
            output_size = output_path.stat().st_size
            print(f"[PDFæ°´å°] âœ… PDFæ°´å°æ·»åŠ æˆåŠŸ: {output_path}, å¤§å°: {output_size / 1024:.2f} KB")
            return True
            
        except ImportError as e:
            print(f"[PDFæ°´å°] âŒ ç¼ºå°‘å¿…è¦çš„åº“: {e}")
            print(f"[PDFæ°´å°] è¯·å®‰è£…: pip install reportlab")
            return False
        except Exception as e:
            print(f"[PDFæ°´å°] âŒ æ·»åŠ æ°´å°å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False

    def _generate_watermarked_preview(self, final_path: Path, preview_path: Path) -> None:
        shutil.copy2(final_path, preview_path)
        document = Document(preview_path)
        watermark_text = "é¢„è§ˆç‰ˆ ä»…ä¾›æŸ¥çœ‹"
        
        # åˆ›å»ºVMLæ°´å°å½¢çŠ¶ï¼Œè®¾ç½®ä¸ºèƒŒæ™¯å±‚ï¼Œéš¾ä»¥åˆ é™¤
        ns = (
            'xmlns:w="http://schemas.openxmlformats.org/wordprocessingml/2006/main" '
            'xmlns:v="urn:schemas-microsoft-com:vml" '
            'xmlns:o="urn:schemas-microsoft-com:office:office"'
        )
        shape_template = (
            f'<w:pict {ns}>'
            '<v:shape id="watermark" o:spid="_x0000_s1025" type="#_x0000_t136" '
            'style="position:absolute;margin-left:0;margin-top:0;width:468pt;height:600pt;'
            'rotation:315;opacity:0.15;z-index:-251654144;mso-position-horizontal:center;'
            'mso-position-vertical:center;mso-wrap-style:none;mso-wrap-distance-left:0;'
            'mso-wrap-distance-right:0;mso-wrap-distance-top:0;mso-wrap-distance-bottom:0;">'
            '<v:fill opacity="0"/>'
            '<v:stroke color="#d10f0f"/>'
            f'<v:textpath style="font-family:å¾®è½¯é›…é»‘;font-size:72pt;font-weight:bold" string="{watermark_text}"/>'
            '<o:lock v:ext="edit" rotation="t" text="t" aspectratio="t"/>'
            '</v:shape>'
            '</w:pict>'
        )
        
        # æ–¹æ³•1: åœ¨é¡µçœ‰ä¸­æ·»åŠ æ°´å°ï¼ˆè¦†ç›–æ‰€æœ‰é¡µé¢ï¼‰
        for section in document.sections:
            header = section.header
            if header.is_linked_to_previous:
                header.is_linked_to_previous = False
            # æ¸…ç©ºç°æœ‰é¡µçœ‰å†…å®¹
            for para in header.paragraphs:
                para.clear()
            paragraph = header.add_paragraph()
            paragraph.alignment = WD_PARAGRAPH_ALIGNMENT.CENTER
            run = paragraph.add_run()
            run._r.append(parse_xml(shape_template))
        
        # æ–¹æ³•2: åœ¨æ­£æ–‡çš„æ¯ä¸ªæ®µè½ä¸­åµŒå…¥æ°´å°ï¼ˆä½œä¸ºèƒŒæ™¯å±‚ï¼‰
        # æ¯éš”å‡ ä¸ªæ®µè½æ’å…¥ä¸€æ¬¡ï¼Œé¿å…æ–‡æ¡£è¿‡å¤§
        watermark_interval = max(1, len(document.paragraphs) // 20)  # å¤§çº¦20ä¸ªæ°´å°
        for i, paragraph in enumerate(document.paragraphs):
            # è·³è¿‡ç©ºæ®µè½å’Œæ ‡é¢˜æ®µè½
            if not paragraph.text.strip() or len(paragraph.text.strip()) < 3:
                continue
            # æ¯éš”ä¸€å®šé—´éš”æ’å…¥æ°´å°
            if i % watermark_interval == 0:
                # åœ¨æ®µè½å¼€å¤´æ’å…¥æ°´å°å½¢çŠ¶
                run = paragraph.runs[0] if paragraph.runs else paragraph.add_run()
                # åˆ›å»ºç‹¬ç«‹çš„æ°´å°å½¢çŠ¶ï¼Œä½ç½®ç›¸å¯¹äºæ®µè½
                para_shape = (
                    f'<w:pict {ns}>'
                    '<v:shape id="watermark_para" o:spid="_x0000_s1026" type="#_x0000_t136" '
                    'style="position:absolute;margin-left:0;margin-top:0;width:400pt;height:400pt;'
                    'rotation:315;opacity:0.12;z-index:-251654144;mso-position-horizontal:center;'
                    'mso-position-vertical:center;mso-wrap-style:none;">'
                    '<v:fill opacity="0"/>'
                    '<v:stroke color="#d10f0f"/>'
                    f'<v:textpath style="font-family:å¾®è½¯é›…é»‘;font-size:60pt;font-weight:bold" string="{watermark_text}"/>'
                    '<o:lock v:ext="edit" rotation="t" text="t" aspectratio="t"/>'
                    '</v:shape>'
                    '</w:pict>'
                )
                run._r.append(parse_xml(para_shape))
        
        document.save(preview_path)
    
    def _generate_html_preview(self, docx_path: Path, html_path: Path, stats: Dict) -> None:
        """å°†Wordæ–‡æ¡£è½¬æ¢ä¸ºHTMLé¢„è§ˆï¼Œå°½é‡ä¿æŒä¸åŸæ–‡æ¡£ä¸€è‡´"""
        print(f"[HTMLé¢„è§ˆ] å¼€å§‹ç”ŸæˆHTMLé¢„è§ˆï¼Œè¾“å…¥æ–‡ä»¶: {docx_path}")
        print(f"[HTMLé¢„è§ˆ] è¾“å‡ºæ–‡ä»¶: {html_path}")
        
        # ä¼˜å…ˆå°è¯•ä½¿ç”¨LibreOfficeè½¬æ¢ï¼ˆä¿ç•™æ ¼å¼æœ€å¥½ï¼‰
        print("[HTMLé¢„è§ˆ] å°è¯•ä½¿ç”¨LibreOfficeè½¬æ¢...")
        if self._try_libreoffice_conversion(docx_path, html_path, stats):
            print("[HTMLé¢„è§ˆ] ä½¿ç”¨LibreOfficeè½¬æ¢æˆåŠŸ")
            return
        
        # å›é€€åˆ°è‡ªå®šä¹‰HTMLç”Ÿæˆ
        print("[HTMLé¢„è§ˆ] LibreOfficeä¸å¯ç”¨ï¼Œä½¿ç”¨è‡ªå®šä¹‰HTMLç”Ÿæˆ")
        print(f"[HTMLé¢„è§ˆ] æ­£åœ¨è¯»å–Wordæ–‡æ¡£: {docx_path}")
        document = Document(docx_path)
        print(f"[HTMLé¢„è§ˆ] Wordæ–‡æ¡£è¯»å–æˆåŠŸï¼Œæ€»æ®µè½æ•°: {len(document.paragraphs)}")
        
        # ä¸å†åœ¨é¢„è§ˆæ–‡æ¡£ä¸­æ·»åŠ æ£€æµ‹ç»“æœï¼Œä¿æŒæ–‡æ¡£å¹²å‡€
        # æ£€æµ‹ç»“æœåªåœ¨é¦–é¡µï¼ˆæŠ¥å‘Šï¼‰ä¸­æ˜¾ç¤º
        
        html_content = f"""<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>æ–‡æ¡£é¢„è§ˆ - é¢„è§ˆç‰ˆ</title>
    <style>
        body {{
            font-family: "SimSun", "å®‹ä½“", "Times New Roman", serif;
            max-width: 210mm;
            margin: 20px auto;
            padding: 20px;
            background: #f5f5f5;
            line-height: 1.6;
        }}
        .document-container {{
            background: white;
            padding: 40px;
            box-shadow: 0 0 10px rgba(0,0,0,0.1);
            min-height: 297mm;
        }}
        .watermark {{
            position: fixed;
            top: 50%;
            left: 50%;
            /* ç§»é™¤transformï¼Œé¿å…WeasyPrintå†…éƒ¨é”™è¯¯ */
            margin-top: -36px;
            margin-left: -200px;
            font-size: 72px;
            color: rgba(209, 15, 15, 0.15);
            font-weight: bold;
            pointer-events: none;
            z-index: 1;
            white-space: nowrap;
        }}
        p {{
            margin: 0;
            padding: 0;
            position: relative;
            z-index: 2;
            /* é»˜è®¤æ ¼å¼ä¼šè¢«å†…è”æ ·å¼è¦†ç›– */
        }}
        h1, h2, h3, h4, h5, h6 {{
            margin: 20px 0 10px 0;
            position: relative;
            z-index: 2;
        }}
        h1 {{ font-size: 18pt; font-weight: bold; text-align: center; }}
        h2 {{ font-size: 16pt; font-weight: bold; }}
        h3 {{ font-size: 14pt; font-weight: bold; }}
        .center {{ text-align: center; }}
        .bold {{ font-weight: bold; }}
        .no-indent {{ text-indent: 0; }}
        .warning {{
            background: #fff3cd;
            border: 1px solid #ffc107;
            padding: 15px;
            margin: 20px 0;
            border-radius: 5px;
            text-align: center;
            font-weight: bold;
            color: #856404;
        }}
        @media print {{
            body {{ background: white; }}
            .document-container {{ box-shadow: none; }}
        }}
    </style>
</head>
<body>
    <div class="watermark">é¢„è§ˆç‰ˆ ä»…ä¾›æŸ¥çœ‹</div>
    <div class="document-container">
"""
        
        paragraph_count = 0
        total_text_length = 0
        chinese_char_count = 0
        print(f"[HTMLé¢„è§ˆ] å¼€å§‹å¤„ç† {len(document.paragraphs)} ä¸ªæ®µè½...")
        for idx, paragraph in enumerate(document.paragraphs):
            # æ¯å¤„ç†100ä¸ªæ®µè½è¾“å‡ºä¸€æ¬¡è¿›åº¦
            if idx > 0 and idx % 100 == 0:
                print(f"[HTMLé¢„è§ˆ] å·²å¤„ç† {idx}/{len(document.paragraphs)} ä¸ªæ®µè½...")
            # æ”¹è¿›æ–‡å­—æå–ï¼šä¼˜å…ˆä½¿ç”¨ paragraph.textï¼Œå¦‚æœä¸ºç©ºåˆ™ä» runs ä¸­æå–
            text = paragraph.text.strip()
            if not text:
                # å¦‚æœ paragraph.text ä¸ºç©ºï¼Œå°è¯•ä» runs ä¸­æå–æ‰€æœ‰æ–‡å­—
                text = "".join([run.text for run in paragraph.runs if run.text]).strip()
            
            # ç»Ÿè®¡æ–‡å­—é•¿åº¦å’Œä¸­æ–‡å­—ç¬¦æ•°é‡
            if text:
                total_text_length += len(text)
                # ç»Ÿè®¡ä¸­æ–‡å­—ç¬¦ï¼ˆUnicodeèŒƒå›´ï¼š\u4e00-\u9fffï¼‰
                chinese_chars = [c for c in text if '\u4e00' <= c <= '\u9fff']
                chinese_char_count += len(chinese_chars)
                # è°ƒè¯•ï¼šè®°å½•å‰å‡ ä¸ªåŒ…å«ä¸­æ–‡çš„æ®µè½
                if chinese_chars and idx < 5:
                    print(f"[HTMLé¢„è§ˆ] æ®µè½ {idx} åŒ…å«ä¸­æ–‡: {text[:50]}... (ä¸­æ–‡å­—ç¬¦æ•°: {len(chinese_chars)})")
            
            # æ£€æŸ¥æ®µè½æ ¼å¼ä¸­æ˜¯å¦æœ‰åˆ†é¡µç¬¦
            # python-docxä¸­ï¼Œåˆ†é¡µç¬¦é€šå¸¸é€šè¿‡paragraph_format.page_break_beforeæˆ–runsä¸­çš„breakå…ƒç´ è¡¨ç¤º
            page_break_before = False
            if paragraph.paragraph_format.page_break_before:
                page_break_before = True
                print(f"[HTMLé¢„è§ˆ] æ£€æµ‹åˆ°åˆ†é¡µç¬¦ï¼ˆæ®µè½ {idx}ï¼‰")
            
            # æ£€æŸ¥runsä¸­æ˜¯å¦æœ‰åˆ†é¡µç¬¦
            for run in paragraph.runs:
                if hasattr(run, 'element'):
                    run_xml = str(run.element.xml)
                    if 'w:br' in run_xml and 'type="page"' in run_xml:
                        page_break_before = True
                        print(f"[HTMLé¢„è§ˆ] æ£€æµ‹åˆ°runä¸­çš„åˆ†é¡µç¬¦ï¼ˆæ®µè½ {idx}ï¼‰")
                        break
            
            # å¦‚æœæ£€æµ‹åˆ°åˆ†é¡µç¬¦ï¼Œæ·»åŠ åˆ†é¡µæ ‡è®°
            # æ³¨æ„ï¼šåœ¨æµè§ˆå™¨é¢„è§ˆä¸­ï¼Œpage-break-before: always ä¼šæ˜¾ç¤ºä¸ºç©ºç™½é¡µ
            # å› æ­¤åªåœ¨æ‰“å°æˆ–PDFç”Ÿæˆæ—¶ä½¿ç”¨åˆ†é¡µç¬¦ï¼Œæµè§ˆå™¨é¢„è§ˆä¸­ä¸æ·»åŠ ç©ºç™½é¡µ
            # å¦‚æœéœ€è¦ï¼Œå¯ä»¥æ·»åŠ ä¸€ä¸ªè½»å¾®çš„åˆ†éš”çº¿æ¥æ ‡è¯†åˆ†é¡µä½ç½®ï¼ˆä½†ä¸å ç”¨ç©ºé—´ï¼‰
            if page_break_before:
                # ä½¿ç”¨CSSç±»ï¼Œåœ¨æµè§ˆå™¨ä¸­ä¸æ˜¾ç¤ºç©ºç™½ï¼Œåªåœ¨æ‰“å°/PDFæ—¶ç”Ÿæ•ˆ
                html_content += '<div class="page-break" style="display: none;"></div>\n'
            
            # æ£€æŸ¥æ®µè½æ˜¯å¦åŒ…å«å›¾ç‰‡
            has_image = self._paragraph_has_image_or_equation(paragraph)
            images_html = ""
            
            if has_image:
                # æå–æ®µè½ä¸­çš„å›¾ç‰‡
                if idx < 5 or idx % 50 == 0:  # åªè®°å½•å‰5ä¸ªæˆ–æ¯50ä¸ª
                    print(f"[HTMLé¢„è§ˆ] æ®µè½ {idx} åŒ…å«å›¾ç‰‡ï¼Œæ­£åœ¨æå–...")
                images_html = self._extract_images_from_paragraph(paragraph, document)
                if idx < 5 or idx % 50 == 0:
                    print(f"[HTMLé¢„è§ˆ] æ®µè½ {idx} å›¾ç‰‡æå–å®Œæˆï¼ŒHTMLé•¿åº¦: {len(images_html)} å­—ç¬¦")
                # å¦‚æœæ£€æµ‹åˆ°å›¾ç‰‡ä½†æå–å¤±è´¥ï¼Œè®°å½•è­¦å‘Š
                if not images_html:
                    print(f"[HTMLé¢„è§ˆ] âš ï¸ è­¦å‘Šï¼šæ®µè½ {idx} æ£€æµ‹åˆ°å›¾ç‰‡ä½†æå–å¤±è´¥ï¼")
                # å¦‚æœæå–åˆ°å›¾ç‰‡ä½†HTMLä¸ºç©ºï¼Œè®°å½•è­¦å‘Š
                if not images_html:
                    print(f"[HTMLé¢„è§ˆ] âš ï¸ è­¦å‘Šï¼šæ®µè½ {idx} æ£€æµ‹åˆ°å›¾ç‰‡ä½†æå–å¤±è´¥ï¼")
            
            # åˆ¤æ–­æ®µè½æ ·å¼ï¼ˆæå‰å®šä¹‰ï¼Œé¿å…ä½œç”¨åŸŸé”™è¯¯ï¼‰
            style_name = paragraph.style.name if paragraph.style else "Normal"
            
            # å¦‚æœæ—¢æ²¡æœ‰æ–‡æœ¬ä¹Ÿæ²¡æœ‰å›¾ç‰‡ï¼Œè·³è¿‡ï¼ˆä½†ä¿ç•™ç©ºæ®µè½ä»¥ç»´æŒæ ¼å¼ï¼‰
            if not text and not images_html:
                html_content += "<p>&nbsp;</p>\n"
                continue
            
            # è°ƒè¯•ï¼šè®°å½•æ®µè½ä¿¡æ¯
            if idx < 10 or (text and len(text) > 0):  # åªè®°å½•å‰10ä¸ªæ®µè½æˆ–æœ‰æ–‡å­—çš„æ®µè½
                print(f"[HTMLé¢„è§ˆ] æ®µè½ {idx}: æ–‡å­—é•¿åº¦={len(text)}, æœ‰å›¾ç‰‡={bool(images_html)}, æ ·å¼={style_name}")
            alignment = paragraph.alignment
            
            # æ„å»ºæ ·å¼
            style_attrs = []
            classes = []
            
            # åˆ¤æ–­æ˜¯å¦æ˜¯æ ‡é¢˜ï¼ˆç”¨äºç¡®å®šå­—ä½“ï¼‰
            is_heading_para = False
            if "Heading" in style_name or "æ ‡é¢˜" in style_name:
                is_heading_para = True
            elif paragraph.alignment == WD_PARAGRAPH_ALIGNMENT.CENTER and len(text) <= 20:
                # å±…ä¸­å¯¹é½çš„çŸ­æ–‡æœ¬å¯èƒ½æ˜¯æ ‡é¢˜
                is_heading_para = True
            elif text and text[0].isdigit() and len(text) <= 20:
                # ä»¥æ•°å­—å¼€å¤´çš„çŸ­æ–‡æœ¬å¯èƒ½æ˜¯æ ‡é¢˜
                if re.match(r'^(\d+\.\d+\.\d+|\d+\.\d+|\d+)([ï¼Œ,ã€‚.ï¼š:ï¼›;]?)$', text):
                    is_heading_para = True
            
            if is_heading_para:
                level = 1
                if "1" in style_name or "ä¸€" in style_name:
                    level = 1
                elif "2" in style_name or "äºŒ" in style_name:
                    level = 2
                elif "3" in style_name or "ä¸‰" in style_name:
                    level = 3
                else:
                    level = 2
                # è½¬ä¹‰æ ‡é¢˜æ–‡å­—ï¼ˆåªè½¬ä¹‰ç‰¹æ®Šå­—ç¬¦ï¼Œä¿ç•™ä¸­æ–‡ï¼‰
                if text:
                    escaped_title = text.replace("&", "&amp;").replace("<", "&lt;").replace(">", "&gt;")
                else:
                    escaped_title = ""
                html_content += f"<h{level}>{escaped_title}</h{level}>\n"
                if images_html:
                    html_content += f"<div style='text-align: center; margin: 10px 0;'>{images_html}</div>\n"
            else:
                # æ™®é€šæ®µè½ - ä»Wordæ–‡æ¡£ä¸­æå–å®Œæ•´çš„æ ¼å¼ä¿¡æ¯
                # æå–æ®µè½æ ¼å¼
                para_format = docx_format_utils.extract_paragraph_format(paragraph)
                
                # åº”ç”¨å¯¹é½æ–¹å¼
                if alignment == WD_PARAGRAPH_ALIGNMENT.CENTER:
                    style_attrs.append("text-align: center;")
                elif alignment == WD_PARAGRAPH_ALIGNMENT.RIGHT:
                    style_attrs.append("text-align: right;")
                elif alignment == WD_PARAGRAPH_ALIGNMENT.JUSTIFY:
                    style_attrs.append("text-align: justify;")
                else:
                    style_attrs.append("text-align: left;")
                
                # åº”ç”¨å­—ä½“å’Œå­—å·ï¼ˆä»runsä¸­æå–ï¼‰
                font_name = para_format.get("font_name")
                font_size = para_format.get("font_size")
                
                # å¦‚æœä»runsä¸­æå–ä¸åˆ°å­—ä½“ï¼Œå°è¯•ä»æ®µè½æ ·å¼ä¸­è·å–
                if not font_name and paragraph.style:
                    try:
                        # å°è¯•ä»æ®µè½æ ·å¼çš„å­—ä½“è®¾ç½®ä¸­è·å–
                        style_font = paragraph.style.font
                        if style_font and style_font.name:
                            font_name = style_font.name
                            if idx < 10:
                                print(f"[HTMLé¢„è§ˆ] æ®µè½ {idx} ä»æ ·å¼è·å–å­—ä½“: {font_name}")
                    except:
                        pass
                
                # æ ¹æ®æå–åˆ°çš„å­—ä½“ä¿¡æ¯ï¼Œç¡®å®šæœ€ç»ˆä½¿ç”¨çš„å­—ä½“
                # æ”¯æŒï¼šé»‘ä½“ã€å®‹ä½“ã€æ¥·ä½“ã€Times New Roman
                font_family_css = None
                
                if font_name:
                    font_name_lower = font_name.lower()
                    # é»‘ä½“è¯†åˆ«
                    if "é»‘" in font_name or "simhei" in font_name_lower or "hei" in font_name_lower or "heiti" in font_name_lower:
                        font_family_css = '"SimHei", "é»‘ä½“", "STHeiti", "WenQuanYi Micro Hei", "WenQuanYi Zen Hei", sans-serif'
                        if idx < 10:
                            print(f"[HTMLé¢„è§ˆ] æ®µè½ {idx} å­—ä½“: {font_name} -> é»‘ä½“")
                    # å®‹ä½“è¯†åˆ«
                    elif "å®‹" in font_name or "simsun" in font_name_lower or "song" in font_name_lower or "songti" in font_name_lower:
                        font_family_css = '"SimSun", "å®‹ä½“", "STSong", "STSongti-SC-Regular", "WenQuanYi Micro Hei", "WenQuanYi Zen Hei", serif'
                        if idx < 10:
                            print(f"[HTMLé¢„è§ˆ] æ®µè½ {idx} å­—ä½“: {font_name} -> å®‹ä½“")
                    # æ¥·ä½“è¯†åˆ«
                    elif "æ¥·" in font_name or "kaiti" in font_name_lower or "kai" in font_name_lower:
                        font_family_css = '"KaiTi", "æ¥·ä½“", "STKaiti", "WenQuanYi Micro Hei", "WenQuanYi Zen Hei", serif'
                        if idx < 10:
                            print(f"[HTMLé¢„è§ˆ] æ®µè½ {idx} å­—ä½“: {font_name} -> æ¥·ä½“")
                    # Times New Roman è¯†åˆ«
                    elif "times" in font_name_lower or "new roman" in font_name_lower or "tnr" in font_name_lower:
                        font_family_css = '"Times New Roman", "Times", "Liberation Serif", "DejaVu Serif", serif'
                        if idx < 10:
                            print(f"[HTMLé¢„è§ˆ] æ®µè½ {idx} å­—ä½“: {font_name} -> Times New Roman")
                
                # å¦‚æœæ²¡æœ‰è¯†åˆ«åˆ°å­—ä½“ï¼Œæ ¹æ®æ®µè½ç±»å‹ä½¿ç”¨é»˜è®¤å­—ä½“
                if not font_family_css:
                    if is_heading_para:
                        # æ ‡é¢˜é»˜è®¤ä½¿ç”¨é»‘ä½“
                        font_family_css = '"SimHei", "é»‘ä½“", "STHeiti", "WenQuanYi Micro Hei", "WenQuanYi Zen Hei", sans-serif'
                        if idx < 10:
                            print(f"[HTMLé¢„è§ˆ] æ®µè½ {idx} æ ‡é¢˜ä½¿ç”¨é»˜è®¤å­—ä½“ï¼šé»‘ä½“ï¼ˆåŸå­—ä½“: {font_name or 'æœªæå–'}ï¼‰")
                    else:
                        # æ­£æ–‡é»˜è®¤ä½¿ç”¨å®‹ä½“
                        font_family_css = '"SimSun", "å®‹ä½“", "STSong", "STSongti-SC-Regular", "WenQuanYi Micro Hei", "WenQuanYi Zen Hei", serif'
                        if idx < 10:
                            print(f"[HTMLé¢„è§ˆ] æ®µè½ {idx} æ­£æ–‡ä½¿ç”¨é»˜è®¤å­—ä½“ï¼šå®‹ä½“ï¼ˆåŸå­—ä½“: {font_name or 'æœªæå–'}ï¼‰")
                
                style_attrs.append(f'font-family: {font_family_css};')
                
                if font_size:
                    style_attrs.append(f"font-size: {font_size}pt;")
                else:
                    # å¦‚æœæ²¡æœ‰å­—å·ï¼Œä½¿ç”¨é»˜è®¤å­—å·
                    if is_heading_para:
                        style_attrs.append("font-size: 16pt;")
                    else:
                        style_attrs.append("font-size: 12pt;")
                
                # åº”ç”¨åŠ ç²—
                is_bold = para_format.get("bold") or any(run.bold for run in paragraph.runs if run.bold)
                if is_bold:
                    style_attrs.append("font-weight: bold;")
                
                # åº”ç”¨è¡Œè·
                line_spacing = para_format.get("line_spacing")
                if line_spacing:
                    if isinstance(line_spacing, (int, float)):
                        # å›ºå®šè¡Œè·ï¼ˆç£…ï¼‰
                        style_attrs.append(f"line-height: {line_spacing}pt;")
                    elif line_spacing == "single":
                        style_attrs.append("line-height: 1.0;")
                    elif line_spacing == "double":
                        style_attrs.append("line-height: 2.0;")
                    elif line_spacing == "1.5":
                        style_attrs.append("line-height: 1.5;")
                
                # åº”ç”¨é¦–è¡Œç¼©è¿›
                first_line_indent = para_format.get("first_line_indent")
                if first_line_indent and first_line_indent > 0:
                    style_attrs.append(f"text-indent: {first_line_indent}pt;")
                else:
                    # é»˜è®¤é¦–è¡Œç¼©è¿›2å­—ç¬¦ï¼ˆ24ptï¼‰
                    style_attrs.append("text-indent: 24pt;")
                
                # åº”ç”¨æ®µå‰æ®µåé—´è·
                space_before = para_format.get("space_before")
                space_after = para_format.get("space_after")
                if space_before and space_before > 0:
                    style_attrs.append(f"margin-top: {space_before}pt;")
                if space_after and space_after > 0:
                    style_attrs.append(f"margin-bottom: {space_after}pt;")
                
                # åº”ç”¨å·¦å³ç¼©è¿›
                left_indent = para_format.get("left_indent")
                right_indent = para_format.get("right_indent")
                if left_indent and left_indent > 0:
                    style_attrs.append(f"margin-left: {left_indent}pt;")
                if right_indent and right_indent > 0:
                    style_attrs.append(f"margin-right: {right_indent}pt;")
                
                class_attr = f' class="{" ".join(classes)}"' if classes else ""
                style_attr = f' style="{" ".join(style_attrs)}"' if style_attrs else ""
                
                # å¤„ç†æ–‡æœ¬ä¸­çš„ç‰¹æ®Šå­—ç¬¦
                # æ³¨æ„ï¼šxml.sax.saxutils.escape åªè½¬ä¹‰ & < >ï¼Œä¸ä¼šå½±å“ä¸­æ–‡å­—ç¬¦
                # ä½†ä¸ºäº†å®‰å…¨ï¼Œæˆ‘ä»¬åªè½¬ä¹‰å¿…è¦çš„å­—ç¬¦ï¼Œä¿ç•™ä¸­æ–‡å­—ç¬¦
                if text:
                    escaped_text = text.replace("&", "&amp;").replace("<", "&lt;").replace(">", "&gt;")
                else:
                    escaped_text = ""
                
                # å¦‚æœæœ‰å›¾ç‰‡ï¼Œå…ˆæ˜¾ç¤ºå›¾ç‰‡ï¼Œå†æ˜¾ç¤ºæ–‡æœ¬
                if images_html:
                    # å›¾ç‰‡æ®µè½é€šå¸¸å±…ä¸­æ˜¾ç¤ºï¼Œç¡®ä¿å›¾ç‰‡èƒ½æ­£ç¡®æ˜¾ç¤º
                    html_content += f'<div style="text-align: center; margin: 10px 0; page-break-inside: avoid;">{images_html}</div>\n'
                    if idx < 5:  # åªè®°å½•å‰5ä¸ªæ®µè½çš„è¯¦ç»†ä¿¡æ¯
                        print(f"[HTMLé¢„è§ˆ] æ®µè½ {idx} æ·»åŠ å›¾ç‰‡HTML: {len(images_html)} å­—ç¬¦")
                if text:
                    # ç¡®ä¿æ–‡å­—è¢«æ·»åŠ åˆ°HTMLä¸­
                    html_content += f'<p{class_attr}{style_attr}>{escaped_text}</p>\n'
        
        html_content += """    </div>
    <div class="warning">
        âš ï¸ è¿™æ˜¯é¢„è§ˆç‰ˆæœ¬ï¼Œä»…ä¾›æŸ¥çœ‹ã€‚å¦‚éœ€ä¸‹è½½æ­£å¼ç‰ˆï¼Œè¯·å®Œæˆæ”¯ä»˜ã€‚
    </div>
</body>
</html>"""
        
        print(f"[HTMLé¢„è§ˆ] æ®µè½å¤„ç†å®Œæˆï¼Œå¼€å§‹å†™å…¥HTMLæ–‡ä»¶...")
        # è®°å½•ç»Ÿè®¡ä¿¡æ¯
        print(f"[HTMLé¢„è§ˆ] HTMLç”Ÿæˆå®Œæˆï¼Œæ€»æ®µè½æ•°: {paragraph_count}, æ€»æ–‡å­—é•¿åº¦: {total_text_length} å­—ç¬¦")
        print(f"[HTMLé¢„è§ˆ] ä¸­æ–‡å­—ç¬¦æ•°: {chinese_char_count} å­—ç¬¦")
        print(f"[HTMLé¢„è§ˆ] HTMLå†…å®¹å¤§å°: {len(html_content) / 1024:.2f} KB")
        # æ£€æŸ¥HTMLä¸­æ˜¯å¦åŒ…å«ä¸­æ–‡å­—ç¬¦
        html_chinese_count = len([c for c in html_content if '\u4e00' <= c <= '\u9fff'])
        print(f"[HTMLé¢„è§ˆ] HTMLä¸­çš„ä¸­æ–‡å­—ç¬¦æ•°: {html_chinese_count} å­—ç¬¦")
        if chinese_char_count > 0 and html_chinese_count == 0:
            print(f"[HTMLé¢„è§ˆ] âš ï¸ è­¦å‘Šï¼šæå–åˆ° {chinese_char_count} ä¸ªä¸­æ–‡å­—ç¬¦ï¼Œä½†HTMLä¸­åªæœ‰ {html_chinese_count} ä¸ªï¼")
        
        html_path.write_text(html_content, encoding="utf-8")
    
    def _extract_images_from_paragraph(self, paragraph, document: Document) -> str:
        """ä»æ®µè½ä¸­æå–å›¾ç‰‡å¹¶è½¬æ¢ä¸ºHTML imgæ ‡ç­¾"""
        import zipfile
        
        images_html = ""
        image_count = 0
        
        try:
            # è·å–æ–‡æ¡£çš„zipæ–‡ä»¶è·¯å¾„ï¼ˆdocxæ˜¯zipæ ¼å¼ï¼‰
            docx_path = document.part.package
            
            # æ–¹æ³•1: ä»runsä¸­æå–å›¾ç‰‡
            for run in paragraph.runs:
                if not hasattr(run, 'element'):
                    continue
                
                try:
                    run_xml = str(run.element.xml)
                    # æ’é™¤æ°´å°
                    if 'v:shape' in run_xml.lower() and 'textpath' in run_xml.lower():
                        continue
                    
                    # æŸ¥æ‰¾å›¾ç‰‡å…³ç³»IDï¼ˆæ”¯æŒå¤šç§æ ¼å¼ï¼‰
                    image_id = None
                    # å°è¯•å¤šç§æ–¹å¼æŸ¥æ‰¾å›¾ç‰‡ID
                    if 'r:embed' in run_xml:
                        # å†…åµŒå›¾ç‰‡
                        match = re.search(r'r:embed="([^"]+)"', run_xml)
                        if match:
                            image_id = match.group(1)
                    elif 'r:link' in run_xml:
                        # é“¾æ¥å›¾ç‰‡
                        match = re.search(r'r:link="([^"]+)"', run_xml)
                        if match:
                            image_id = match.group(1)
                    # ä¹Ÿå°è¯•æŸ¥æ‰¾a:blipä¸­çš„embedå±æ€§
                    if not image_id and 'a:blip' in run_xml:
                        match = re.search(r'r:embed="([^"]+)"', run_xml)
                        if match:
                            image_id = match.group(1)
                    
                    if image_id:
                        # ä»æ–‡æ¡£ä¸­æå–å›¾ç‰‡æ•°æ®
                        try:
                            # å°è¯•ä»å¤šä¸ªä½ç½®è·å–å›¾ç‰‡
                            image_part = None
                            
                            # æ–¹æ³•1: ä»ä¸»æ–‡æ¡£éƒ¨åˆ†è·å–
                            if hasattr(document.part, 'related_parts') and image_id in document.part.related_parts:
                                image_part = document.part.related_parts[image_id]
                                print(f"[HTMLé¢„è§ˆ] ä»ä¸»æ–‡æ¡£éƒ¨åˆ†æ‰¾åˆ°å›¾ç‰‡: {image_id}")
                            
                            # æ–¹æ³•2: ä»runçš„partè·å–
                            if not image_part and hasattr(run, 'part') and hasattr(run.part, 'related_parts'):
                                if image_id in run.part.related_parts:
                                    image_part = run.part.related_parts[image_id]
                                    print(f"[HTMLé¢„è§ˆ] ä»run.partæ‰¾åˆ°å›¾ç‰‡: {image_id}")
                            
                            # æ–¹æ³•3: ä»æ–‡æ¡£çš„æ‰€æœ‰éƒ¨åˆ†æŸ¥æ‰¾
                            if not image_part:
                                # å°è¯•ä»æ–‡æ¡£çš„æ‰€æœ‰ç›¸å…³éƒ¨åˆ†æŸ¥æ‰¾
                                for rel in document.part.rels.values():
                                    if rel.rId == image_id:
                                        image_part = rel.target_part
                                        print(f"[HTMLé¢„è§ˆ] ä»æ–‡æ¡£å…³ç³»ä¸­æ‰¾åˆ°å›¾ç‰‡: {image_id}")
                                        break
                            
                            if not image_part:
                                print(f"[HTMLé¢„è§ˆ] è­¦å‘Š: æœªæ‰¾åˆ°å›¾ç‰‡å…³ç³»ID: {image_id}")
                                continue
                                
                            image_data = image_part.blob
                            if not image_data:
                                print(f"[HTMLé¢„è§ˆ] è­¦å‘Š: å›¾ç‰‡æ•°æ®ä¸ºç©º: {image_id}")
                                continue
                            
                            # ç¡®å®šå›¾ç‰‡æ ¼å¼
                            content_type = image_part.content_type if hasattr(image_part, 'content_type') else ''
                            
                            # æ£€æŸ¥æ˜¯å¦ä¸ºä¸æ”¯æŒçš„æ ¼å¼ï¼ˆWMFã€EMFç­‰ï¼‰
                            if 'wmf' in content_type.lower() or 'emf' in content_type.lower() or 'x-wmf' in content_type.lower():
                                print(f"[HTMLé¢„è§ˆ] âš ï¸ è·³è¿‡ä¸æ”¯æŒçš„å›¾ç‰‡æ ¼å¼: {content_type} (WeasyPrintä¸æ”¯æŒWMF/EMFæ ¼å¼)")
                                continue
                            
                            if 'jpeg' in content_type or 'jpg' in content_type:
                                img_format = 'jpeg'
                            elif 'png' in content_type:
                                img_format = 'png'
                            elif 'gif' in content_type:
                                img_format = 'gif'
                            elif 'bmp' in content_type:
                                img_format = 'bmp'
                            elif 'webp' in content_type:
                                img_format = 'webp'
                            else:
                                # æ£€æŸ¥æ–‡ä»¶å¤´æ¥ç¡®å®šæ ¼å¼
                                if image_data.startswith(b'\x89PNG'):
                                    img_format = 'png'
                                elif image_data.startswith(b'\xff\xd8\xff'):
                                    img_format = 'jpeg'
                                elif image_data.startswith(b'GIF'):
                                    img_format = 'gif'
                                elif image_data.startswith(b'BM'):
                                    img_format = 'bmp'
                                elif image_data.startswith(b'RIFF') and b'WEBP' in image_data[:12]:
                                    img_format = 'webp'
                                else:
                                    # å°è¯•ä»æ–‡ä»¶æ‰©å±•ååˆ¤æ–­
                                    if hasattr(image_part, 'partname'):
                                        partname = str(image_part.partname)
                                        if '.jpg' in partname or '.jpeg' in partname:
                                            img_format = 'jpeg'
                                        elif '.png' in partname:
                                            img_format = 'png'
                                        elif '.gif' in partname:
                                            img_format = 'gif'
                                        else:
                                            print(f"[HTMLé¢„è§ˆ] âš ï¸ æœªçŸ¥å›¾ç‰‡æ ¼å¼: {content_type}ï¼Œè·³è¿‡")
                                            continue
                                    else:
                                        print(f"[HTMLé¢„è§ˆ] âš ï¸ æœªçŸ¥å›¾ç‰‡æ ¼å¼: {content_type}ï¼Œè·³è¿‡")
                                        continue
                                    
                                # å¦‚æœåˆ°è¿™é‡Œè¿˜æ²¡æœ‰è®¾ç½® img_formatï¼Œä½¿ç”¨é»˜è®¤å€¼
                                if 'img_format' not in locals():
                                    img_format = 'png'  # é»˜è®¤
                            
                            # è½¬æ¢ä¸ºbase64
                            base64_data = base64.b64encode(image_data).decode('utf-8')
                            data_uri = f"data:image/{img_format};base64,{base64_data}"
                            
                            # åˆ›å»ºimgæ ‡ç­¾
                            images_html += f'<img src="{data_uri}" style="max-width: 100%; height: auto; margin: 10px 0;" alt="å›¾ç‰‡ {image_count + 1}" />'
                            image_count += 1
                            print(f"[HTMLé¢„è§ˆ] æˆåŠŸæå–å›¾ç‰‡ {image_count}ï¼Œæ ¼å¼: {img_format}ï¼Œå¤§å°: {len(image_data)} å­—èŠ‚")
                            
                        except Exception as e:
                            print(f"[HTMLé¢„è§ˆ] æå–å›¾ç‰‡å¤±è´¥: {e}")
                            import traceback
                            print(f"[HTMLé¢„è§ˆ] é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
                            continue
                            
                except Exception as e:
                    print(f"[HTMLé¢„è§ˆ] å¤„ç†runæ—¶å‡ºé”™: {e}")
                    continue
            
            # æ–¹æ³•2: ä»æ®µè½çš„å†…è”å½¢çŠ¶ä¸­æå–å›¾ç‰‡ï¼ˆå³ä½¿æ–¹æ³•1å·²ç»æ‰¾åˆ°å›¾ç‰‡ï¼Œä¹Ÿç»§ç»­æŸ¥æ‰¾ï¼Œå› ä¸ºä¸€ä¸ªæ®µè½å¯èƒ½æœ‰å¤šä¸ªå›¾ç‰‡ï¼‰
            if hasattr(paragraph, '_element'):
                try:
                    # æŸ¥æ‰¾drawingå…ƒç´ ï¼ˆä½¿ç”¨findallé…åˆqnï¼Œè€Œä¸æ˜¯xpath with namespacesï¼‰
                    drawings = paragraph._element.findall('.//' + qn('w:drawing'))
                    
                    for drawing in drawings:
                        # æŸ¥æ‰¾å›¾ç‰‡å…³ç³»ID
                        blip_elements = drawing.findall('.//' + qn('a:blip'))
                        
                        for blip in blip_elements:
                            embed_attr = blip.get('{http://schemas.openxmlformats.org/officeDocument/2006/relationships}embed')
                            link_attr = blip.get('{http://schemas.openxmlformats.org/officeDocument/2006/relationships}link')
                            
                            image_id = embed_attr or link_attr
                            if image_id:
                                try:
                                    # æ£€æŸ¥æ˜¯å¦å·²ç»å¤„ç†è¿‡è¿™ä¸ªå›¾ç‰‡ï¼ˆé¿å…é‡å¤ï¼‰
                                    # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå…è®¸é‡å¤ï¼ˆå› ä¸ºå¯èƒ½æœ‰ä¸åŒçš„å¼•ç”¨æ–¹å¼ï¼‰
                                    
                                    # å°è¯•ä»å¤šä¸ªä½ç½®è·å–å›¾ç‰‡
                                    image_part = None
                                    
                                    # æ–¹æ³•1: ä»ä¸»æ–‡æ¡£éƒ¨åˆ†è·å–
                                    if hasattr(document.part, 'related_parts') and image_id in document.part.related_parts:
                                        image_part = document.part.related_parts[image_id]
                                        print(f"[HTMLé¢„è§ˆ] ä»drawingæ‰¾åˆ°å›¾ç‰‡ï¼ˆä¸»æ–‡æ¡£ï¼‰: {image_id}")
                                    
                                    # æ–¹æ³•2: ä»æ–‡æ¡£çš„æ‰€æœ‰å…³ç³»æŸ¥æ‰¾
                                    if not image_part:
                                        for rel in document.part.rels.values():
                                            if rel.rId == image_id:
                                                image_part = rel.target_part
                                                print(f"[HTMLé¢„è§ˆ] ä»drawingæ‰¾åˆ°å›¾ç‰‡ï¼ˆå…³ç³»ï¼‰: {image_id}")
                                                break
                                    
                                    if not image_part:
                                        print(f"[HTMLé¢„è§ˆ] è­¦å‘Š: ä»drawingæœªæ‰¾åˆ°å›¾ç‰‡å…³ç³»ID: {image_id}")
                                        continue
                                        
                                    image_data = image_part.blob
                                    if not image_data:
                                        print(f"[HTMLé¢„è§ˆ] è­¦å‘Š: ä»drawingè·å–çš„å›¾ç‰‡æ•°æ®ä¸ºç©º: {image_id}")
                                        continue
                                    
                                    # ç¡®å®šå›¾ç‰‡æ ¼å¼
                                    content_type = image_part.content_type if hasattr(image_part, 'content_type') else ''
                                    
                                    # æ£€æŸ¥æ˜¯å¦ä¸ºä¸æ”¯æŒçš„æ ¼å¼ï¼ˆWMFã€EMFç­‰ï¼‰
                                    if 'wmf' in content_type.lower() or 'emf' in content_type.lower() or 'x-wmf' in content_type.lower():
                                        print(f"[HTMLé¢„è§ˆ] âš ï¸ è·³è¿‡ä¸æ”¯æŒçš„å›¾ç‰‡æ ¼å¼: {content_type} (WeasyPrintä¸æ”¯æŒWMF/EMFæ ¼å¼)")
                                        # å¯ä»¥æ·»åŠ ä¸€ä¸ªå ä½ç¬¦å›¾ç‰‡
                                        images_html += f'<div style="border: 1px dashed #ccc; padding: 20px; text-align: center; color: #999; margin: 10px 0;">[å›¾ç‰‡æ ¼å¼ä¸æ”¯æŒ: {content_type}]</div>'
                                        continue
                                    
                                    if 'jpeg' in content_type or 'jpg' in content_type:
                                        img_format = 'jpeg'
                                    elif 'png' in content_type:
                                        img_format = 'png'
                                    elif 'gif' in content_type:
                                        img_format = 'gif'
                                    elif 'bmp' in content_type:
                                        img_format = 'bmp'
                                    elif 'webp' in content_type:
                                        img_format = 'webp'
                                    else:
                                        # æ£€æŸ¥æ–‡ä»¶å¤´æ¥ç¡®å®šæ ¼å¼
                                        if image_data.startswith(b'\x89PNG'):
                                            img_format = 'png'
                                        elif image_data.startswith(b'\xff\xd8\xff'):
                                            img_format = 'jpeg'
                                        elif image_data.startswith(b'GIF'):
                                            img_format = 'gif'
                                        elif image_data.startswith(b'BM'):
                                            img_format = 'bmp'
                                        elif image_data.startswith(b'RIFF') and b'WEBP' in image_data[:12]:
                                            img_format = 'webp'
                                        else:
                                            print(f"[HTMLé¢„è§ˆ] âš ï¸ æœªçŸ¥å›¾ç‰‡æ ¼å¼: {content_type}ï¼Œè·³è¿‡")
                                            images_html += f'<div style="border: 1px dashed #ccc; padding: 20px; text-align: center; color: #999; margin: 10px 0;">[å›¾ç‰‡æ ¼å¼æœªçŸ¥: {content_type}]</div>'
                                            continue
                                    
                                    # è½¬æ¢ä¸ºbase64
                                    base64_data = base64.b64encode(image_data).decode('utf-8')
                                    data_uri = f"data:image/{img_format};base64,{base64_data}"
                                    
                                    # åˆ›å»ºimgæ ‡ç­¾
                                    images_html += f'<img src="{data_uri}" style="max-width: 100%; height: auto; margin: 10px 0;" alt="å›¾ç‰‡ {image_count + 1}" />'
                                    image_count += 1
                                    print(f"[HTMLé¢„è§ˆ] ä»drawingæˆåŠŸæå–å›¾ç‰‡ {image_count}ï¼Œæ ¼å¼: {img_format}ï¼Œå¤§å°: {len(image_data)} å­—èŠ‚")
                                    
                                except Exception as e:
                                    print(f"[HTMLé¢„è§ˆ] ä»drawingæå–å›¾ç‰‡å¤±è´¥: {e}")
                                    import traceback
                                    print(f"[HTMLé¢„è§ˆ] é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
                                    continue
                                    
                except Exception as e:
                    print(f"[HTMLé¢„è§ˆ] å¤„ç†drawingæ—¶å‡ºé”™: {e}")
                    import traceback
                    print(f"[HTMLé¢„è§ˆ] é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
                    pass
            
            # æ–¹æ³•3: å¦‚æœå‰ä¸¤ç§æ–¹æ³•éƒ½æ²¡æ‰¾åˆ°å›¾ç‰‡ï¼Œå°è¯•ç›´æ¥ä»zipæ–‡ä»¶ä¸­æå–
            # è¿™é€‚ç”¨äºæŸäº›ç‰¹æ®Šæ ¼å¼çš„å›¾ç‰‡æˆ–å…³ç³»IDæŸ¥æ‰¾å¤±è´¥çš„æƒ…å†µ
            if not images_html and hasattr(document, 'part') and hasattr(document.part, 'package'):
                try:
                    # è·å–docxæ–‡ä»¶çš„è·¯å¾„
                    docx_file_path = None
                    if hasattr(document.part.package, 'name'):
                        docx_file_path = document.part.package.name
                    elif hasattr(document.part.package, '__file__'):
                        docx_file_path = document.part.package.__file__
                    
                    if docx_file_path:
                        import zipfile
                        from pathlib import Path
                        
                        docx_path = Path(docx_file_path)
                        if docx_path.exists() and docx_path.suffix.lower() == '.docx':
                            print(f"[HTMLé¢„è§ˆ] å°è¯•ä»zipæ–‡ä»¶ç›´æ¥æå–å›¾ç‰‡: {docx_path}")
                            
                            with zipfile.ZipFile(docx_path, 'r') as zip_ref:
                                # æŸ¥æ‰¾æ‰€æœ‰å›¾ç‰‡æ–‡ä»¶ï¼ˆé€šå¸¸åœ¨word/media/ç›®å½•ä¸‹ï¼‰
                                image_files = [f for f in zip_ref.namelist() 
                                             if f.startswith('word/media/') and 
                                             any(f.lower().endswith(ext) for ext in ['.png', '.jpg', '.jpeg', '.gif', '.bmp', '.webp'])]
                                
                                print(f"[HTMLé¢„è§ˆ] åœ¨zipæ–‡ä»¶ä¸­æ‰¾åˆ° {len(image_files)} ä¸ªå›¾ç‰‡æ–‡ä»¶")
                                
                                # å°è¯•ä»æ®µè½XMLä¸­æŸ¥æ‰¾å¼•ç”¨çš„å›¾ç‰‡æ–‡ä»¶å
                                para_xml = str(paragraph._element.xml) if hasattr(paragraph, '_element') else ''
                                
                                for img_file in image_files:
                                    # æ£€æŸ¥è¿™ä¸ªå›¾ç‰‡æ˜¯å¦å¯èƒ½å±äºå½“å‰æ®µè½
                                    # é€šè¿‡æ£€æŸ¥å›¾ç‰‡æ–‡ä»¶åæ˜¯å¦åœ¨æ®µè½XMLä¸­è¢«å¼•ç”¨
                                    img_filename = Path(img_file).name
                                    
                                    # å¦‚æœæ®µè½åŒ…å«drawingæˆ–å›¾ç‰‡ç›¸å…³å…ƒç´ ï¼Œå°è¯•åŒ¹é…
                                    if ('drawing' in para_xml.lower() or 'pic:pic' in para_xml.lower() or 'a:blip' in para_xml.lower()):
                                        try:
                                            # è¯»å–å›¾ç‰‡æ•°æ®
                                            image_data = zip_ref.read(img_file)
                                            
                                            # ç¡®å®šå›¾ç‰‡æ ¼å¼
                                            img_format = 'png'  # é»˜è®¤
                                            if img_file.lower().endswith('.jpg') or img_file.lower().endswith('.jpeg'):
                                                img_format = 'jpeg'
                                            elif img_file.lower().endswith('.png'):
                                                img_format = 'png'
                                            elif img_file.lower().endswith('.gif'):
                                                img_format = 'gif'
                                            elif img_file.lower().endswith('.bmp'):
                                                img_format = 'bmp'
                                            elif img_file.lower().endswith('.webp'):
                                                img_format = 'webp'
                                            
                                            # è½¬æ¢ä¸ºbase64
                                            base64_data = base64.b64encode(image_data).decode('utf-8')
                                            data_uri = f"data:image/{img_format};base64,{base64_data}"
                                            
                                            # åˆ›å»ºimgæ ‡ç­¾ï¼ˆåªæ·»åŠ ä¸€æ¬¡ï¼Œé¿å…é‡å¤ï¼‰
                                            if img_filename not in images_html:
                                                images_html += f'<img src="{data_uri}" style="max-width: 100%; height: auto; margin: 10px 0;" alt="å›¾ç‰‡ {image_count + 1}" />'
                                                image_count += 1
                                                print(f"[HTMLé¢„è§ˆ] ä»zipæ–‡ä»¶æˆåŠŸæå–å›¾ç‰‡ {image_count}: {img_filename}ï¼Œæ ¼å¼: {img_format}ï¼Œå¤§å°: {len(image_data)} å­—èŠ‚")
                                                
                                                # å¦‚æœå·²ç»æ‰¾åˆ°ä¸€ä¸ªå›¾ç‰‡ï¼Œå°±åœæ­¢ï¼ˆé¿å…ä¸€ä¸ªæ®µè½æ˜¾ç¤ºå¤šä¸ªå›¾ç‰‡ï¼‰
                                                # å¦‚æœéœ€è¦æ˜¾ç¤ºå¤šä¸ªå›¾ç‰‡ï¼Œå¯ä»¥ç§»é™¤è¿™ä¸ªbreak
                                                if image_count >= 1:
                                                    break
                                                    
                                        except Exception as e:
                                            print(f"[HTMLé¢„è§ˆ] ä»zipæ–‡ä»¶è¯»å–å›¾ç‰‡å¤±è´¥ {img_file}: {e}")
                                            continue
                                            
                except Exception as e:
                    print(f"[HTMLé¢„è§ˆ] ä»zipæ–‡ä»¶æå–å›¾ç‰‡æ—¶å‡ºé”™: {e}")
                    import traceback
                    print(f"[HTMLé¢„è§ˆ] é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
                    pass
        
        except Exception as e:
            print(f"[HTMLé¢„è§ˆ] æå–å›¾ç‰‡æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            import traceback
            print(f"[HTMLé¢„è§ˆ] é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
        
        if images_html:
            print(f"[HTMLé¢„è§ˆ] æ®µè½å›¾ç‰‡æå–å®Œæˆï¼Œå…±æå– {image_count} å¼ å›¾ç‰‡")
        else:
            # å¦‚æœæ²¡æ‰¾åˆ°å›¾ç‰‡ï¼Œä½†æ®µè½åŒ…å«drawingå…ƒç´ ï¼Œè®°å½•è­¦å‘Š
            if hasattr(paragraph, '_element'):
                para_xml = str(paragraph._element.xml)
                if 'drawing' in para_xml.lower() or 'pic:pic' in para_xml.lower():
                    print(f"[HTMLé¢„è§ˆ] è­¦å‘Š: æ®µè½åŒ…å«drawingå…ƒç´ ä½†æœªæå–åˆ°å›¾ç‰‡ï¼ŒXMLç‰‡æ®µ: {para_xml[:200]}")
        
        return images_html
    
    def _generate_pdf_preview(self, docx_path: Path, pdf_path: Path, stats: Dict) -> bool:
        """å°†Wordæ–‡æ¡£è½¬æ¢ä¸ºPDFé¢„è§ˆï¼ˆä½¿ç”¨WeasyPrintä»HTMLè½¬PDFï¼‰
        
        æ³¨æ„ï¼šLibreOffice åœ¨æŸäº›ç¯å¢ƒä¸‹æ— æ³•æ­£å¸¸å·¥ä½œï¼Œå› æ­¤ç›´æ¥ä½¿ç”¨ WeasyPrint
        """
        print(f"[PDFé¢„è§ˆ] å¼€å§‹ç”ŸæˆPDFé¢„è§ˆï¼Œè¾“å…¥æ–‡ä»¶: {docx_path}, è¾“å‡ºæ–‡ä»¶: {pdf_path}")
        try:
            from weasyprint import HTML, CSS
            # ä¸å†å¯¼å…¥FontConfigurationï¼Œé¿å…transformé”™è¯¯
            print("[PDFé¢„è§ˆ] WeasyPrintå¯¼å…¥æˆåŠŸ")
        except ImportError as e:
            print(f"[PDFé¢„è§ˆ] âŒ weasyprintæœªå®‰è£…ï¼Œè·³è¿‡PDFç”Ÿæˆ: {e}")
            import traceback
            traceback.print_exc()
            return False
        
        try:
            # å…ˆç”ŸæˆHTMLï¼ˆç”¨äºPDFè½¬æ¢ï¼‰
            html_path = pdf_path.with_suffix('.html')
            print(f"[PDFé¢„è§ˆ] å¼€å§‹ç”ŸæˆHTMLé¢„è§ˆ: {html_path}")
            self._generate_html_preview(docx_path, html_path, stats)
            
            # æ£€æŸ¥HTMLæ–‡ä»¶æ˜¯å¦ç”ŸæˆæˆåŠŸ
            if not html_path.exists():
                print(f"[PDFé¢„è§ˆ] é”™è¯¯: HTMLæ–‡ä»¶æœªç”Ÿæˆ: {html_path}")
                return False
            
            # è¯»å–Wordæ–‡æ¡£çš„é¡µé¢è®¾ç½®
            from docx import Document
            doc = Document(docx_path)
            page_settings = self._extract_page_settings(doc)
            
            # è¯»å–HTMLå†…å®¹
            html_content = html_path.read_text(encoding='utf-8')
            
            # ç”ŸæˆPDFä¸“ç”¨æ ·å¼ï¼ˆä½¿ç”¨Wordæ–‡æ¡£çš„é¡µé¢è®¾ç½®ï¼‰
            pdf_css = self._generate_pdf_css(page_settings)
            
            # åœ¨HTMLçš„headä¸­æ·»åŠ CSSå’Œmetaæ ‡ç­¾ï¼ˆç¡®ä¿UTF-8ç¼–ç ï¼‰
            if '</head>' in html_content:
                # æ£€æŸ¥æ˜¯å¦å·²æœ‰charset metaæ ‡ç­¾
                if 'charset' not in html_content.lower():
                    html_content = html_content.replace('</head>', '<meta charset="UTF-8">\n</head>')
                html_content = html_content.replace('</head>', f'<style>{pdf_css}</style></head>')
            else:
                # å¦‚æœæ²¡æœ‰headæ ‡ç­¾ï¼Œæ·»åŠ ä¸€ä¸ª
                if '<html' in html_content:
                    html_content = html_content.replace('<html', '<html><head><meta charset="UTF-8"><style>' + pdf_css + '</style></head>')
            
            print(f"[PDFé¢„è§ˆ] å¼€å§‹è½¬æ¢HTMLåˆ°PDFï¼ŒHTMLå¤§å°: {len(html_content) / 1024:.2f} KB")
            
            # ç»Ÿè®¡HTMLä¸­çš„å›¾ç‰‡æ•°é‡ï¼ˆç”¨äºè°ƒè¯•ï¼‰
            import re
            img_count = len(re.findall(r'<img[^>]+>', html_content, re.IGNORECASE))
            data_uri_count = len(re.findall(r'data:image/[^;]+;base64,', html_content, re.IGNORECASE))
            print(f"[PDFé¢„è§ˆ] HTMLä¸­åŒ…å« {img_count} ä¸ªimgæ ‡ç­¾ï¼Œå…¶ä¸­ {data_uri_count} ä¸ªä½¿ç”¨data URI")
            
            # æ£€æŸ¥HTMLä¸­çš„ä¸­æ–‡å­—ç¬¦æ•°é‡
            html_chinese_count = len([c for c in html_content if '\u4e00' <= c <= '\u9fff'])
            print(f"[PDFé¢„è§ˆ] HTMLä¸­çš„ä¸­æ–‡å­—ç¬¦æ•°: {html_chinese_count} å­—ç¬¦")
            if html_chinese_count > 0:
                print(f"[PDFé¢„è§ˆ] âœ… HTMLä¸­åŒ…å«ä¸­æ–‡å­—ç¬¦ï¼Œå¦‚æœPDFä¸­çœ‹ä¸åˆ°ä¸­æ–‡ï¼Œå¯èƒ½æ˜¯æœåŠ¡å™¨ç¼ºå°‘ä¸­æ–‡å­—ä½“")
                # æ˜¾ç¤ºå‰å‡ ä¸ªä¸­æ–‡å­—ç¬¦ä½œä¸ºç¤ºä¾‹
                chinese_chars_in_html = [c for c in html_content if '\u4e00' <= c <= '\u9fff'][:10]
                if chinese_chars_in_html:
                    print(f"[PDFé¢„è§ˆ] HTMLä¸­çš„ä¸­æ–‡å­—ç¬¦ç¤ºä¾‹: {''.join(chinese_chars_in_html)}")
            else:
                print(f"[PDFé¢„è§ˆ] âš ï¸ è­¦å‘Šï¼šHTMLä¸­æ²¡æœ‰ä¸­æ–‡å­—ç¬¦ï¼å¯èƒ½æ˜¯æ–‡å­—æå–æˆ–è½¬ä¹‰æ—¶ä¸¢å¤±äº†")
            
            # ä½¿ç”¨weasyprintè½¬æ¢
            # è®¾ç½®base_urlä¸ºHTMLæ–‡ä»¶æ‰€åœ¨ç›®å½•ï¼Œå¸®åŠ©weasyprintè§£æç›¸å¯¹è·¯å¾„å’Œdata URI
            # æ³¨æ„ï¼šä¸ä½¿ç”¨FontConfiguration()ï¼Œå› ä¸ºå®ƒå¯èƒ½å¯¼è‡´transformé”™è¯¯
            html_doc = HTML(
                string=html_content,
                base_url=str(html_path.parent)  # è®¾ç½®base_urlï¼Œå¸®åŠ©è§£æå›¾ç‰‡
            )
            
            # æ£€æŸ¥ç³»ç»Ÿå¯ç”¨å­—ä½“ï¼ˆç”¨äºè¯Šæ–­ï¼‰
            try:
                import subprocess
                result = subprocess.run(['fc-list', ':lang=zh'], capture_output=True, text=True, timeout=5)
                if result.returncode == 0:
                    fonts = result.stdout.strip().split('\n')
                    chinese_fonts = [f for f in fonts if any(keyword in f.lower() for keyword in ['song', 'simsun', 'å®‹', 'hei', 'simhei', 'é»‘', 'wqy', 'wenquanyi'])]
                    print(f"[PDFé¢„è§ˆ] ç³»ç»Ÿæ£€æµ‹åˆ° {len(chinese_fonts)} ä¸ªä¸­æ–‡å­—ä½“:")
                    for font in chinese_fonts[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
                        print(f"[PDFé¢„è§ˆ]   - {font[:100]}")
                    if len(chinese_fonts) == 0:
                        print(f"[PDFé¢„è§ˆ] âš ï¸ è­¦å‘Šï¼šç³»ç»Ÿæœªæ£€æµ‹åˆ°ä¸­æ–‡å­—ä½“ï¼PDFå¯èƒ½æ— æ³•æ­£ç¡®æ˜¾ç¤ºä¸­æ–‡")
                else:
                    print(f"[PDFé¢„è§ˆ] âš ï¸ æ— æ³•æ£€æµ‹ç³»ç»Ÿå­—ä½“ï¼ˆfc-listå‘½ä»¤å¤±è´¥ï¼‰")
            except Exception as e:
                print(f"[PDFé¢„è§ˆ] âš ï¸ å­—ä½“æ£€æµ‹å¤±è´¥: {e}")
            
            print(f"[PDFé¢„è§ˆ] å¼€å§‹ç”ŸæˆPDFæ–‡ä»¶...")
            # ç”ŸæˆPDFï¼ˆä¸ä½¿ç”¨font_configï¼Œé¿å…transformé”™è¯¯ï¼‰
            # æ ¹æ®WeasyPrintæ–‡æ¡£ï¼Œfont_configæ˜¯å¯é€‰çš„ï¼Œä¸ä½¿ç”¨ä¹Ÿèƒ½æ­£å¸¸å·¥ä½œ
            html_doc.write_pdf(
                pdf_path,
                optimize_images=False,  # ç¦ç”¨å›¾ç‰‡ä¼˜åŒ–ï¼Œé¿å…æŸäº›å†…éƒ¨é”™è¯¯
            )
            
            pdf_size = pdf_path.stat().st_size
            print(f"[PDFé¢„è§ˆ] PDFç”ŸæˆæˆåŠŸï¼Œå¤§å°: {pdf_size / 1024:.2f} KB")
            
            # æ£€æŸ¥PDFä¸­çš„å­—ä½“ï¼ˆä½¿ç”¨pypdfï¼‰
            try:
                from pypdf import PdfReader
                from pypdf.generic import IndirectObject
                reader = PdfReader(str(pdf_path))
                if len(reader.pages) > 0:
                    page = reader.pages[0]
                    # è·å–Resourceså¯¹è±¡ï¼Œå¯èƒ½æ˜¯IndirectObjectï¼Œéœ€è¦å…ˆè·å–å®é™…å¯¹è±¡
                    resources = page.get('/Resources', {})
                    if isinstance(resources, IndirectObject):
                        resources = resources.get_object()
                    
                    if resources and '/Font' in resources:
                        fonts_used = resources['/Font']
                        # å¦‚æœfonts_usedæ˜¯IndirectObjectï¼Œä¹Ÿéœ€è¦è·å–å®é™…å¯¹è±¡
                        if isinstance(fonts_used, IndirectObject):
                            fonts_used = fonts_used.get_object()
                        
                        if fonts_used:
                            print(f"[PDFé¢„è§ˆ] PDFä¸­ä½¿ç”¨çš„å­—ä½“:")
                            font_embedded_count = 0
                            font_referenced_count = 0
                            for font_name, font_obj in fonts_used.items():
                                try:
                                    # ç¡®ä¿font_objæ˜¯å®é™…å¯¹è±¡
                                    if isinstance(font_obj, IndirectObject):
                                        font_info = font_obj.get_object()
                                    else:
                                        font_info = font_obj
                                    
                                    base_font = font_info.get('/BaseFont', 'Unknown')
                                    
                                    # æ£€æŸ¥å­—ä½“æ˜¯å¦åµŒå…¥ï¼ˆå¦‚æœæœ‰/FontDescriptorå’Œ/FontFileï¼Œè¯´æ˜å­—ä½“å·²åµŒå…¥ï¼‰
                                    is_embedded = False
                                    if '/FontDescriptor' in font_info:
                                        font_desc = font_info['/FontDescriptor']
                                        # å¦‚æœfont_descæ˜¯IndirectObjectï¼Œéœ€è¦è·å–å®é™…å¯¹è±¡
                                        if isinstance(font_desc, IndirectObject):
                                            font_desc = font_desc.get_object()
                                        if isinstance(font_desc, dict):
                                            # æ£€æŸ¥æ˜¯å¦æœ‰å­—ä½“æ–‡ä»¶ï¼ˆåµŒå…¥çš„å­—ä½“ï¼‰
                                            if any(key in font_desc for key in ['/FontFile', '/FontFile2', '/FontFile3']):
                                                is_embedded = True
                                                font_embedded_count += 1
                                            else:
                                                font_referenced_count += 1
                                    
                                    font_status = "å·²åµŒå…¥" if is_embedded else "ä»…å¼•ç”¨ï¼ˆæœªåµŒå…¥ï¼‰"
                                    print(f"[PDFé¢„è§ˆ]   - {font_name}: {base_font} ({font_status})")
                                    
                                    # æ£€æŸ¥æ˜¯å¦æ˜¯ä¸­æ–‡å­—ä½“
                                    if any(keyword in str(base_font).lower() for keyword in ['song', 'simsun', 'å®‹', 'hei', 'simhei', 'é»‘', 'wqy', 'wenquanyi']):
                                        if not is_embedded:
                                            print(f"[PDFé¢„è§ˆ]     âš ï¸ è­¦å‘Šï¼šä¸­æ–‡å­—ä½“æœªåµŒå…¥ï¼Œåœ¨ä¸åŒç³»ç»Ÿä¸Šå¯èƒ½æ˜¾ç¤ºä¸åŒå­—ä½“")
                                except Exception as e:
                                    print(f"[PDFé¢„è§ˆ]   - {font_name}: (æ— æ³•è¯»å–å­—ä½“ä¿¡æ¯: {e})")
                            
                            print(f"[PDFé¢„è§ˆ] å­—ä½“ç»Ÿè®¡: {font_embedded_count} ä¸ªå·²åµŒå…¥, {font_referenced_count} ä¸ªä»…å¼•ç”¨")
                            if font_referenced_count > 0:
                                print(f"[PDFé¢„è§ˆ] âš ï¸ æ³¨æ„ï¼šæœ‰ {font_referenced_count} ä¸ªå­—ä½“æœªåµŒå…¥ï¼Œåœ¨ä¸åŒç³»ç»Ÿï¼ˆå¦‚Macï¼‰ä¸Šå¯èƒ½æ˜¾ç¤ºä¸åŒå­—ä½“")
                        else:
                            print(f"[PDFé¢„è§ˆ] âš ï¸ PDFä¸­æœªæ‰¾åˆ°å­—ä½“ä¿¡æ¯ï¼ˆfonts_usedä¸ºç©ºï¼‰")
                    else:
                        print(f"[PDFé¢„è§ˆ] âš ï¸ PDFä¸­æœªæ‰¾åˆ°å­—ä½“ä¿¡æ¯")
            except Exception as e:
                print(f"[PDFé¢„è§ˆ] âš ï¸ æ— æ³•è¯»å–PDFå­—ä½“ä¿¡æ¯: {e}")
                import traceback
                print(f"[PDFé¢„è§ˆ] é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
            
            # æ£€æŸ¥PDFä¸­æ˜¯å¦åŒ…å«ä¸­æ–‡å­—ç¬¦ï¼ˆé€šè¿‡è¯»å–PDFæ–‡æœ¬å†…å®¹ï¼‰
            if html_chinese_count > 0:
                try:
                    # å°è¯•è¯»å–PDFçš„æ–‡æœ¬å†…å®¹ï¼ˆä½¿ç”¨pypdfï¼‰
                    from pypdf import PdfReader
                    reader = PdfReader(str(pdf_path))
                    pdf_text = ""
                    for page in reader.pages[:3]:  # åªæ£€æŸ¥å‰3é¡µ
                        pdf_text += page.extract_text() or ""
                    pdf_chinese_count = len([c for c in pdf_text if '\u4e00' <= c <= '\u9fff'])
                    print(f"[PDFé¢„è§ˆ] PDFä¸­çš„ä¸­æ–‡å­—ç¬¦æ•°: {pdf_chinese_count} å­—ç¬¦")
                    if pdf_chinese_count == 0:
                        print(f"[PDFé¢„è§ˆ] âŒ é”™è¯¯ï¼šHTMLä¸­æœ‰ {html_chinese_count} ä¸ªä¸­æ–‡å­—ç¬¦ï¼Œä½†PDFä¸­åªæœ‰ {pdf_chinese_count} ä¸ªï¼")
                        print(f"[PDFé¢„è§ˆ] ğŸ’¡ è§£å†³æ–¹æ¡ˆï¼šæœåŠ¡å™¨éœ€è¦å®‰è£…ä¸­æ–‡å­—ä½“åŒ…")
                        print(f"[PDFé¢„è§ˆ] ğŸ’¡ å®‰è£…å‘½ä»¤ï¼ˆCentOS/RHELï¼‰: sudo yum install -y wqy-microhei-fonts wqy-zenhei-fonts")
                        print(f"[PDFé¢„è§ˆ] ğŸ’¡ å®‰è£…å‘½ä»¤ï¼ˆUbuntu/Debianï¼‰: sudo apt-get install -y fonts-wqy-microhei fonts-wqy-zenhei")
                    else:
                        print(f"[PDFé¢„è§ˆ] âœ… PDFä¸­åŒ…å«ä¸­æ–‡å­—ç¬¦ï¼Œå­—ä½“æ”¯æŒæ­£å¸¸")
                except Exception as e:
                    print(f"[PDFé¢„è§ˆ] æ— æ³•æ£€æŸ¥PDFä¸­çš„ä¸­æ–‡å­—ç¬¦: {e}")
            
            # éªŒè¯PDFæ–‡ä»¶æ˜¯å¦æœ‰æ•ˆï¼ˆè‡³å°‘åº”è¯¥æœ‰ä¸€å®šå¤§å°ï¼‰
            if pdf_size < 1024:  # å°äº1KBå¯èƒ½æœ‰é—®é¢˜
                print(f"[PDFé¢„è§ˆ] è­¦å‘Š: PDFæ–‡ä»¶å¤§å°å¼‚å¸¸å° ({pdf_size} å­—èŠ‚)ï¼Œå¯èƒ½ç”Ÿæˆå¤±è´¥")
                return False
            
            return True
            
        except Exception as e:
            print(f"[PDFé¢„è§ˆ] ç”ŸæˆPDFå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def _extract_page_settings(self, document: Document) -> Dict:
        """ä»Wordæ–‡æ¡£ä¸­æå–é¡µé¢è®¾ç½®"""
        settings = {
            "paper_size": "A4",  # é»˜è®¤A4
            "margins": {
                "top": 2.54,      # é»˜è®¤1è‹±å¯¸ = 2.54cm
                "bottom": 2.54,
                "left": 3.18,     # é»˜è®¤1.25è‹±å¯¸ = 3.18cm
                "right": 3.18,
            },
            "orientation": "portrait"  # é»˜è®¤çºµå‘
        }
        
        try:
            # è·å–ç¬¬ä¸€ä¸ªsectionçš„é¡µé¢è®¾ç½®ï¼ˆé€šå¸¸æ‰€æœ‰sectionä½¿ç”¨ç›¸åŒè®¾ç½®ï¼‰
            if document.sections:
                section = document.sections[0]
                page_width = section.page_width
                page_height = section.page_height
                
                # åˆ¤æ–­é¡µé¢æ–¹å‘
                if page_width > page_height:
                    settings["orientation"] = "landscape"
                else:
                    settings["orientation"] = "portrait"
                
                # åˆ¤æ–­çº¸å¼ å¤§å°ï¼ˆè½¬æ¢ä¸ºå˜ç±³ï¼‰
                width_cm = page_width / 360000  # Wordå†…éƒ¨å•ä½è½¬æ¢ä¸ºå˜ç±³
                height_cm = page_height / 360000
                
                # å¸¸è§çº¸å¼ å¤§å°åˆ¤æ–­
                if abs(width_cm - 21.0) < 0.5 and abs(height_cm - 29.7) < 0.5:
                    settings["paper_size"] = "A4"
                elif abs(width_cm - 21.59) < 0.5 and abs(height_cm - 27.94) < 0.5:
                    settings["paper_size"] = "Letter"
                elif abs(width_cm - 21.0) < 0.5 and abs(height_cm - 29.7) < 0.5:
                    settings["paper_size"] = "A4"
                else:
                    # è‡ªå®šä¹‰å¤§å°ï¼Œä½¿ç”¨å®é™…å°ºå¯¸
                    settings["paper_size"] = f"{width_cm}cm {height_cm}cm"
                
                # æå–é¡µè¾¹è·ï¼ˆè½¬æ¢ä¸ºå˜ç±³ï¼‰
                # Wordå†…éƒ¨å•ä½ï¼š1è‹±å¯¸ = 914400 EMUï¼Œ1å˜ç±³ = 360000 EMU
                # æ‰€ä»¥é™¤ä»¥360000å¾—åˆ°å˜ç±³
                top_margin_cm = section.top_margin / 360000
                bottom_margin_cm = section.bottom_margin / 360000
                left_margin_cm = section.left_margin / 360000
                right_margin_cm = section.right_margin / 360000
                
                settings["margins"]["top"] = round(top_margin_cm, 2)
                settings["margins"]["bottom"] = round(bottom_margin_cm, 2)
                settings["margins"]["left"] = round(left_margin_cm, 2)
                settings["margins"]["right"] = round(right_margin_cm, 2)
                
                print(f"[PDFé¢„è§ˆ] æå–é¡µé¢è®¾ç½®: {settings['paper_size']}, æ–¹å‘: {settings['orientation']}")
                print(f"[PDFé¢„è§ˆ] æå–é¡µè¾¹è·: ä¸Š={settings['margins']['top']}cm, ä¸‹={settings['margins']['bottom']}cm, å·¦={settings['margins']['left']}cm, å³={settings['margins']['right']}cm")
                print(f"[PDFé¢„è§ˆ] WordåŸå§‹é¡µè¾¹è·(EMU): ä¸Š={section.top_margin}, ä¸‹={section.bottom_margin}, å·¦={section.left_margin}, å³={section.right_margin}")
        except Exception as e:
            print(f"[PDFé¢„è§ˆ] æå–é¡µé¢è®¾ç½®å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼: {e}")
        
        return settings
    
    def _generate_pdf_css(self, page_settings: Dict) -> str:
        """æ ¹æ®é¡µé¢è®¾ç½®ç”ŸæˆPDF CSS"""
        paper_size = page_settings.get("paper_size", "A4")
        orientation = page_settings.get("orientation", "portrait")
        margins = page_settings.get("margins", {})
        
        # æ„å»º@pageè§„åˆ™
        # ä½¿ç”¨æå–åˆ°çš„å®é™…é¡µè¾¹è·ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨Wordæ–‡æ¡£çš„é»˜è®¤å€¼ï¼ˆ2.54cm = 1è‹±å¯¸ï¼‰
        # æ³¨æ„ï¼šä¸è¦ä½¿ç”¨ç¡¬ç¼–ç çš„é»˜è®¤å€¼ï¼Œåº”è¯¥ä»Wordæ–‡æ¡£ä¸­æå–
        margin_top = f"{margins.get('top', 2.54):.2f}cm" if margins.get('top') else "2.54cm"
        margin_bottom = f"{margins.get('bottom', 2.54):.2f}cm" if margins.get('bottom') else "2.54cm"
        margin_left = f"{margins.get('left', 3.18):.2f}cm" if margins.get('left') else "3.18cm"
        margin_right = f"{margins.get('right', 2.54):.2f}cm" if margins.get('right') else "2.54cm"
        
        print(f"[PDFé¢„è§ˆ] åº”ç”¨é¡µè¾¹è·: ä¸Š={margin_top}, ä¸‹={margin_bottom}, å·¦={margin_left}, å³={margin_right}")
        
        # å¦‚æœçº¸å¼ å¤§å°æ˜¯è‡ªå®šä¹‰çš„ï¼Œç›´æ¥ä½¿ç”¨
        if "cm" in str(paper_size) and " " in str(paper_size):
            size_value = paper_size
        else:
            # æ ‡å‡†çº¸å¼ å¤§å°
            size_value = paper_size
            if orientation == "landscape":
                size_value = f"{paper_size} landscape"
        
        css = f"""
            @page {{
                size: {size_value};
                margin-top: {margin_top};
                margin-bottom: {margin_bottom};
                margin-left: {margin_left};
                margin-right: {margin_right};
                /* ä½¿ç”¨èƒŒæ™¯è‰²å’Œè¾¹æ¡†è®©åˆ†é¡µæ›´æ˜æ˜¾ */
                background: #ffffff;
            }}
            @page:first {{
                /* ç¬¬ä¸€é¡µç‰¹æ®Šå¤„ç† */
            }}
            /* åœ¨æ¯é¡µåº•éƒ¨æ·»åŠ åˆ†é¡µçº¿ - ä½¿ç”¨æ›´ç®€å•çš„æ–¹æ³• */
            @page {{
                @bottom-center {{
                    content: "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” content: "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” content: "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” HTMLç”Ÿæˆæ—¶ï¼Œåœ¨æ¯é¡µåº•éƒ¨æ·»åŠ å¯è§çš„åˆ†é¡µçº¿ã€‚è®©æˆ‘æ”¹ç”¨æ›´ç®€å•çš„æ–¹æ³•ï¼šåœ¨HTMLå†…å®¹ä¸­ç›´æ¥æ’å…¥HRæ ‡ç­¾æˆ–å¸¦è¾¹æ¡†çš„divã€‚
</think>
æ”¹ç”¨æ›´ç›´æ¥çš„æ–¹æ³•ï¼šåœ¨ HTML å†…å®¹ä¸­ç›´æ¥æ’å…¥å¯è§çš„åˆ†é¡µçº¿å…ƒç´ ï¼š
<ï½œtoolâ–callsâ–beginï½œ><ï½œtoolâ–callâ–beginï½œ>
read_file
            body {{
                font-family: "SimSun", "å®‹ä½“", "STSong", "STSongti-SC-Regular", "WenQuanYi Micro Hei", "WenQuanYi Zen Hei", serif;
                padding: 0;
                margin: 0;
                background: #ffffff;
                /* ç¡®ä¿ä¸­æ–‡å­—ç¬¦æ­£ç¡®æ˜¾ç¤º */
                -webkit-font-smoothing: antialiased;
            }}
            /* é»˜è®¤æ®µè½å­—ä½“ï¼šå®‹ä½“ï¼ˆå†…è”æ ·å¼ä¼šè¦†ç›–æ­¤è®¾ç½®ï¼‰ */
            /* æ³¨æ„ï¼šWeasyPrintéœ€è¦ç³»ç»Ÿå®‰è£…å¯¹åº”çš„å­—ä½“æ–‡ä»¶æ‰èƒ½æ­£ç¡®æ¸²æŸ“ */
            p {{
                font-family: "SimSun", "å®‹ä½“", "STSong", "STSongti-SC-Regular", "WenQuanYi Micro Hei", "WenQuanYi Zen Hei", serif;
            }}
            /* é»˜è®¤æ ‡é¢˜å­—ä½“ï¼šé»‘ä½“ï¼ˆå†…è”æ ·å¼ä¼šè¦†ç›–æ­¤è®¾ç½®ï¼‰ */
            h1, h2, h3, h4, h5, h6 {{
                font-family: "SimHei", "é»‘ä½“", "STHeiti", "WenQuanYi Micro Hei", "WenQuanYi Zen Hei", sans-serif;
            }}
            /* æ”¯æŒå¤šç§å­—ä½“ï¼šé»‘ä½“ã€å®‹ä½“ã€æ¥·ä½“ã€Times New Roman */
            /* è¿™äº›å­—ä½“æ ˆä¼šåœ¨å†…è”æ ·å¼ä¸­è¢«ä½¿ç”¨ */
            /* ç¡®ä¿å›¾ç‰‡æ­£ç¡®æ˜¾ç¤º */
            img {{
                max-width: 100%;
                height: auto;
                display: block;
                margin: 10px auto;
                page-break-inside: avoid;
            }}
            /* åˆ†é¡µæ§åˆ¶ - åªåœ¨æ‰“å°æˆ–PDFç”Ÿæˆæ—¶ç”Ÿæ•ˆï¼Œæµè§ˆå™¨é¢„è§ˆä¸­ä¸æ˜¾ç¤ºç©ºç™½é¡µ */
            .page-break {{
                /* åœ¨æµè§ˆå™¨ä¸­éšè—ï¼Œä¸å ç”¨ç©ºé—´ */
                display: none;
                /* åªåœ¨æ‰“å°æˆ–PDFç”Ÿæˆæ—¶ç”Ÿæ•ˆ */
                page-break-before: always;
            }}
            /* æ‰“å°æ—¶æ˜¾ç¤ºåˆ†é¡µç¬¦ */
            @media print {{
                .page-break {{
                    display: block;
                    page-break-before: always;
                    height: 0;
                    margin: 0;
                    padding: 0;
                }}
            }}
            /* åœ¨æ¯ä¸ªæ®µè½åæ·»åŠ è½»å¾®çš„åˆ†éš”ï¼ˆå¸®åŠ©è¯†åˆ«åˆ†é¡µï¼‰ */
            p {{
                orphans: 3;
                widows: 3;
                margin-bottom: 0.5em;
            }}
            /* åœ¨æ ‡é¢˜åæ·»åŠ æ›´å¤šé—´è·ï¼Œå¸®åŠ©è¯†åˆ«åˆ†é¡µ */
            h1, h2, h3, h4, h5, h6 {{
                page-break-after: avoid;
                margin-top: 1em;
                margin-bottom: 0.5em;
            }}
            /* å›¾ç‰‡å’Œè¡¨æ ¼åˆ†é¡µæ§åˆ¶ */
            img, table {{
                page-break-inside: avoid;
            }}
            /* æ–‡æ¡£å®¹å™¨æ ·å¼ - æ·»åŠ è¾¹æ¡†è®©åˆ†é¡µæ›´æ˜æ˜¾ */
            .document-container {{
                border: 1px solid #e0e0e0;
                padding: 20px;
                margin: 0;
                background: #ffffff;
                /* æ¯é¡µéƒ½æœ‰ç‹¬ç«‹çš„å®¹å™¨è¾¹æ¡† */
                box-shadow: 0 0 0 1px #d0d0d0;
            }}
            /* åœ¨æ¯é¡µåº•éƒ¨æ·»åŠ åˆ†é¡µæ ‡è®° */
            .page-end {{
                border-bottom: 2px solid #cccccc;
                margin-bottom: 20px;
                padding-bottom: 10px;
            }}
            .watermark {{
                position: fixed;
                top: 50%;
                left: 50%;
                /* å®Œå…¨ç§»é™¤transformå’Œå¤æ‚çš„CSSå±æ€§ï¼Œé¿å…WeasyPrintå†…éƒ¨é”™è¯¯ */
                margin-top: -36px;  /* å­—ä½“å¤§å°çš„ä¸€åŠ */
                margin-left: -200px;  /* å¤§çº¦æ–‡æœ¬å®½åº¦çš„ä¸€åŠ */
                font-size: 72px;
                color: rgba(209, 15, 15, 0.15);
                font-weight: bold;
                pointer-events: none;
                z-index: 1;
                /* ç§»é™¤writing-modeï¼Œé¿å…å¯èƒ½çš„å…¼å®¹æ€§é—®é¢˜ */
            }}
            """
        return css
    
    def _verify_format_changes(self, original_path: Path, final_path: Path, rules: Dict) -> Dict:
        """éªŒè¯æ ¼å¼ä¿®æ”¹æ˜¯å¦æ­£ç¡®ï¼šå¯¹æ¯”åŸå§‹æ–‡æ¡£å’Œä¿®æ”¹åçš„æ–‡æ¡£"""
        from docx import Document
        # docx_format_utils å·²ç»åœ¨æ–‡ä»¶é¡¶éƒ¨å¯¼å…¥ï¼Œç›´æ¥ä½¿ç”¨å³å¯
        
        verification = {
            "summary": {},
            "errors": [],
            "warnings": []
        }
        
        try:
            original_doc = Document(original_path)
            final_doc = Document(final_path)
            
            # ç¡®ä¿ä¸¤ä¸ªæ–‡æ¡£çš„æ®µè½æ•°é‡ä¸€è‡´
            if len(original_doc.paragraphs) != len(final_doc.paragraphs):
                verification["warnings"].append(
                    f"æ®µè½æ•°é‡ä¸ä¸€è‡´ï¼šåŸå§‹æ–‡æ¡£ {len(original_doc.paragraphs)} æ®µï¼Œä¿®æ”¹å {len(final_doc.paragraphs)} æ®µ"
                )
            
            # å¯¹æ¯”æ¯ä¸ªæ®µè½çš„æ ¼å¼
            total_paragraphs = min(len(original_doc.paragraphs), len(final_doc.paragraphs))
            format_changes_count = 0
            font_correct_count = 0
            line_spacing_correct_count = 0
            format_errors = []
            
            for idx in range(total_paragraphs):
                orig_para = original_doc.paragraphs[idx]
                final_para = final_doc.paragraphs[idx]
                
                orig_format = docx_format_utils.extract_paragraph_format(orig_para)
                final_format = docx_format_utils.extract_paragraph_format(final_para)
                
                # æ£€æŸ¥æ ¼å¼æ˜¯å¦æœ‰å˜åŒ–
                has_changes = False
                for key in orig_format:
                    if orig_format.get(key) != final_format.get(key):
                        has_changes = True
                        break
                
                if has_changes:
                    format_changes_count += 1
                    
                    # éªŒè¯å­—ä½“æ˜¯å¦æ­£ç¡®ï¼ˆæ­£æ–‡åº”è¯¥æ˜¯å®‹ä½“ï¼Œæ ‡é¢˜åº”è¯¥æ˜¯é»‘ä½“ï¼‰
                    text = final_para.text.strip()
                    if text:
                        # åˆ¤æ–­æ®µè½ç±»å‹
                        is_title = any(keyword in final_para.style.name.lower() for keyword in ["heading", "æ ‡é¢˜", "title"])
                        
                        if is_title:
                            # æ ‡é¢˜åº”è¯¥æ˜¯é»‘ä½“
                            if final_format.get("font_name") and "é»‘" in final_format.get("font_name", ""):
                                font_correct_count += 1
                            elif final_format.get("font_name"):
                                format_errors.append(
                                    f"æ®µè½ {idx}ï¼ˆæ ‡é¢˜ï¼‰å­—ä½“åº”ä¸ºé»‘ä½“ï¼Œå®é™…ä¸ºï¼š{final_format.get('font_name')}"
                                )
                        else:
                            # æ­£æ–‡åº”è¯¥æ˜¯å®‹ä½“
                            if final_format.get("font_name") and "å®‹" in final_format.get("font_name", ""):
                                font_correct_count += 1
                        
                        # éªŒè¯è¡Œè·ï¼ˆæ­£æ–‡åº”è¯¥æ˜¯20ç£…ï¼‰
                        if not is_title and final_format.get("line_spacing"):
                            line_spacing = final_format.get("line_spacing")
                            if isinstance(line_spacing, (int, float)) and abs(line_spacing - 20) < 1:
                                line_spacing_correct_count += 1
                            elif isinstance(line_spacing, (int, float)) and line_spacing != 20:
                                format_errors.append(
                                    f"æ®µè½ {idx}ï¼ˆæ­£æ–‡ï¼‰è¡Œè·åº”ä¸º20ç£…ï¼Œå®é™…ä¸ºï¼š{line_spacing}"
                                )
            
            verification["summary"] = {
                "æ€»æ®µè½æ•°": total_paragraphs,
                "æ ¼å¼ä¿®æ”¹æ®µè½æ•°": format_changes_count,
                "å­—ä½“æ­£ç¡®æ®µè½æ•°": font_correct_count,
                "è¡Œè·æ­£ç¡®æ®µè½æ•°": line_spacing_correct_count
            }
            
            # å¦‚æœæ ¼å¼é”™è¯¯å¤ªå¤šï¼Œè®°å½•ä¸ºé”™è¯¯
            if format_errors:
                verification["errors"].extend(format_errors[:20])  # æœ€å¤šè®°å½•20ä¸ªé”™è¯¯
            
            # å¦‚æœæ ¼å¼ä¿®æ”¹çš„æ®µè½å¤ªå°‘ï¼Œå¯èƒ½æ˜¯æ ¼å¼æ²¡æœ‰æ­£ç¡®åº”ç”¨
            if format_changes_count == 0 and total_paragraphs > 0:
                verification["warnings"].append("æœªæ£€æµ‹åˆ°ä»»ä½•æ ¼å¼ä¿®æ”¹ï¼Œå¯èƒ½æ ¼å¼è§„åˆ™æœªæ­£ç¡®åº”ç”¨")
            
        except Exception as e:
            verification["errors"].append(f"æ ¼å¼éªŒè¯è¿‡ç¨‹å‡ºé”™: {e}")
            import traceback
            print(f"[æ ¼å¼éªŒè¯] é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
        
        return verification
    
    def _try_libreoffice_conversion(self, docx_path: Path, html_path: Path, stats: Dict) -> bool:
        """å°è¯•ä½¿ç”¨LibreOfficeå°†Wordæ–‡æ¡£è½¬æ¢ä¸ºHTMLï¼ˆä¿ç•™æ ¼å¼æœ€å¥½ï¼‰"""
        import subprocess
        import shutil
        
        print("[HTMLé¢„è§ˆ] æ£€æŸ¥LibreOfficeæ˜¯å¦å¯ç”¨...")
        # æ£€æŸ¥LibreOfficeæ˜¯å¦å¯ç”¨
        libreoffice_cmd = None
        for cmd in ['libreoffice', 'soffice']:
            if shutil.which(cmd):
                libreoffice_cmd = cmd
                print(f"[HTMLé¢„è§ˆ] æ‰¾åˆ°LibreOfficeå‘½ä»¤: {cmd}")
                break
        
        if not libreoffice_cmd:
            print("[HTMLé¢„è§ˆ] LibreOfficeæœªå®‰è£…ï¼Œä½¿ç”¨è‡ªå®šä¹‰HTMLç”Ÿæˆ")
            return False
        
        try:
            # åˆ›å»ºä¸´æ—¶ç›®å½•ç”¨äºè¾“å‡º
            temp_dir = html_path.parent / "temp_html"
            temp_dir.mkdir(exist_ok=True)
            
            # ä½¿ç”¨LibreOfficeè½¬æ¢
            # --headless: æ— ç•Œé¢æ¨¡å¼
            # --convert-to html: è½¬æ¢ä¸ºHTML
            # --outdir: è¾“å‡ºç›®å½•
            cmd = [
                libreoffice_cmd,
                '--headless',
                '--convert-to', 'html',
                '--outdir', str(temp_dir),
                str(docx_path)
            ]
            
            print(f"[HTMLé¢„è§ˆ] æ‰§è¡ŒLibreOfficeè½¬æ¢å‘½ä»¤: {' '.join(cmd)}")
            
            # å‡†å¤‡ç¯å¢ƒå˜é‡ï¼Œç¡®ä¿åŒ…å«å¿…è¦çš„ PATH
            import os
            env = os.environ.copy()
            # ç¡®ä¿ PATH åŒ…å« /usr/bin å’Œ /binï¼ˆuname ç­‰å‘½ä»¤éœ€è¦ï¼‰
            current_path = env.get('PATH', '')
            if '/usr/bin' not in current_path:
                env['PATH'] = f"/usr/bin:/bin:{current_path}"
            if '/bin' not in env['PATH']:
                env['PATH'] = f"/bin:{env['PATH']}"
            
            print(f"[HTMLé¢„è§ˆ] å¼€å§‹æ‰§è¡ŒLibreOfficeè½¬æ¢ï¼Œè¶…æ—¶æ—¶é—´: 60ç§’...")
            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=60,  # 60ç§’è¶…æ—¶
                env=env  # ä½¿ç”¨åŒ…å«å®Œæ•´ PATH çš„ç¯å¢ƒå˜é‡
            )
            print(f"[HTMLé¢„è§ˆ] LibreOfficeè½¬æ¢å®Œæˆï¼Œè¿”å›ç : {result.returncode}")
            
            if result.returncode != 0:
                print(f"[HTMLé¢„è§ˆ] LibreOfficeè½¬æ¢å¤±è´¥: {result.stderr}")
                return False
            
            # æŸ¥æ‰¾ç”Ÿæˆçš„HTMLæ–‡ä»¶
            html_file_name = docx_path.stem + '.html'
            generated_html = temp_dir / html_file_name
            
            if not generated_html.exists():
                print(f"[HTMLé¢„è§ˆ] LibreOfficeç”Ÿæˆçš„HTMLæ–‡ä»¶ä¸å­˜åœ¨: {generated_html}")
                return False
            
            # è¯»å–ç”Ÿæˆçš„HTMLå†…å®¹
            html_content = generated_html.read_text(encoding='utf-8', errors='ignore')
            
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            try:
                generated_html.unlink()
                temp_dir.rmdir()
            except:
                pass
            
            # ä¸å†åœ¨é¢„è§ˆæ–‡æ¡£ä¸­æ·»åŠ æ£€æµ‹ç»“æœï¼Œä¿æŒæ–‡æ¡£å¹²å‡€
            # æ£€æµ‹ç»“æœåªåœ¨é¦–é¡µï¼ˆæŠ¥å‘Šï¼‰ä¸­æ˜¾ç¤º
            
            # æ·»åŠ æ°´å°å’Œè­¦å‘Šæ ·å¼
            watermark_style = """
            <style>
                .preview-watermark {
                    position: fixed;
                    top: 50%;
                    left: 50%;
                    /* ç§»é™¤transformï¼Œé¿å…WeasyPrintå†…éƒ¨é”™è¯¯ */
                    margin-top: -36px;
                    margin-left: -200px;
                    font-size: 72px;
                    color: rgba(209, 15, 15, 0.15);
                    font-weight: bold;
                    pointer-events: none;
                    z-index: 9999;
                    white-space: nowrap;
                }
                .preview-warning {
                    background: #fff3cd;
                    border: 1px solid #ffc107;
                    padding: 15px;
                    margin: 20px 0;
                    border-radius: 5px;
                    text-align: center;
                    font-weight: bold;
                    color: #856404;
                }
            </style>
            """
            
            # åœ¨headæ ‡ç­¾ä¸­æ’å…¥æ ·å¼
            if '</head>' in html_content:
                html_content = html_content.replace('</head>', watermark_style + '</head>')
            
            # åœ¨bodyæ ‡ç­¾åæ’å…¥æ°´å°ï¼ˆä¸æ’å…¥æ£€æµ‹ç»“æœï¼‰
            if '<body' in html_content:
                # æ‰¾åˆ°bodyæ ‡ç­¾ç»“æŸä½ç½®
                body_end = html_content.find('>', html_content.find('<body'))
                if body_end != -1:
                    insert_pos = body_end + 1
                    insert_content = '<div class="preview-watermark">é¢„è§ˆç‰ˆ ä»…ä¾›æŸ¥çœ‹</div>'
                    html_content = html_content[:insert_pos] + insert_content + html_content[insert_pos:]
            
            # åœ¨æ–‡æ¡£æœ«å°¾æ·»åŠ è­¦å‘Š
            if '</body>' in html_content:
                warning_html = '<div class="preview-warning">âš ï¸ è¿™æ˜¯é¢„è§ˆç‰ˆæœ¬ï¼Œä»…ä¾›æŸ¥çœ‹ã€‚å¦‚éœ€ä¸‹è½½æ­£å¼ç‰ˆï¼Œè¯·å®Œæˆæ”¯ä»˜ã€‚</div>'
                html_content = html_content.replace('</body>', warning_html + '</body>')
            
            # ä¿å­˜HTMLæ–‡ä»¶
            html_path.write_text(html_content, encoding='utf-8')
            
            print(f"[HTMLé¢„è§ˆ] LibreOfficeè½¬æ¢æˆåŠŸï¼ŒHTMLå¤§å°: {len(html_content) / 1024:.2f} KB")
            return True
            
        except subprocess.TimeoutExpired:
            print("[HTMLé¢„è§ˆ] LibreOfficeè½¬æ¢è¶…æ—¶")
            return False
        except Exception as e:
            print(f"[HTMLé¢„è§ˆ] LibreOfficeè½¬æ¢å‡ºé”™: {e}")
            return False
    
    def _try_libreoffice_pdf_conversion(self, docx_path: Path, pdf_path: Path) -> bool:
        """å°è¯•ä½¿ç”¨LibreOfficeå°†Wordæ–‡æ¡£ç›´æ¥è½¬æ¢ä¸ºPDFï¼ˆæœ€æ¥è¿‘Wordæ•ˆæœï¼‰"""
        import subprocess
        import shutil
        import os
        import sys
        
        # ç«‹å³è¾“å‡ºæ—¥å¿—
        log_msg = f"[PDFé¢„è§ˆ] ========== å¼€å§‹ LibreOffice PDF è½¬æ¢ =========="
        print(log_msg, file=sys.stderr, flush=True)
        try:
            with open("/var/log/geshixiugai/error.log", "a") as f:
                f.write(f"{log_msg}\n")
        except Exception:
            pass
        
        # æ£€æŸ¥LibreOfficeæ˜¯å¦å¯ç”¨
        libreoffice_cmd = None
        
        # æ–¹æ³•1: ç›´æ¥æ£€æŸ¥å¸¸è§è·¯å¾„ï¼ˆæœ€å¿«æœ€å¯é ï¼‰
        direct_paths = [
            '/bin/libreoffice',      # é˜¿é‡Œäº‘ Linux
            '/bin/soffice',          # é˜¿é‡Œäº‘ Linux
            '/usr/bin/libreoffice',  # æ ‡å‡†è·¯å¾„
            '/usr/bin/soffice',      # æ ‡å‡†è·¯å¾„
            '/usr/local/bin/libreoffice',
            '/usr/local/bin/soffice',
        ]
        
        for path in direct_paths:
            if os.path.exists(path) and os.access(path, os.X_OK):
                # éªŒè¯å¯ä»¥æ‰§è¡Œ
                try:
                    result = subprocess.run(
                        [path, '--version'],
                        capture_output=True,
                        text=True,
                        timeout=3
                    )
                    if result.returncode == 0:
                        libreoffice_cmd = path
                        log_msg = f"[PDFé¢„è§ˆ] åœ¨è·¯å¾„æ‰¾åˆ°LibreOffice: {path}"
                        print(log_msg, file=sys.stderr, flush=True)
                        try:
                            with open("/var/log/geshixiugai/error.log", "a") as f:
                                f.write(f"{log_msg}\n")
                        except Exception:
                            pass
                        log_msg = f"[PDFé¢„è§ˆ] LibreOfficeç‰ˆæœ¬: {result.stdout.strip()}"
                        print(log_msg, file=sys.stderr, flush=True)
                        try:
                            with open("/var/log/geshixiugai/error.log", "a") as f:
                                f.write(f"{log_msg}\n")
                        except Exception:
                            pass
                        break
                except Exception as e:
                    print(f"[PDFé¢„è§ˆ] è·¯å¾„ {path} å­˜åœ¨ä½†æ— æ³•æ‰§è¡Œ: {e}")
                    continue
        
        # æ–¹æ³•2: ä½¿ç”¨ which æŸ¥æ‰¾ï¼ˆå¦‚æœç›´æ¥è·¯å¾„æ‰¾ä¸åˆ°ï¼‰
        if not libreoffice_cmd:
            for cmd in ['libreoffice', 'soffice']:
                cmd_path = shutil.which(cmd)
                if cmd_path:
                    libreoffice_cmd = cmd_path
                    print(f"[PDFé¢„è§ˆ] é€šè¿‡ which æ‰¾åˆ°LibreOfficeå‘½ä»¤: {cmd_path}")
                    break
        
        # æ–¹æ³•3: å°è¯•ç›´æ¥æ‰§è¡Œå‘½ä»¤ï¼ˆå¯èƒ½åœ¨ PATH ä¸­ä½† which æ£€æµ‹ä¸åˆ°ï¼‰
        if not libreoffice_cmd:
            for cmd in ['libreoffice', 'soffice']:
                try:
                    # å°è¯•æ‰§è¡Œ --version å‘½ä»¤æ¥éªŒè¯
                    result = subprocess.run(
                        [cmd, '--version'],
                        capture_output=True,
                        text=True,
                        timeout=5,
                        env=os.environ.copy()  # ä½¿ç”¨å½“å‰ç¯å¢ƒå˜é‡
                    )
                    if result.returncode == 0:
                        libreoffice_cmd = cmd
                        print(f"[PDFé¢„è§ˆ] é€šè¿‡æ‰§è¡ŒéªŒè¯æ‰¾åˆ°LibreOfficeå‘½ä»¤: {cmd}")
                        print(f"[PDFé¢„è§ˆ] LibreOfficeç‰ˆæœ¬: {result.stdout.strip()}")
                        break
                except (FileNotFoundError, subprocess.TimeoutExpired) as e:
                    print(f"[PDFé¢„è§ˆ] å‘½ä»¤ {cmd} æ‰§è¡Œå¤±è´¥: {e}")
                    continue
        
        # æ–¹æ³•3: å°è¯•å¸¸è§å®‰è£…è·¯å¾„ï¼ˆåŒ…æ‹¬ macOSï¼‰
        if not libreoffice_cmd:
            import platform
            is_macos = platform.system() == 'Darwin'
            
            common_paths = [
                '/bin/libreoffice',  # é˜¿é‡Œäº‘ Linux å¸¸è§è·¯å¾„
                '/bin/soffice',       # é˜¿é‡Œäº‘ Linux å¸¸è§è·¯å¾„ï¼ˆsofficeï¼‰
                '/usr/bin/libreoffice',
                '/usr/bin/soffice',
                '/usr/local/bin/libreoffice',
                '/usr/local/bin/soffice',
                '/opt/libreoffice*/program/soffice',
            ]
            
            # macOS ç‰¹æœ‰è·¯å¾„
            if is_macos:
                # Homebrew å®‰è£…è·¯å¾„ï¼ˆIntel å’Œ Apple Siliconï¼‰
                common_paths.extend([
                    '/opt/homebrew/bin/libreoffice',  # Apple Silicon (M1/M2)
                    '/usr/local/bin/libreoffice',     # Intel
                    '/Applications/LibreOffice.app/Contents/MacOS/soffice',  # æ‰‹åŠ¨å®‰è£…
                    '/Applications/LibreOffice.app/Contents/MacOS/libreoffice',  # æ‰‹åŠ¨å®‰è£…ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                ])
            
            for path_pattern in common_paths:
                if '*' in path_pattern:
                    # å¤„ç†é€šé…ç¬¦è·¯å¾„
                    import glob
                    matches = glob.glob(path_pattern)
                    if matches:
                        libreoffice_cmd = matches[0]
                        print(f"[PDFé¢„è§ˆ] åœ¨å¸¸è§è·¯å¾„æ‰¾åˆ°LibreOffice: {libreoffice_cmd}")
                        break
                else:
                    if os.path.exists(path_pattern) and os.access(path_pattern, os.X_OK):
                        libreoffice_cmd = path_pattern
                        print(f"[PDFé¢„è§ˆ] åœ¨å¸¸è§è·¯å¾„æ‰¾åˆ°LibreOffice: {libreoffice_cmd}")
                        break
        
        if not libreoffice_cmd:
            log_msg = "[PDFé¢„è§ˆ] LibreOfficeæœªæ‰¾åˆ°ï¼Œæ— æ³•ä½¿ç”¨LibreOfficeè½¬æ¢PDF"
            print(log_msg, file=sys.stderr, flush=True)
            try:
                with open("/var/log/geshixiugai/error.log", "a") as f:
                    f.write(f"{log_msg}\n")
            except Exception:
                pass
            log_msg = "[PDFé¢„è§ˆ] è¯Šæ–­ä¿¡æ¯:"
            print(log_msg, file=sys.stderr, flush=True)
            try:
                with open("/var/log/geshixiugai/error.log", "a") as f:
                    f.write(f"{log_msg}\n")
            except Exception:
                pass
            log_msg = f"[PDFé¢„è§ˆ]   - PATHç¯å¢ƒå˜é‡: {os.environ.get('PATH', 'æœªè®¾ç½®')}"
            print(log_msg, file=sys.stderr, flush=True)
            try:
                with open("/var/log/geshixiugai/error.log", "a") as f:
                    f.write(f"{log_msg}\n")
            except Exception:
                pass
            log_msg = f"[PDFé¢„è§ˆ]   - æ£€æŸ¥çš„è·¯å¾„: {direct_paths}"
            print(log_msg, file=sys.stderr, flush=True)
            try:
                with open("/var/log/geshixiugai/error.log", "a") as f:
                    f.write(f"{log_msg}\n")
            except Exception:
                pass
            # æ£€æŸ¥å“ªäº›è·¯å¾„å­˜åœ¨
            existing_paths = [p for p in direct_paths if os.path.exists(p)]
            if existing_paths:
                print(f"[PDFé¢„è§ˆ]   - å­˜åœ¨çš„è·¯å¾„: {existing_paths}")
                for p in existing_paths:
                    stat_info = os.stat(p)
                    print(f"[PDFé¢„è§ˆ]     {p}: æƒé™={oct(stat_info.st_mode)}, æ‰€æœ‰è€…UID={stat_info.st_uid}")
            else:
                print(f"[PDFé¢„è§ˆ]   - æ²¡æœ‰æ‰¾åˆ°ä»»ä½•LibreOfficeè·¯å¾„")
            print("[PDFé¢„è§ˆ] æç¤º: è¯·ç¡®ä¿LibreOfficeå·²å®‰è£…å¹¶åœ¨PATHä¸­ï¼Œæˆ–ä½¿ç”¨ 'which libreoffice' æ£€æŸ¥")
            return False
        
        try:
            # å‡†å¤‡è¾“å‡ºç›®å½•
            output_dir = pdf_path.parent
            
            # ä½¿ç”¨LibreOfficeè½¬æ¢
            # --headless: æ— ç•Œé¢æ¨¡å¼
            # --convert-to pdf: è½¬æ¢ä¸ºPDFï¼Œå¹¶åµŒå…¥å­—ä½“ä»¥ç¡®ä¿è·¨å¹³å°ä¸€è‡´æ€§
            # --outdir: è¾“å‡ºç›®å½•
            # ä½¿ç”¨æ ‡å‡†PDFè½¬æ¢å‘½ä»¤
            # æ³¨æ„ï¼šLibreOfficeé»˜è®¤ä¼šåµŒå…¥å¯ç”¨å­—ä½“ï¼Œç¡®ä¿è·¨å¹³å°ä¸€è‡´æ€§
            cmd = [
                libreoffice_cmd,
                '--headless',
                '--convert-to', 'pdf',
                '--outdir', str(output_dir),
                str(docx_path)
            ]
            
            log_msg = f"[PDFé¢„è§ˆ] æ‰§è¡ŒLibreOffice PDFè½¬æ¢å‘½ä»¤: {' '.join(cmd)}"
            print(log_msg, flush=True)
            
            # å‡†å¤‡ç¯å¢ƒå˜é‡ï¼Œç¡®ä¿åŒ…å«å¿…è¦çš„ PATH å’Œ HOME
            env = os.environ.copy()
            # ç¡®ä¿ PATH åŒ…å« /usr/bin å’Œ /binï¼ˆuname ç­‰å‘½ä»¤éœ€è¦ï¼‰
            current_path = env.get('PATH', '')
            if '/usr/bin' not in current_path:
                env['PATH'] = f"/usr/bin:/bin:{current_path}"
            if '/bin' not in env['PATH']:
                env['PATH'] = f"/bin:{env['PATH']}"
            # è®¾ç½® HOME ç¯å¢ƒå˜é‡ï¼ˆLibreOffice å¯èƒ½éœ€è¦ï¼‰
            if 'HOME' not in env:
                env['HOME'] = str(abs_output_dir.parent)
            # è®¾ç½®ç”¨æˆ·ç›®å½•ï¼ˆLibreOffice å¯èƒ½éœ€è¦ï¼‰
            if 'USER' not in env:
                import pwd
                try:
                    current_uid = os.getuid()
                    user_info = pwd.getpwuid(current_uid)
                    env['USER'] = user_info.pw_name
                    env['HOME'] = user_info.pw_dir
                except Exception:
                    pass
            
            # æ‰§è¡Œè½¬æ¢ï¼ˆè¶…æ—¶60ç§’ï¼‰
            # æ³¨æ„ï¼šä½¿ç”¨ç»å¯¹è·¯å¾„ï¼Œé¿å…ç›¸å¯¹è·¯å¾„é—®é¢˜
            abs_docx_path = docx_path.resolve()
            abs_output_dir = output_dir.resolve()
            
            # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨ä¸”æƒé™æ­£ç¡®
            abs_output_dir.mkdir(parents=True, exist_ok=True)
            os.chmod(abs_output_dir, 0o755)
            
            # ç¡®ä¿è¾“å…¥æ–‡ä»¶å¯è¯»
            os.chmod(abs_docx_path, 0o644)
            
            # å¤„ç†ä¸­æ–‡æ–‡ä»¶åé—®é¢˜ï¼šæ€»æ˜¯ä½¿ç”¨ä¸´æ—¶æ–‡ä»¶ï¼Œé¿å…ä¸­æ–‡æ–‡ä»¶åå¯¼è‡´çš„é—®é¢˜
            import tempfile
            import shutil
            import uuid
            temp_input = None
            temp_output_name = None
            use_temp_file = True  # æ€»æ˜¯ä½¿ç”¨ä¸´æ—¶æ–‡ä»¶ï¼Œé¿å…ä¸­æ–‡æ–‡ä»¶åé—®é¢˜
            
            # ç”Ÿæˆå”¯ä¸€çš„ä¸´æ—¶æ–‡ä»¶å
            temp_id = str(uuid.uuid4())[:8]
            temp_input = abs_output_dir / f"temp_input_{temp_id}{abs_docx_path.suffix}"
            temp_output_name = f"temp_input_{temp_id}.pdf"
            
            # å¤åˆ¶æ–‡ä»¶åˆ°ä¸´æ—¶æ–‡ä»¶
            shutil.copy2(abs_docx_path, temp_input)
            os.chmod(temp_input, 0o644)
            log_msg = f"[PDFé¢„è§ˆ] ä½¿ç”¨ä¸´æ—¶æ–‡ä»¶é¿å…ä¸­æ–‡æ–‡ä»¶åé—®é¢˜: {temp_input} -> {temp_output_name}"
            print(log_msg, file=sys.stderr, flush=True)
            try:
                with open("/var/log/geshixiugai/error.log", "a") as f:
                    f.write(f"{log_msg}\n")
            except Exception:
                pass
            
            # ä½¿ç”¨ä¸´æ—¶æ–‡ä»¶
            input_file = temp_input
            expected_pdf_name = temp_output_name
            
            # æ·»åŠ ç¯å¢ƒå˜é‡ï¼Œç¡®ä¿LibreOfficeä½¿ç”¨æ­£ç¡®çš„å­—ä½“è®¾ç½®
            # ç¦ç”¨OpenCLï¼Œé¿å…æ¸²æŸ“é—®é¢˜
            env['SAL_DISABLE_OPENCL'] = '1'
            # è®¾ç½®LibreOfficeç”¨æˆ·é…ç½®ç›®å½•ï¼ˆå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»ºï¼‰
            lo_user_dir = Path.home() / '.config' / 'libreoffice'
            if not lo_user_dir.exists():
                try:
                    lo_user_dir.mkdir(parents=True, exist_ok=True)
                except Exception:
                    pass
            
            # é‡è¦ï¼šLibreOfficeåœ¨è½¬æ¢PDFæ—¶ä¼šä¿ç•™åŸå§‹å­—ä½“
            # ä½†å¦‚æœç³»ç»Ÿç¼ºå°‘å­—ä½“ï¼Œä¼šè‡ªåŠ¨æ›¿æ¢ä¸ºå¯ç”¨å­—ä½“
            # è§£å†³æ–¹æ¡ˆï¼š
            # 1. å®‰è£…æ‰€éœ€å­—ä½“ï¼ˆè§ å®‰è£…ä¸­æ–‡å­—ä½“.shï¼‰
            # 2. é…ç½®å­—ä½“æ›¿æ¢è§„åˆ™ï¼ˆè§ é…ç½®LibreOfficeå­—ä½“æ›¿æ¢.shï¼‰
            # 3. ç¡®ä¿PDFå¯¼å‡ºæ—¶åµŒå…¥å­—ä½“ï¼ˆLibreOfficeé»˜è®¤ä¼šåµŒå…¥å¯ç”¨å­—ä½“ï¼‰
            
            log_msg = f"[PDFé¢„è§ˆ] LibreOfficeé…ç½®ç›®å½•: {lo_user_dir}"
            print(log_msg, file=sys.stderr, flush=True)
            try:
                with open("/var/log/geshixiugai/error.log", "a") as f:
                    f.write(f"{log_msg}\n")
            except Exception:
                pass
            
            # æ£€æŸ¥æ–‡ä»¶æƒé™ï¼Œå¦‚æœæ–‡ä»¶å±äºå…¶ä»–ç”¨æˆ·ï¼Œå¯èƒ½éœ€è¦ä½¿ç”¨sudo
            # ä½†é¦–å…ˆå°è¯•ç›´æ¥æ‰§è¡Œ
            # æ³¨æ„ï¼šä½¿ç”¨PDFå¯¼å‡ºè¿‡æ»¤å™¨ï¼Œç¡®ä¿ä¿ç•™åŸå§‹å­—ä½“
            # LibreOfficeé»˜è®¤ä¼šä¿ç•™å­—ä½“ï¼Œä½†å¦‚æœç³»ç»Ÿç¼ºå°‘å­—ä½“ï¼Œå¯èƒ½ä¼šæ›¿æ¢
            # å°è¯•æ–¹æ³•1ï¼šä½¿ç”¨æ ‡å‡†PDFè½¬æ¢å‘½ä»¤
            # æ³¨æ„ï¼šLibreOffice 7.1.8.1ç‰ˆæœ¬å¯èƒ½ä¸æ”¯æŒå¤æ‚çš„JSONæ ¼å¼å‚æ•°
            # å…ˆä½¿ç”¨ç®€å•çš„PDFè½¬æ¢ï¼ŒLibreOfficeé»˜è®¤ä¼šåµŒå…¥å¯ç”¨å­—ä½“
            cmd_abs = [
                libreoffice_cmd,
                '--headless',
                '--convert-to', 'pdf',
                '--outdir', str(abs_output_dir),
                str(input_file)
            ]
            
            log_msg = f"[PDFé¢„è§ˆ] å°è¯•æ–¹æ³•1ï¼šä½¿ç”¨PDFè½¬æ¢å‘½ä»¤ï¼Œä¿ç•™åŸå§‹å­—ä½“"
            print(log_msg, file=sys.stderr, flush=True)
            try:
                with open("/var/log/geshixiugai/error.log", "a") as f:
                    f.write(f"{log_msg}\n")
            except Exception:
                pass
            
            log_msg = f"[PDFé¢„è§ˆ] ä½¿ç”¨ç»å¯¹è·¯å¾„æ‰§è¡Œå‘½ä»¤: {' '.join(cmd_abs)}"
            print(log_msg, file=sys.stderr, flush=True)
            try:
                with open("/var/log/geshixiugai/error.log", "a") as f:
                    f.write(f"{log_msg}\n")
            except Exception:
                pass
            log_msg = f"[PDFé¢„è§ˆ] è¾“å…¥æ–‡ä»¶: {abs_docx_path}, å­˜åœ¨: {abs_docx_path.exists()}"
            print(log_msg, file=sys.stderr, flush=True)
            try:
                with open("/var/log/geshixiugai/error.log", "a") as f:
                    f.write(f"{log_msg}\n")
            except Exception:
                pass
            log_msg = f"[PDFé¢„è§ˆ] è¾“å‡ºç›®å½•: {abs_output_dir}, å­˜åœ¨: {abs_output_dir.exists()}"
            print(log_msg, file=sys.stderr, flush=True)
            try:
                with open("/var/log/geshixiugai/error.log", "a") as f:
                    f.write(f"{log_msg}\n")
            except Exception:
                pass
            
            # æ£€æŸ¥æ–‡ä»¶æƒé™
            try:
                file_stat = abs_docx_path.stat()
                log_msg = f"[PDFé¢„è§ˆ] æ–‡ä»¶æƒé™: {oct(file_stat.st_mode)}, æ‰€æœ‰è€…UID: {file_stat.st_uid}, GID: {file_stat.st_gid}"
                print(log_msg, file=sys.stderr, flush=True)
                try:
                    with open("/var/log/geshixiugai/error.log", "a") as f:
                        f.write(f"{log_msg}\n")
                except Exception:
                    pass
                # æ£€æŸ¥å½“å‰ç”¨æˆ·
                current_uid = os.getuid()
                log_msg = f"[PDFé¢„è§ˆ] å½“å‰ç”¨æˆ·UID: {current_uid}"
                print(log_msg, file=sys.stderr, flush=True)
                try:
                    with open("/var/log/geshixiugai/error.log", "a") as f:
                        f.write(f"{log_msg}\n")
                except Exception:
                    pass
            except Exception as e:
                log_msg = f"[PDFé¢„è§ˆ] æ— æ³•è·å–æ–‡ä»¶æƒé™ä¿¡æ¯: {e}"
                print(log_msg, file=sys.stderr, flush=True)
                try:
                    with open("/var/log/geshixiugai/error.log", "a") as f:
                        f.write(f"{log_msg}\n")
                except Exception:
                    pass
            
            result = subprocess.run(
                cmd_abs,
                capture_output=True,
                text=True,
                timeout=60,
                env=env  # ä½¿ç”¨åŒ…å«å®Œæ•´ PATH çš„ç¯å¢ƒå˜é‡
            )
            
            log_msg = f"[PDFé¢„è§ˆ] LibreOfficeæ‰§è¡Œå®Œæˆï¼Œè¿”å›ç : {result.returncode}"
            print(log_msg, file=sys.stderr, flush=True)
            try:
                with open("/var/log/geshixiugai/error.log", "a") as f:
                    f.write(f"{log_msg}\n")
            except Exception:
                pass
            if result.stdout:
                log_msg = f"[PDFé¢„è§ˆ] LibreOfficeæ ‡å‡†è¾“å‡º: {result.stdout}"
                print(log_msg, file=sys.stderr, flush=True)
                try:
                    with open("/var/log/geshixiugai/error.log", "a") as f:
                        f.write(f"{log_msg}\n")
                except Exception:
                    pass
            if result.stderr:
                log_msg = f"[PDFé¢„è§ˆ] LibreOfficeé”™è¯¯è¾“å‡º: {result.stderr}"
                print(log_msg, file=sys.stderr, flush=True)
                try:
                    with open("/var/log/geshixiugai/error.log", "a") as f:
                        f.write(f"{log_msg}\n")
                except Exception:
                    pass
            
            # å¦‚æœå‡ºç° "no export filter" é”™è¯¯ï¼Œå°è¯•ä½¿ç”¨ä¸åŒçš„æ–¹æ³•
            if result.stderr and "no export filter" in result.stderr.lower():
                log_msg = f"[PDFé¢„è§ˆ] æ£€æµ‹åˆ° 'no export filter' é”™è¯¯ï¼Œå°è¯•ä½¿ç”¨ soffice å‘½ä»¤"
                print(log_msg, file=sys.stderr, flush=True)
                try:
                    with open("/var/log/geshixiugai/error.log", "a") as f:
                        f.write(f"{log_msg}\n")
                except Exception:
                    pass
                
                # å°è¯•ä½¿ç”¨ soffice å‘½ä»¤
                soffice_cmd = None
                for path in ['/bin/soffice', '/usr/bin/soffice']:
                    if os.path.exists(path) and os.access(path, os.X_OK):
                        soffice_cmd = path
                        break
                
                if soffice_cmd:
                    # ä½¿ç”¨æ ‡å‡†PDFè½¬æ¢å‘½ä»¤
                    cmd_abs2 = [
                        soffice_cmd,
                        '--headless',
                        '--convert-to', 'pdf',
                        '--outdir', str(abs_output_dir),
                        str(input_file)
                    ]
                    
                    log_msg = f"[PDFé¢„è§ˆ] å°è¯•ä½¿ç”¨ soffice å‘½ä»¤: {' '.join(cmd_abs2)}"
                    print(log_msg, file=sys.stderr, flush=True)
                    try:
                        with open("/var/log/geshixiugai/error.log", "a") as f:
                            f.write(f"{log_msg}\n")
                    except Exception:
                        pass
                    
                    result = subprocess.run(
                        cmd_abs2,
                        capture_output=True,
                        text=True,
                        timeout=60,
                        env=env
                    )
                    
                    log_msg = f"[PDFé¢„è§ˆ] soffice æ‰§è¡Œå®Œæˆï¼Œè¿”å›ç : {result.returncode}"
                    print(log_msg, file=sys.stderr, flush=True)
                    try:
                        with open("/var/log/geshixiugai/error.log", "a") as f:
                            f.write(f"{log_msg}\n")
                    except Exception:
                        pass
                    if result.stderr:
                        log_msg = f"[PDFé¢„è§ˆ] soffice é”™è¯¯è¾“å‡º: {result.stderr}"
                        print(log_msg, file=sys.stderr, flush=True)
                        try:
                            with open("/var/log/geshixiugai/error.log", "a") as f:
                                f.write(f"{log_msg}\n")
                        except Exception:
                            pass
            
            # LibreOffice ä¼šåœ¨è¾“å‡ºç›®å½•ç”Ÿæˆä¸è¾“å…¥æ–‡ä»¶åŒåçš„PDF
            # ä¾‹å¦‚ï¼špreview.docx -> preview.pdf
            # ä½¿ç”¨ç»å¯¹è·¯å¾„æŸ¥æ‰¾
            generated_pdf = abs_output_dir / expected_pdf_name
            
            # ç­‰å¾…æ–‡ä»¶ç”Ÿæˆï¼ˆLibreOffice å¯èƒ½éœ€è¦ä¸€ç‚¹æ—¶é—´ï¼‰
            import time
            max_wait = 10  # å¢åŠ åˆ°10ç§’ï¼Œç»™LibreOfficeæ›´å¤šæ—¶é—´
            wait_interval = 0.5  # æ¯0.5ç§’æ£€æŸ¥ä¸€æ¬¡
            waited = 0
            while not generated_pdf.exists() and waited < max_wait:
                time.sleep(wait_interval)
                waited += wait_interval
                log_msg = f"[PDFé¢„è§ˆ] ç­‰å¾…PDFæ–‡ä»¶ç”Ÿæˆ... ({waited:.1f}s)"
                print(log_msg, file=sys.stderr, flush=True)
                try:
                    with open("/var/log/geshixiugai/error.log", "a") as f:
                        f.write(f"{log_msg}\n")
                except Exception:
                    pass
            
            # æ£€æŸ¥æ˜¯å¦æˆåŠŸç”ŸæˆPDFæ–‡ä»¶ï¼ˆå³ä½¿è¿”å›ç éé›¶ï¼Œä¹Ÿå¯èƒ½æˆåŠŸè½¬æ¢ï¼‰
            if generated_pdf.exists():
                # éªŒè¯æ–‡ä»¶å¤§å°ï¼ˆåº”è¯¥å¤§äº0ï¼‰
                pdf_size = generated_pdf.stat().st_size
                if pdf_size > 0:
                    log_msg = f"[PDFé¢„è§ˆ] âœ… PDFæ–‡ä»¶å·²ç”Ÿæˆ: {generated_pdf}, å¤§å°: {pdf_size / 1024:.2f} KB"
                    print(log_msg, file=sys.stderr, flush=True)
                    try:
                        with open("/var/log/geshixiugai/error.log", "a") as f:
                            f.write(f"{log_msg}\n")
                    except Exception:
                        pass
                    # å³ä½¿è¿”å›ç éé›¶ï¼Œåªè¦æ–‡ä»¶ç”Ÿæˆäº†å°±è®¤ä¸ºæˆåŠŸ
                    # å°†ç”Ÿæˆçš„PDFç§»åŠ¨åˆ°ç›®æ ‡è·¯å¾„
                    shutil.move(str(generated_pdf), str(pdf_path))
                    log_msg = f"[PDFé¢„è§ˆ] LibreOffice PDFè½¬æ¢æˆåŠŸï¼Œæ–‡ä»¶å·²ç§»åŠ¨åˆ°: {pdf_path}"
                    print(log_msg, file=sys.stderr, flush=True)
                    try:
                        with open("/var/log/geshixiugai/error.log", "a") as f:
                            f.write(f"{log_msg}\n")
                    except Exception:
                        pass
                    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                    if temp_input and temp_input.exists():
                        temp_input.unlink()
                    return True
                else:
                    log_msg = f"[PDFé¢„è§ˆ] âš ï¸ PDFæ–‡ä»¶å­˜åœ¨ä½†å¤§å°ä¸º0: {generated_pdf}"
                    print(log_msg, file=sys.stderr, flush=True)
                    try:
                        with open("/var/log/geshixiugai/error.log", "a") as f:
                            f.write(f"{log_msg}\n")
                    except Exception:
                        pass
            
            # å¦‚æœæ‰¾ä¸åˆ°é¢„æœŸçš„PDFæ–‡ä»¶ï¼Œå°è¯•åˆ—å‡ºè¾“å‡ºç›®å½•ä¸­çš„æ‰€æœ‰æ–‡ä»¶
            if not generated_pdf.exists():
                print(f"[PDFé¢„è§ˆ] é¢„æœŸPDFæ–‡ä»¶ä¸å­˜åœ¨: {generated_pdf}")
                print(f"[PDFé¢„è§ˆ] æ£€æŸ¥è¾“å‡ºç›®å½•ä¸­çš„æ‰€æœ‰æ–‡ä»¶:")
                try:
                    all_files = list(output_dir.glob("*"))
                    for f in all_files:
                        print(f"[PDFé¢„è§ˆ]   - {f.name} ({f.stat().st_size} bytes)")
                    # å°è¯•æŸ¥æ‰¾ä»»ä½• PDF æ–‡ä»¶
                    pdf_files = list(output_dir.glob("*.pdf"))
                    if pdf_files:
                        print(f"[PDFé¢„è§ˆ] æ‰¾åˆ° {len(pdf_files)} ä¸ªPDFæ–‡ä»¶ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ª: {pdf_files[0]}")
                        generated_pdf = pdf_files[0]
                    else:
                        log_msg = f"[PDFé¢„è§ˆ] è¾“å‡ºç›®å½•ä¸­æ²¡æœ‰æ‰¾åˆ°ä»»ä½•PDFæ–‡ä»¶"
                        print(log_msg, flush=True)
                        if result.returncode != 0:
                            log_msg = f"[PDFé¢„è§ˆ] LibreOfficeè¿”å›é”™è¯¯ç : {result.returncode}"
                            print(log_msg, flush=True)
                            if result.stdout:
                                log_msg = f"[PDFé¢„è§ˆ] LibreOfficeæ ‡å‡†è¾“å‡º: {result.stdout}"
                                print(log_msg, flush=True)
                            if result.stderr:
                                log_msg = f"[PDFé¢„è§ˆ] LibreOfficeé”™è¯¯è¾“å‡º: {result.stderr}"
                                print(log_msg, flush=True)
                        # æ£€æŸ¥è¾“å‡ºç›®å½•æƒé™
                        try:
                            dir_stat = abs_output_dir.stat()
                            log_msg = f"[PDFé¢„è§ˆ] è¾“å‡ºç›®å½•æƒé™: {oct(dir_stat.st_mode)}, æ‰€æœ‰è€…UID: {dir_stat.st_uid}"
                            print(log_msg, flush=True)
                        except Exception as e:
                            log_msg = f"[PDFé¢„è§ˆ] æ— æ³•è·å–ç›®å½•æƒé™: {e}"
                            print(log_msg, flush=True)
                        # è¾“å‡ºè¯¦ç»†çš„è¯Šæ–­ä¿¡æ¯
                        log_msg = f"[PDFé¢„è§ˆ] è½¬æ¢å¤±è´¥è¯Šæ–­: è¾“å…¥æ–‡ä»¶={abs_docx_path}, è¾“å‡ºç›®å½•={abs_output_dir}, LibreOfficeå‘½ä»¤={libreoffice_cmd}"
                        print(log_msg, flush=True)
                        return False
                except Exception as e:
                    print(f"[PDFé¢„è§ˆ] åˆ—å‡ºæ–‡ä»¶æ—¶å‡ºé”™: {e}")
                    return False
            
            # å¦‚æœæ‰¾åˆ°äº†PDFæ–‡ä»¶ï¼Œç§»åŠ¨åˆ°ç›®æ ‡ä½ç½®
            if generated_pdf.exists():
                pdf_size = generated_pdf.stat().st_size
                if pdf_size > 0:
                    # ç§»åŠ¨åˆ°ç›®æ ‡ä½ç½®
                    if generated_pdf != pdf_path:
                        shutil.move(str(generated_pdf), str(pdf_path))
                    else:
                        # å¦‚æœå·²ç»æ˜¯ç›®æ ‡è·¯å¾„ï¼ŒéªŒè¯æ–‡ä»¶å¤§å°
                        pdf_size = pdf_path.stat().st_size
                    
                    print(f"[PDFé¢„è§ˆ] âœ… LibreOffice PDFè½¬æ¢æˆåŠŸï¼Œå¤§å°: {pdf_size / 1024:.2f} KB")
                    
                    # éªŒè¯PDFæ–‡ä»¶æ˜¯å¦æœ‰æ•ˆï¼ˆè‡³å°‘åº”è¯¥æœ‰ä¸€å®šå¤§å°ï¼‰
                    if pdf_size < 1024:  # å°äº1KBå¯èƒ½æœ‰é—®é¢˜
                        print(f"[PDFé¢„è§ˆ] âš ï¸ è­¦å‘Š: PDFæ–‡ä»¶å¤§å°å¼‚å¸¸å° ({pdf_size} å­—èŠ‚)ï¼Œå¯èƒ½ç”Ÿæˆå¤±è´¥")
                        return False
                    
                    return True
                else:
                    print(f"[PDFé¢„è§ˆ] âš ï¸ PDFæ–‡ä»¶å­˜åœ¨ä½†å¤§å°ä¸º0: {generated_pdf}")
                    return False
            else:
                print(f"[PDFé¢„è§ˆ] âŒ æœªæ‰¾åˆ°ç”Ÿæˆçš„PDFæ–‡ä»¶")
                if result.returncode != 0:
                    print(f"[PDFé¢„è§ˆ] LibreOfficeè¿”å›é”™è¯¯ç : {result.returncode}")
                return False
            
        except subprocess.TimeoutExpired:
            print("[PDFé¢„è§ˆ] LibreOffice PDFè½¬æ¢è¶…æ—¶ï¼ˆè¶…è¿‡60ç§’ï¼‰")
            return False
        except Exception as e:
            print(f"[PDFé¢„è§ˆ] LibreOffice PDFè½¬æ¢å‡ºé”™: {e}")
            import traceback
            traceback.print_exc()
            return False

